# -*- coding: utf-8 -*-
"""Versions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ju5cKGgSWOXz6f7NsbaZNejE4y5CAPvJ

Previous Models

5 layers with early stopping
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn.functional as F
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Preprocess and load the dataset
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

# Define a convolution neural network
class Network(nn.Module):
    def __init__(self, num_classes):
        super(Network, self).__init__()

        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)
        self.bn1 = nn.BatchNorm2d(12)
        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(12)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)
        self.bn4 = nn.BatchNorm2d(24)
        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)
        self.bn5 = nn.BatchNorm2d(24)
        self.fc1 = nn.Linear(24*106*106, num_classes)

    def forward(self, input): #add dropout between each layer
        output = F.relu(self.bn1(self.conv1(input)))
        output = F.relu(self.bn2(self.conv2(output)))
        output = self.pool(output)
        output = F.relu(self.bn4(self.conv4(output)))
        output = F.relu(self.bn5(self.conv5(output)))
        output = output.view(-1, 24*106*106)
        output = self.fc1(output)

        return output

# Instantiate a neural network model
num_classes = 102  # Number of classes in Flowers102 dataset
model = Network(num_classes)


# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)  # was 0.0001

# Train the model
epochs = 20
train_losses = []
test_losses = []
best_test_loss = float("inf")
patience = 3
bad_counter = 0
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(test_loss)

    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')

    # Early stopping and learning rate adjustment
    if test_loss < best_test_loss:
        best_test_loss = test_loss
        bad_counter = 0
    else:
        bad_counter += 1
        if bad_counter >= patience:
            print("Adjusting learning rate...")
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10
            bad_counter = 0  # Reset bad_counter
    print(bad_counter)

# Plot the training and test losses
plt.plot(range(1, epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, epochs+1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Losses')
plt.legend()
plt.show()

"""2 layers - OPTIMAL MODEL"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn.functional as F
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Preprocess and load the dataset
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
val_dataset = Flowers102(root='./data', split='val', transform=data_transform, download=True)
test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64)
test_loader = DataLoader(test_dataset, batch_size=64)


# Define the neural network architecture
class MyCNN(nn.Module):
    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=100, img_h=100, num_classes=102):
        super(MyCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn1 = nn.BatchNorm2d(num_out_ch[0])  # Batch normalization after conv1
        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn2 = nn.BatchNorm2d(num_out_ch[1])  # Batch normalization after conv2
        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))
        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)
        self.dropout = nn.Dropout(0.5)  # Dropout layer with p=0.5

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.dropout(x)  # Apply dropout after pooling
        x = self.fc(x.reshape(x.shape[0], -1))
        return x

# Initialize the model
num_classes = len(set(train_dataset._labels))
model = MyCNN(num_channels=3, num_out_ch=[16, 32], img_w=224, img_h=224, num_classes=num_classes)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00001)

# Train the model
epochs = 100
train_losses = []
test_losses = []
val_losses = []
best_test_loss = float("inf")
patience = 3
bad_counter = 0
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        for images, labels in val_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total_val += labels.size(0)
            correct_val += (predicted == labels).sum().item()
    val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(val_loss)

    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(test_loss)

        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {(100*correct_val / total_val):.2f}%')

    # Early stopping and learning rate adjustment
    if test_loss < best_test_loss:
        best_test_loss = test_loss
        bad_counter = 0
    else:
        bad_counter += 1
        if bad_counter >= patience:
            print("Adjusting learning rate...")
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10
            bad_counter = 0  # Reset bad_counter
    print(bad_counter)

print(f'Final Test Loss: {test_loss}, Final Test Accuracy: {(100 * correct / total):.2f}%')
# Plot the training and test losses
plt.plot(range(1, epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, epochs+1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Losses')
plt.legend()
plt.show()

"""OPTIMAL MODEL with improved graphs and using validation set"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn.functional as F
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt

# Preprocess and load the dataset
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
val_dataset = Flowers102(root='./data', split='val', transform=data_transform, download=True)
test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=64)
test_loader = DataLoader(test_dataset, batch_size=64)


# Define the neural network architecture
class MyCNN(nn.Module):
    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=100, img_h=100, num_classes=102):
        super(MyCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn1 = nn.BatchNorm2d(num_out_ch[0])  # Batch normalization after conv1
        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn2 = nn.BatchNorm2d(num_out_ch[1])  # Batch normalization after conv2
        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))
        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)
        self.dropout = nn.Dropout(0.5)  # Dropout layer with p=0.5

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.dropout(x)  # Apply dropout after pooling
        x = self.fc(x.reshape(x.shape[0], -1))
        return x

# Initialize the model
num_classes = len(set(train_dataset._labels))
model = MyCNN(num_channels=3, num_out_ch=[16, 32], img_w=224, img_h=224, num_classes=num_classes)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00001)

# Train the model
epochs = 100
train_losses = []
val_losses = []
test_losses = []
train_accuracy = []
val_accuracy = []
test_accuracy = []
best_test_loss = float("inf")
patience = 3
bad_counter = 0
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    correct_train = 0
    total_train = 0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
        _, predicted = torch.max(outputs, 1)
        total_train += labels.size(0)
        correct_train += (predicted == labels).sum().item()
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)
    train_accuracy.append(100 * correct_train / total_train)

    model.eval()
    val_loss = 0.0
    correct_val = 0
    total_val = 0
    with torch.no_grad():
        for images, labels in val_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total_val += labels.size(0)
            correct_val += (predicted == labels).sum().item()
    val_loss = val_loss / len(val_loader.dataset)
    val_losses.append(val_loss)
    val_accuracy.append(100 * correct_val / total_val)

    model.eval()
    test_loss = 0.0
    correct_test = 0
    total_test = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total_test += labels.size(0)
            correct_test += (predicted == labels).sum().item()
    test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(test_loss)
    test_accuracy.append(100 * correct_test / total_test)

    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {(100*correct_val / total_val):.2f}%')

    # Early stopping and learning rate adjustment
    if test_loss < best_test_loss:
        best_test_loss = test_loss
        bad_counter = 0
    else:
        bad_counter += 1
        if bad_counter >= patience:
            print("Adjusting learning rate...")
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10
            bad_counter = 0  # Reset bad_counter
    print(bad_counter)

print(f'Final Test Loss: {test_loss}, Final Test Accuracy: {(100 * correct_test / total_test):.2f}%')

# Plot the training and test losses
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(range(1, epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')
plt.plot(range(1, epochs+1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Losses')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(range(1, epochs+1), train_accuracy, label='Train Accuracy')
plt.plot(range(1, epochs+1), val_accuracy, label='Validation Accuracy')
plt.plot(range(1, epochs+1), test_accuracy, label='Test Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Training and Test Accuracy')
plt.legend()

plt.tight_layout()
plt.show()

"""Cosine Annealing Test (FAILED)"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn.functional as F
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR

# Preprocess and load the dataset
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

# Define the neural network architecture
class MyCNN(nn.Module):
    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=100, img_h=100, num_classes=102):
        super(MyCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        #add relu

        self.bn1 = nn.BatchNorm2d(num_out_ch[0])  # Batch normalization after conv1
        #added pooling
        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))
        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn2 = nn.BatchNorm2d(num_out_ch[1])  # Batch normalization after conv2
        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))
        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)
        self.dropout = nn.Dropout(0.5)  # Dropout layer with p=0.5

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.dropout(x)  # Apply dropout after pooling
        x = self.fc(x.reshape(x.shape[0], -1))
        return x

# Initialize the model
num_classes = len(set(train_dataset._labels))
model = MyCNN(num_channels=3, num_out_ch=[16, 32], img_w=224, img_h=224, num_classes=num_classes)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00001)

# Train the model
epochs = 100
train_losses = []
test_losses = []
best_test_loss = float("inf")
patience = 3
bad_counter = 0


for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(test_loss)

    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')

    # Early stopping and learning rate adjustment
    if test_loss < best_test_loss:
        best_test_loss = test_loss
        bad_counter = 0
    else:
        bad_counter += 1
        if bad_counter >= patience:
            print("Adjusting learning rate...")
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10
            bad_counter = 0  # Reset bad_counter


# Plot the training and test losses
plt.plot(range(1, epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, epochs+1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Losses')
plt.legend()
plt.show()

"""4 layers Adaptive pool with sequential"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import torch.nn.functional as F
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR

# Preprocess and load the dataset
data_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

class MyCNN(nn.Module):
    def __init__(self, num_channels=3, num_out_ch=[8, 16, 32, 64], img_w=100, img_h=100, num_classes=102):
        super(MyCNN, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],
                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),
            nn.BatchNorm2d(num_out_ch[0]),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),

            nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],
                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),
            nn.BatchNorm2d(num_out_ch[1]),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),

            nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[2],
                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),
            nn.BatchNorm2d(num_out_ch[2]),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),

            nn.Conv2d(in_channels=num_out_ch[2], out_channels=num_out_ch[3],
                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),
            nn.BatchNorm2d(num_out_ch[3]),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),

            nn.AdaptiveAvgPool2d((1, 1))
        )
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(in_features=num_out_ch[3], out_features=num_classes)
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # Flatten the features
        x = self.classifier(x)
        return x

# Initialize the model
num_classes = len(set(train_dataset._labels))
model = MyCNN(num_channels=3, num_out_ch=[16, 32, 64, 128], img_w=224, img_h=224, num_classes=num_classes)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001)

# Train the model
epochs = 20
train_losses = []
test_losses = []
best_test_loss = float("inf")
patience = 3
bad_counter = 0

# Cosine Annealing Learning Rate Scheduler
scheduler = CosineAnnealingLR(optimizer, T_max=epochs)

for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(test_loss)

    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')

    # Early stopping and learning rate adjustment
    if test_loss < best_test_loss:
        best_test_loss = test_loss
        bad_counter = 0
    else:
        bad_counter += 1
        if bad_counter >= patience:
            print("Adjusting learning rate...")
            scheduler.step()  # Update learning rate
            bad_counter = 0  # Reset bad_counter

# Plot the training and test losses
plt.plot(range(1, epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, epochs+1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Losses')
plt.legend()
plt.show()

"""USING RAY TUNING"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import ray
from ray import train
from ray import tune
from ray.train import Checkpoint
from ray.train.torch import TorchTrainer


# Load the dataset
data_transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(30),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Define the neural network architecture
class MyCNN(nn.Module):
    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=128, img_h=128, num_classes=102):
        super(MyCNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn1 = nn.BatchNorm2d(num_out_ch[0])
        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],
                               kernel_size=(3,3), stride=(1,1), padding=(1,1))
        self.bn2 = nn.BatchNorm2d(num_out_ch[1])
        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))
        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(F.relu(self.bn1(self.conv1(x))))
        x = self.pool(F.relu(self.bn2(self.conv2(x))))
        x = self.dropout(x)
        x = self.fc(x.reshape(x.shape[0], -1))
        return x

def train(config):
    # Load the dataset with absolute paths
    train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
    test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=64)

    # Initialize the model
    model = MyCNN(num_channels=3, num_out_ch=[config["conv1_out_ch"], config["conv2_out_ch"]],
                  img_w=128, img_h=128, num_classes=102)

    # Define loss function and optimizer
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=config["lr"])

    # Train the model
    epochs = 5
    for epoch in range(epochs):
        model.train()
        for images, labels in train_loader:
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

    # Evaluate the model
    model.eval()
    with torch.no_grad():
        total = 0
        correct = 0
        for images, labels in test_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    accuracy = correct / total

    # Use ray.train.report instead of tune.report
    ray.train.report({"accuracy": accuracy})

# Configure Ray Tune
ray.shutdown()
ray.init()
analysis = tune.run(
    train,
    config=config,
    resources_per_trial={"cpu": 2},
    num_samples=10,
)

# Get best hyperparameters
best_config = analysis.get_best_config(metric="accuracy", mode="max")
print("Best hyperparameters:", best_config)

"""RESEARCH PAPER WITH OVERFEAT NETWORK ARCHITECTURE"""

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.datasets import Flowers102
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import torch.nn.functional as F

# Preprocess and load the dataset with augmented transformations
data_transform = transforms.Compose([
    transforms.Resize((231, 231)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.8, 1.2)),
    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)
test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=64)

# Define the neural network architecture
class MyCNN(nn.Module):
    def __init__(self, num_classes=102):
        super(MyCNN, self).__init__()
        # Initialize the CNN layers with the specified architecture
        self.features = nn.Sequential(
            nn.Conv2d(3, 96, kernel_size=11, stride=4),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        # Calculate the input size for the fully connected layers dynamically
        self.fc_input_size = self._get_fc_input_size()

        # Fully connected layers
        self.fc1 = nn.Linear(self.fc_input_size, 3072)
        self.fc2 = nn.Linear(3072, 4096)
        self.fc3 = nn.Linear(4096, num_classes)



    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)  # Flatten the feature maps
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def _get_fc_input_size(self):
        # Forward a dummy input through the convolutional layers to get the output size
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 231, 231)  # Assuming input image size of 231x231
            features_output = self.features(dummy_input)
            return features_output.view(features_output.size(0), -1).shape[1]

# Initialize the model
num_classes = len(set(train_dataset._labels))
model = MyCNN(num_classes=num_classes)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)

# Train the model
epochs = 200
train_losses = []
test_losses = []
best_test_loss = float('inf')
patience = 3
counter = 0
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for images, labels in train_loader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * images.size(0)
    train_loss = running_loss / len(train_loader.dataset)
    train_losses.append(train_loss)

    model.eval()
    test_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            test_loss += loss.item() * images.size(0)
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    test_loss = test_loss / len(test_loader.dataset)
    test_losses.append(test_loss)

    # Early stopping and learning rate adjustment
    if test_loss < best_test_loss:
        best_test_loss = test_loss
        bad_counter = 0
    else:
        bad_counter += 1
        if bad_counter >= patience:
            print("Adjusting learning rate...")
            for param_group in optimizer.param_groups:
                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10
            bad_counter = 0  # Reset bad_counter

    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')

# Plot the training and test losses
plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')
plt.plot(range(1, len(test_losses) + 1), test_losses, label='Test Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Test Losses')
plt.legend()
plt.show()