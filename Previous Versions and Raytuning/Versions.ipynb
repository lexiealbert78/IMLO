{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIIs3V9QF2fu"
      },
      "source": [
        "Previous Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj8MlCkyUHpE"
      },
      "source": [
        "5 layers with early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YCzRma2i0Ney",
        "outputId": "a62e0f0b-a8a4-45d9-ac80-49800033abf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:11<00:00, 29929752.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 321948.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 11194519.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Train Loss: 11.1368, Test Loss: 5.4219, Test Accuracy: 2.85%\n",
            "0\n",
            "Epoch [2/20], Train Loss: 7.0505, Test Loss: 4.7942, Test Accuracy: 6.91%\n",
            "0\n",
            "Epoch [3/20], Train Loss: 3.4557, Test Loss: 4.9555, Test Accuracy: 13.09%\n",
            "1\n",
            "Epoch [4/20], Train Loss: 2.3601, Test Loss: 5.2322, Test Accuracy: 12.46%\n",
            "2\n",
            "Epoch [5/20], Train Loss: 1.8673, Test Loss: 5.1538, Test Accuracy: 14.10%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [6/20], Train Loss: 1.2897, Test Loss: 4.3205, Test Accuracy: 19.14%\n",
            "0\n",
            "Epoch [7/20], Train Loss: 0.8834, Test Loss: 4.2625, Test Accuracy: 18.85%\n",
            "0\n",
            "Epoch [8/20], Train Loss: 0.7971, Test Loss: 4.1018, Test Accuracy: 19.19%\n",
            "0\n",
            "Epoch [9/20], Train Loss: 0.6704, Test Loss: 4.1281, Test Accuracy: 19.45%\n",
            "1\n",
            "Epoch [10/20], Train Loss: 0.6509, Test Loss: 4.2125, Test Accuracy: 19.21%\n",
            "2\n",
            "Epoch [11/20], Train Loss: 0.5943, Test Loss: 4.0638, Test Accuracy: 20.82%\n",
            "0\n",
            "Epoch [12/20], Train Loss: 0.5703, Test Loss: 4.0460, Test Accuracy: 20.72%\n",
            "0\n",
            "Epoch [13/20], Train Loss: 0.5240, Test Loss: 4.1305, Test Accuracy: 19.78%\n",
            "1\n",
            "Epoch [14/20], Train Loss: 0.5143, Test Loss: 4.0931, Test Accuracy: 20.12%\n",
            "2\n",
            "Epoch [15/20], Train Loss: 0.4543, Test Loss: 4.1114, Test Accuracy: 19.84%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [16/20], Train Loss: 0.4194, Test Loss: 4.0542, Test Accuracy: 20.05%\n",
            "1\n",
            "Epoch [17/20], Train Loss: 0.3696, Test Loss: 4.0516, Test Accuracy: 20.04%\n",
            "2\n",
            "Epoch [18/20], Train Loss: 0.4332, Test Loss: 4.0363, Test Accuracy: 20.88%\n",
            "0\n",
            "Epoch [19/20], Train Loss: 0.4000, Test Loss: 4.0802, Test Accuracy: 20.46%\n",
            "1\n",
            "Epoch [20/20], Train Loss: 0.4369, Test Loss: 4.0494, Test Accuracy: 20.43%\n",
            "2\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocess and load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Define a convolution neural network\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(12)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(24)\n",
        "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(24)\n",
        "        self.fc1 = nn.Linear(24*106*106, num_classes)\n",
        "\n",
        "    def forward(self, input): #add dropout between each layer\n",
        "        output = F.relu(self.bn1(self.conv1(input)))\n",
        "        output = F.relu(self.bn2(self.conv2(output)))\n",
        "        output = self.pool(output)\n",
        "        output = F.relu(self.bn4(self.conv4(output)))\n",
        "        output = F.relu(self.bn5(self.conv5(output)))\n",
        "        output = output.view(-1, 24*106*106)\n",
        "        output = self.fc1(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "# Instantiate a neural network model\n",
        "num_classes = 102  # Number of classes in Flowers102 dataset\n",
        "model = Network(num_classes)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # was 0.0001\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "best_test_loss = float(\"inf\")\n",
        "patience = 3\n",
        "bad_counter = 0\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')\n",
        "\n",
        "    # Early stopping and learning rate adjustment\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "        if bad_counter >= patience:\n",
        "            print(\"Adjusting learning rate...\")\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10\n",
        "            bad_counter = 0  # Reset bad_counter\n",
        "    print(bad_counter)\n",
        "\n",
        "# Plot the training and test losses\n",
        "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Losses')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnRovF6_F64s"
      },
      "source": [
        "2 layers - OPTIMAL MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-ynGXAf9wSn",
        "outputId": "1880c100-d688-4b23-ea30-0015e5574748"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:12<00:00, 28053594.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 398927.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 2773199.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Train Loss: 4.9499, Test Loss: 4.4809, Test Accuracy: 4.72%\n",
            "0\n",
            "Epoch [2/100], Train Loss: 4.3212, Test Loss: 4.1950, Test Accuracy: 7.95%\n",
            "0\n",
            "Epoch [3/100], Train Loss: 3.9015, Test Loss: 3.9978, Test Accuracy: 10.21%\n",
            "0\n",
            "Epoch [4/100], Train Loss: 3.6390, Test Loss: 3.8305, Test Accuracy: 12.75%\n",
            "0\n",
            "Epoch [5/100], Train Loss: 3.4061, Test Loss: 3.8206, Test Accuracy: 13.25%\n",
            "0\n",
            "Epoch [6/100], Train Loss: 3.2506, Test Loss: 3.6863, Test Accuracy: 15.19%\n",
            "0\n",
            "Epoch [7/100], Train Loss: 3.0283, Test Loss: 3.6618, Test Accuracy: 15.38%\n",
            "0\n",
            "Epoch [8/100], Train Loss: 2.9116, Test Loss: 3.6009, Test Accuracy: 15.94%\n",
            "0\n",
            "Epoch [9/100], Train Loss: 2.7937, Test Loss: 3.5796, Test Accuracy: 17.25%\n",
            "0\n",
            "Epoch [10/100], Train Loss: 2.6881, Test Loss: 3.5466, Test Accuracy: 17.30%\n",
            "0\n",
            "Epoch [11/100], Train Loss: 2.5247, Test Loss: 3.4818, Test Accuracy: 18.78%\n",
            "0\n",
            "Epoch [12/100], Train Loss: 2.4655, Test Loss: 3.4842, Test Accuracy: 18.93%\n",
            "1\n",
            "Epoch [13/100], Train Loss: 2.3005, Test Loss: 3.4443, Test Accuracy: 19.56%\n",
            "0\n",
            "Epoch [14/100], Train Loss: 2.2897, Test Loss: 3.4085, Test Accuracy: 19.47%\n",
            "0\n",
            "Epoch [15/100], Train Loss: 2.1317, Test Loss: 3.3964, Test Accuracy: 20.25%\n",
            "0\n",
            "Epoch [16/100], Train Loss: 2.1058, Test Loss: 3.3609, Test Accuracy: 20.77%\n",
            "0\n",
            "Epoch [17/100], Train Loss: 2.0061, Test Loss: 3.3598, Test Accuracy: 20.62%\n",
            "0\n",
            "Epoch [18/100], Train Loss: 1.9361, Test Loss: 3.3209, Test Accuracy: 21.97%\n",
            "0\n",
            "Epoch [19/100], Train Loss: 1.9058, Test Loss: 3.3205, Test Accuracy: 21.73%\n",
            "0\n",
            "Epoch [20/100], Train Loss: 1.7951, Test Loss: 3.3268, Test Accuracy: 21.53%\n",
            "1\n",
            "Epoch [21/100], Train Loss: 1.7218, Test Loss: 3.3135, Test Accuracy: 21.87%\n",
            "0\n",
            "Epoch [22/100], Train Loss: 1.6741, Test Loss: 3.2866, Test Accuracy: 22.80%\n",
            "0\n",
            "Epoch [23/100], Train Loss: 1.5998, Test Loss: 3.2798, Test Accuracy: 22.18%\n",
            "0\n",
            "Epoch [24/100], Train Loss: 1.5729, Test Loss: 3.2384, Test Accuracy: 23.65%\n",
            "0\n",
            "Epoch [25/100], Train Loss: 1.5199, Test Loss: 3.2853, Test Accuracy: 23.73%\n",
            "1\n",
            "Epoch [26/100], Train Loss: 1.4763, Test Loss: 3.2347, Test Accuracy: 24.57%\n",
            "0\n",
            "Epoch [27/100], Train Loss: 1.4088, Test Loss: 3.2495, Test Accuracy: 23.48%\n",
            "1\n",
            "Epoch [28/100], Train Loss: 1.3170, Test Loss: 3.2526, Test Accuracy: 24.00%\n",
            "2\n",
            "Epoch [29/100], Train Loss: 1.2857, Test Loss: 3.2322, Test Accuracy: 24.09%\n",
            "0\n",
            "Epoch [30/100], Train Loss: 1.2699, Test Loss: 3.1889, Test Accuracy: 24.98%\n",
            "0\n",
            "Epoch [31/100], Train Loss: 1.2429, Test Loss: 3.2359, Test Accuracy: 24.41%\n",
            "1\n",
            "Epoch [32/100], Train Loss: 1.1913, Test Loss: 3.1792, Test Accuracy: 24.87%\n",
            "0\n",
            "Epoch [33/100], Train Loss: 1.0937, Test Loss: 3.2042, Test Accuracy: 25.04%\n",
            "1\n",
            "Epoch [34/100], Train Loss: 1.0818, Test Loss: 3.1747, Test Accuracy: 25.97%\n",
            "0\n",
            "Epoch [35/100], Train Loss: 1.0686, Test Loss: 3.1737, Test Accuracy: 25.48%\n",
            "0\n",
            "Epoch [36/100], Train Loss: 1.0102, Test Loss: 3.2205, Test Accuracy: 24.17%\n",
            "1\n",
            "Epoch [37/100], Train Loss: 1.0183, Test Loss: 3.2110, Test Accuracy: 24.59%\n",
            "2\n",
            "Epoch [38/100], Train Loss: 0.9572, Test Loss: 3.1553, Test Accuracy: 26.04%\n",
            "0\n",
            "Epoch [39/100], Train Loss: 0.9762, Test Loss: 3.1970, Test Accuracy: 25.74%\n",
            "1\n",
            "Epoch [40/100], Train Loss: 0.8981, Test Loss: 3.1844, Test Accuracy: 26.23%\n",
            "2\n",
            "Epoch [41/100], Train Loss: 0.8781, Test Loss: 3.1481, Test Accuracy: 26.36%\n",
            "0\n",
            "Epoch [42/100], Train Loss: 0.8702, Test Loss: 3.1940, Test Accuracy: 25.26%\n",
            "1\n",
            "Epoch [43/100], Train Loss: 0.8924, Test Loss: 3.1673, Test Accuracy: 25.60%\n",
            "2\n",
            "Epoch [44/100], Train Loss: 0.8040, Test Loss: 3.1566, Test Accuracy: 26.17%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [45/100], Train Loss: 0.7741, Test Loss: 3.1554, Test Accuracy: 26.38%\n",
            "1\n",
            "Epoch [46/100], Train Loss: 0.7531, Test Loss: 3.1537, Test Accuracy: 26.56%\n",
            "2\n",
            "Epoch [47/100], Train Loss: 0.7420, Test Loss: 3.1494, Test Accuracy: 26.39%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [48/100], Train Loss: 0.7656, Test Loss: 3.1360, Test Accuracy: 26.69%\n",
            "0\n",
            "Epoch [49/100], Train Loss: 0.7575, Test Loss: 3.1454, Test Accuracy: 26.70%\n",
            "1\n",
            "Epoch [50/100], Train Loss: 0.7744, Test Loss: 3.1400, Test Accuracy: 26.67%\n",
            "2\n",
            "Epoch [51/100], Train Loss: 0.7387, Test Loss: 3.1628, Test Accuracy: 26.64%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [52/100], Train Loss: 0.7566, Test Loss: 3.1402, Test Accuracy: 26.61%\n",
            "1\n",
            "Epoch [53/100], Train Loss: 0.7538, Test Loss: 3.1307, Test Accuracy: 26.96%\n",
            "0\n",
            "Epoch [54/100], Train Loss: 0.7585, Test Loss: 3.1772, Test Accuracy: 26.52%\n",
            "1\n",
            "Epoch [55/100], Train Loss: 0.7945, Test Loss: 3.1733, Test Accuracy: 26.00%\n",
            "2\n",
            "Epoch [56/100], Train Loss: 0.7641, Test Loss: 3.1449, Test Accuracy: 26.56%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [57/100], Train Loss: 0.7297, Test Loss: 3.1541, Test Accuracy: 26.17%\n",
            "1\n",
            "Epoch [58/100], Train Loss: 0.7617, Test Loss: 3.1497, Test Accuracy: 26.54%\n",
            "2\n",
            "Epoch [59/100], Train Loss: 0.7790, Test Loss: 3.1194, Test Accuracy: 27.08%\n",
            "0\n",
            "Epoch [60/100], Train Loss: 0.7575, Test Loss: 3.1495, Test Accuracy: 26.20%\n",
            "1\n",
            "Epoch [61/100], Train Loss: 0.7256, Test Loss: 3.1406, Test Accuracy: 26.95%\n",
            "2\n",
            "Epoch [62/100], Train Loss: 0.7285, Test Loss: 3.1589, Test Accuracy: 26.22%\n",
            "Adjusting learning rate...\n",
            "0\n",
            "Epoch [63/100], Train Loss: 0.7156, Test Loss: 3.1493, Test Accuracy: 26.15%\n",
            "1\n",
            "Epoch [64/100], Train Loss: 0.7093, Test Loss: 3.1432, Test Accuracy: 26.52%\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocess and load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=data_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "\n",
        "# Define the neural network architecture\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=100, img_h=100, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn1 = nn.BatchNorm2d(num_out_ch[0])  # Batch normalization after conv1\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn2 = nn.BatchNorm2d(num_out_ch[1])  # Batch normalization after conv2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with p=0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout(x)  # Apply dropout after pooling\n",
        "        x = self.fc(x.reshape(x.shape[0], -1))\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "num_classes = len(set(train_dataset._labels))\n",
        "model = MyCNN(num_channels=3, num_out_ch=[16, 32], img_w=224, img_h=224, num_classes=num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "val_losses = []\n",
        "best_test_loss = float(\"inf\")\n",
        "patience = 3\n",
        "bad_counter = 0\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {(100*correct_val / total_val):.2f}%')\n",
        "\n",
        "    # Early stopping and learning rate adjustment\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "        if bad_counter >= patience:\n",
        "            print(\"Adjusting learning rate...\")\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10\n",
        "            bad_counter = 0  # Reset bad_counter\n",
        "    print(bad_counter)\n",
        "\n",
        "print(f'Final Test Loss: {test_loss}, Final Test Accuracy: {(100 * correct / total):.2f}%')\n",
        "# Plot the training and test losses\n",
        "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Losses')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OPTIMAL MODEL with improved graphs and using validation set"
      ],
      "metadata": {
        "id": "CikLXx7oOiq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Preprocess and load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "val_dataset = Flowers102(root='./data', split='val', transform=data_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "\n",
        "# Define the neural network architecture\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=100, img_h=100, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn1 = nn.BatchNorm2d(num_out_ch[0])  # Batch normalization after conv1\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn2 = nn.BatchNorm2d(num_out_ch[1])  # Batch normalization after conv2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with p=0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout(x)  # Apply dropout after pooling\n",
        "        x = self.fc(x.reshape(x.shape[0], -1))\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "num_classes = len(set(train_dataset._labels))\n",
        "model = MyCNN(num_channels=3, num_out_ch=[16, 32], img_w=224, img_h=224, num_classes=num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "test_losses = []\n",
        "train_accuracy = []\n",
        "val_accuracy = []\n",
        "test_accuracy = []\n",
        "best_test_loss = float(\"inf\")\n",
        "patience = 3\n",
        "bad_counter = 0\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracy.append(100 * correct_train / total_train)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "    val_loss = val_loss / len(val_loader.dataset)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracy.append(100 * correct_val / total_val)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracy.append(100 * correct_test / total_test)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {(100*correct_val / total_val):.2f}%')\n",
        "\n",
        "    # Early stopping and learning rate adjustment\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "        if bad_counter >= patience:\n",
        "            print(\"Adjusting learning rate...\")\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10\n",
        "            bad_counter = 0  # Reset bad_counter\n",
        "    print(bad_counter)\n",
        "\n",
        "print(f'Final Test Loss: {test_loss}, Final Test Accuracy: {(100 * correct_test / total_test):.2f}%')\n",
        "\n",
        "# Plot the training and test losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n",
        "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Losses')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, epochs+1), train_accuracy, label='Train Accuracy')\n",
        "plt.plot(range(1, epochs+1), val_accuracy, label='Validation Accuracy')\n",
        "plt.plot(range(1, epochs+1), test_accuracy, label='Test Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "Kv4sGgFXLRIP",
        "outputId": "7416a972-d0b6-47dc-a8b8-55a8a3be07ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Train Loss: 4.8394, Validation Loss: 4.4025, Validation Accuracy: 6.18%\n",
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-35c44c4b575e>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mtotal_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/flowers102.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1278\u001b[0m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_saturation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mfn_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhue_factor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m                 \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    951\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjust_hue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/_functional_pil.py\u001b[0m in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HSV\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mnp_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdither\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjh_6ZA4EgMM"
      },
      "source": [
        "Cosine Annealing Test (FAILED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1NqgQkQBEe1j",
        "outputId": "b9f0b4c5-91a0-403f-d93c-0619714e0080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:12<00:00, 27558139.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 166603.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 13070358.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Train Loss: 4.9231, Test Loss: 4.4689, Test Accuracy: 5.12%\n",
            "Epoch [2/100], Train Loss: 4.3306, Test Loss: 4.2112, Test Accuracy: 7.68%\n",
            "Epoch [3/100], Train Loss: 3.9282, Test Loss: 4.0318, Test Accuracy: 10.60%\n",
            "Epoch [4/100], Train Loss: 3.6743, Test Loss: 3.9051, Test Accuracy: 12.38%\n",
            "Epoch [5/100], Train Loss: 3.4599, Test Loss: 3.7928, Test Accuracy: 13.47%\n",
            "Epoch [6/100], Train Loss: 3.3014, Test Loss: 3.7248, Test Accuracy: 15.60%\n",
            "Epoch [7/100], Train Loss: 3.1211, Test Loss: 3.6650, Test Accuracy: 15.06%\n",
            "Epoch [8/100], Train Loss: 2.9154, Test Loss: 3.6285, Test Accuracy: 16.18%\n",
            "Epoch [9/100], Train Loss: 2.8354, Test Loss: 3.5706, Test Accuracy: 17.35%\n",
            "Epoch [10/100], Train Loss: 2.7390, Test Loss: 3.5211, Test Accuracy: 18.33%\n",
            "Epoch [11/100], Train Loss: 2.5595, Test Loss: 3.4969, Test Accuracy: 18.28%\n",
            "Epoch [12/100], Train Loss: 2.5265, Test Loss: 3.4781, Test Accuracy: 18.10%\n",
            "Epoch [13/100], Train Loss: 2.4056, Test Loss: 3.4600, Test Accuracy: 18.95%\n",
            "Epoch [14/100], Train Loss: 2.2940, Test Loss: 3.4274, Test Accuracy: 18.54%\n",
            "Epoch [15/100], Train Loss: 2.1958, Test Loss: 3.4007, Test Accuracy: 20.46%\n",
            "Epoch [16/100], Train Loss: 2.0872, Test Loss: 3.3823, Test Accuracy: 20.31%\n",
            "Epoch [17/100], Train Loss: 2.0706, Test Loss: 3.3958, Test Accuracy: 20.28%\n",
            "Epoch [18/100], Train Loss: 2.0146, Test Loss: 3.3523, Test Accuracy: 22.13%\n",
            "Epoch [19/100], Train Loss: 1.9021, Test Loss: 3.3316, Test Accuracy: 21.58%\n",
            "Epoch [20/100], Train Loss: 1.8475, Test Loss: 3.3457, Test Accuracy: 20.74%\n",
            "Epoch [21/100], Train Loss: 1.7499, Test Loss: 3.3106, Test Accuracy: 21.56%\n",
            "Epoch [22/100], Train Loss: 1.7131, Test Loss: 3.3061, Test Accuracy: 22.52%\n",
            "Epoch [23/100], Train Loss: 1.6493, Test Loss: 3.3074, Test Accuracy: 22.87%\n",
            "Epoch [24/100], Train Loss: 1.5986, Test Loss: 3.2921, Test Accuracy: 22.20%\n",
            "Epoch [25/100], Train Loss: 1.5470, Test Loss: 3.2801, Test Accuracy: 23.37%\n",
            "Epoch [26/100], Train Loss: 1.5121, Test Loss: 3.2875, Test Accuracy: 23.22%\n",
            "Epoch [27/100], Train Loss: 1.4352, Test Loss: 3.2709, Test Accuracy: 23.52%\n",
            "Epoch [28/100], Train Loss: 1.3893, Test Loss: 3.2574, Test Accuracy: 23.52%\n",
            "Epoch [29/100], Train Loss: 1.3490, Test Loss: 3.2627, Test Accuracy: 23.47%\n",
            "Epoch [30/100], Train Loss: 1.3068, Test Loss: 3.2522, Test Accuracy: 23.52%\n",
            "Epoch [31/100], Train Loss: 1.2627, Test Loss: 3.2790, Test Accuracy: 23.39%\n",
            "Epoch [32/100], Train Loss: 1.2250, Test Loss: 3.2582, Test Accuracy: 23.91%\n",
            "Epoch [33/100], Train Loss: 1.2180, Test Loss: 3.2406, Test Accuracy: 23.53%\n",
            "Epoch [34/100], Train Loss: 1.1651, Test Loss: 3.2328, Test Accuracy: 24.49%\n",
            "Epoch [35/100], Train Loss: 1.1497, Test Loss: 3.2564, Test Accuracy: 23.09%\n",
            "Epoch [36/100], Train Loss: 1.1010, Test Loss: 3.2410, Test Accuracy: 24.00%\n",
            "Epoch [37/100], Train Loss: 1.0498, Test Loss: 3.2109, Test Accuracy: 24.82%\n",
            "Epoch [38/100], Train Loss: 1.0713, Test Loss: 3.2485, Test Accuracy: 23.79%\n",
            "Epoch [39/100], Train Loss: 1.0213, Test Loss: 3.2289, Test Accuracy: 23.97%\n",
            "Epoch [40/100], Train Loss: 0.9666, Test Loss: 3.2255, Test Accuracy: 25.39%\n",
            "Adjusting learning rate...\n",
            "Epoch [41/100], Train Loss: 0.9727, Test Loss: 3.2190, Test Accuracy: 25.03%\n",
            "Epoch [42/100], Train Loss: 0.8913, Test Loss: 3.2399, Test Accuracy: 24.23%\n",
            "Epoch [43/100], Train Loss: 0.8950, Test Loss: 3.2145, Test Accuracy: 24.77%\n",
            "Adjusting learning rate...\n",
            "Epoch [44/100], Train Loss: 0.9079, Test Loss: 3.2325, Test Accuracy: 24.90%\n",
            "Epoch [45/100], Train Loss: 0.9002, Test Loss: 3.2219, Test Accuracy: 25.01%\n",
            "Epoch [46/100], Train Loss: 0.8963, Test Loss: 3.2097, Test Accuracy: 25.17%\n",
            "Epoch [47/100], Train Loss: 0.9083, Test Loss: 3.2325, Test Accuracy: 24.39%\n",
            "Epoch [48/100], Train Loss: 0.9154, Test Loss: 3.2049, Test Accuracy: 25.37%\n",
            "Epoch [49/100], Train Loss: 0.9254, Test Loss: 3.2239, Test Accuracy: 25.42%\n",
            "Epoch [50/100], Train Loss: 0.8717, Test Loss: 3.1973, Test Accuracy: 25.83%\n",
            "Epoch [51/100], Train Loss: 0.9077, Test Loss: 3.2087, Test Accuracy: 24.80%\n",
            "Epoch [52/100], Train Loss: 0.9100, Test Loss: 3.2215, Test Accuracy: 25.03%\n",
            "Epoch [53/100], Train Loss: 0.8941, Test Loss: 3.2357, Test Accuracy: 24.61%\n",
            "Adjusting learning rate...\n",
            "Epoch [54/100], Train Loss: 0.8932, Test Loss: 3.2188, Test Accuracy: 25.45%\n",
            "Epoch [55/100], Train Loss: 0.9216, Test Loss: 3.2253, Test Accuracy: 24.62%\n",
            "Epoch [56/100], Train Loss: 0.9074, Test Loss: 3.2227, Test Accuracy: 25.21%\n",
            "Adjusting learning rate...\n",
            "Epoch [57/100], Train Loss: 0.8764, Test Loss: 3.2090, Test Accuracy: 25.06%\n",
            "Epoch [58/100], Train Loss: 0.8991, Test Loss: 3.2175, Test Accuracy: 24.96%\n",
            "Epoch [59/100], Train Loss: 0.8852, Test Loss: 3.2186, Test Accuracy: 25.63%\n",
            "Adjusting learning rate...\n",
            "Epoch [60/100], Train Loss: 0.9326, Test Loss: 3.2210, Test Accuracy: 25.11%\n",
            "Epoch [61/100], Train Loss: 0.8805, Test Loss: 3.2210, Test Accuracy: 25.65%\n",
            "Epoch [62/100], Train Loss: 0.8660, Test Loss: 3.2191, Test Accuracy: 25.26%\n",
            "Adjusting learning rate...\n",
            "Epoch [63/100], Train Loss: 0.8909, Test Loss: 3.2125, Test Accuracy: 25.17%\n",
            "Epoch [64/100], Train Loss: 0.9064, Test Loss: 3.2348, Test Accuracy: 24.98%\n",
            "Epoch [65/100], Train Loss: 0.9199, Test Loss: 3.2129, Test Accuracy: 25.16%\n",
            "Adjusting learning rate...\n",
            "Epoch [66/100], Train Loss: 0.8724, Test Loss: 3.2334, Test Accuracy: 25.03%\n",
            "Epoch [67/100], Train Loss: 0.8729, Test Loss: 3.2170, Test Accuracy: 25.01%\n",
            "Epoch [68/100], Train Loss: 0.8934, Test Loss: 3.2239, Test Accuracy: 25.63%\n",
            "Adjusting learning rate...\n",
            "Epoch [69/100], Train Loss: 0.8828, Test Loss: 3.2111, Test Accuracy: 24.91%\n",
            "Epoch [70/100], Train Loss: 0.9126, Test Loss: 3.1997, Test Accuracy: 25.22%\n",
            "Epoch [71/100], Train Loss: 0.9529, Test Loss: 3.2068, Test Accuracy: 25.37%\n",
            "Adjusting learning rate...\n",
            "Epoch [72/100], Train Loss: 0.9024, Test Loss: 3.2259, Test Accuracy: 24.95%\n",
            "Epoch [73/100], Train Loss: 0.9201, Test Loss: 3.2148, Test Accuracy: 25.42%\n",
            "Epoch [74/100], Train Loss: 0.9094, Test Loss: 3.2160, Test Accuracy: 24.87%\n",
            "Adjusting learning rate...\n",
            "Epoch [75/100], Train Loss: 0.8850, Test Loss: 3.2232, Test Accuracy: 25.11%\n",
            "Epoch [76/100], Train Loss: 0.8906, Test Loss: 3.2212, Test Accuracy: 25.76%\n",
            "Epoch [77/100], Train Loss: 0.8808, Test Loss: 3.2357, Test Accuracy: 24.67%\n",
            "Adjusting learning rate...\n",
            "Epoch [78/100], Train Loss: 0.8921, Test Loss: 3.2051, Test Accuracy: 24.88%\n",
            "Epoch [79/100], Train Loss: 0.9016, Test Loss: 3.2323, Test Accuracy: 24.85%\n",
            "Epoch [80/100], Train Loss: 0.9287, Test Loss: 3.2134, Test Accuracy: 25.14%\n",
            "Adjusting learning rate...\n",
            "Epoch [81/100], Train Loss: 0.8887, Test Loss: 3.2160, Test Accuracy: 25.08%\n",
            "Epoch [82/100], Train Loss: 0.9271, Test Loss: 3.2212, Test Accuracy: 24.57%\n",
            "Epoch [83/100], Train Loss: 0.8875, Test Loss: 3.2060, Test Accuracy: 25.14%\n",
            "Adjusting learning rate...\n",
            "Epoch [84/100], Train Loss: 0.9123, Test Loss: 3.2147, Test Accuracy: 25.19%\n",
            "Epoch [85/100], Train Loss: 0.9148, Test Loss: 3.2248, Test Accuracy: 25.11%\n",
            "Epoch [86/100], Train Loss: 0.9053, Test Loss: 3.2272, Test Accuracy: 24.98%\n",
            "Adjusting learning rate...\n",
            "Epoch [87/100], Train Loss: 0.9111, Test Loss: 3.2152, Test Accuracy: 25.03%\n",
            "Epoch [88/100], Train Loss: 0.8862, Test Loss: 3.2259, Test Accuracy: 24.88%\n",
            "Epoch [89/100], Train Loss: 0.9131, Test Loss: 3.2122, Test Accuracy: 25.68%\n",
            "Adjusting learning rate...\n",
            "Epoch [90/100], Train Loss: 0.9026, Test Loss: 3.2298, Test Accuracy: 24.61%\n",
            "Epoch [91/100], Train Loss: 0.9023, Test Loss: 3.2057, Test Accuracy: 25.35%\n",
            "Epoch [92/100], Train Loss: 0.9136, Test Loss: 3.2227, Test Accuracy: 25.66%\n",
            "Adjusting learning rate...\n",
            "Epoch [93/100], Train Loss: 0.9055, Test Loss: 3.2363, Test Accuracy: 25.16%\n",
            "Epoch [94/100], Train Loss: 0.9251, Test Loss: 3.2033, Test Accuracy: 25.79%\n",
            "Epoch [95/100], Train Loss: 0.9107, Test Loss: 3.2078, Test Accuracy: 25.11%\n",
            "Adjusting learning rate...\n",
            "Epoch [96/100], Train Loss: 0.9179, Test Loss: 3.2089, Test Accuracy: 25.35%\n",
            "Epoch [97/100], Train Loss: 0.8958, Test Loss: 3.2201, Test Accuracy: 25.03%\n",
            "Epoch [98/100], Train Loss: 0.8785, Test Loss: 3.2214, Test Accuracy: 25.66%\n",
            "Adjusting learning rate...\n",
            "Epoch [99/100], Train Loss: 0.9108, Test Loss: 3.2272, Test Accuracy: 24.61%\n",
            "Epoch [100/100], Train Loss: 0.8979, Test Loss: 3.2051, Test Accuracy: 25.06%\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAByuklEQVR4nO3deVwU9f8H8NfsAsu5y30fIiKgouKNmlpiXvlVu/1ZamVlaWp2+i3No6JvZpeVWn3Lb6lZmpqVpnjfN3iLKAqIHCLCch+78/tjYnXjEHBhYHk9H495yM7OzL53WJnXfuYznxFEURRBREREZCYUchdAREREZEoMN0RERGRWGG6IiIjIrDDcEBERkVlhuCEiIiKzwnBDREREZoXhhoiIiMwKww0RERGZFYYbIiIiMisMN0TNxIQJE9CqVat6rTtnzhwIgmDagpqYK1euQBAELFu2TO5SiEhmDDdEd0kQhFpNO3fulLvUFq9Vq1a1+l2ZKiC9//77WL9+fa2WrQhnH330kUlem6gls5C7AKLm7scffzR6/MMPPyAmJqbS/LCwsLt6nW+++QZ6vb5e67799tt488037+r1zcGnn36K/Px8w+ONGzfip59+wieffAJXV1fD/N69e5vk9d5//308/PDDGDVqlEm2R0S1w3BDdJeeeOIJo8cHDx5ETExMpfn/VFhYCFtb21q/jqWlZb3qAwALCwtYWPC/+z9DRnp6On766SeMGjWq3qf8iKjp4WkpokYwYMAAdOjQAceOHUO/fv1ga2uLf//73wCA3377DcOHD4e3tzdUKhWCgoIwf/586HQ6o238s8/N7acxvv76awQFBUGlUqF79+44cuSI0bpV9bkRBAFTpkzB+vXr0aFDB6hUKrRv3x5//fVXpfp37tyJbt26wdraGkFBQVi6dGmt+/Hs2bMHjzzyCPz9/aFSqeDn54eXX34ZRUVFld6fvb09UlNTMWrUKNjb28PNzQ2vvvpqpX2Rk5ODCRMmQKPRwNHREePHj0dOTs4da6mt5cuXo2vXrrCxsYGzszMef/xxpKSkGC2TkJCAhx56CJ6enrC2toavry8ef/xx5ObmApD2b0FBAf73v/8ZTndNmDDhrmvLzMzEM888Aw8PD1hbW6NTp0743//+V2m5VatWoWvXrnBwcIBarUZ4eDg+++wzw/NlZWWYO3cugoODYW1tDRcXF/Tt2xcxMTFG2zl//jwefvhhODs7w9raGt26dcOGDRuMlqnttogaC7/KETWSGzduYOjQoXj88cfxxBNPwMPDAwCwbNky2NvbY8aMGbC3t8f27dsxe/ZsaLVaLFiw4I7bXblyJfLy8vD8889DEAR8+OGHePDBB5GYmHjH1p69e/di7dq1ePHFF+Hg4IDPP/8cDz30EJKTk+Hi4gIAiI2NxZAhQ+Dl5YW5c+dCp9Nh3rx5cHNzq9X7Xr16NQoLC/HCCy/AxcUFhw8fxqJFi3D16lWsXr3aaFmdTofBgwejZ8+e+Oijj7B161YsXLgQQUFBeOGFFwAAoihi5MiR2Lt3LyZNmoSwsDCsW7cO48ePr1U9d/Lee+9h1qxZePTRRzFx4kRcv34dixYtQr9+/RAbGwtHR0eUlpZi8ODBKCkpwUsvvQRPT0+kpqbijz/+QE5ODjQaDX788UdMnDgRPXr0wHPPPQcACAoKuqvaioqKMGDAAFy8eBFTpkxBYGAgVq9ejQkTJiAnJwfTpk0DAMTExGDMmDEYOHAg/vOf/wAAzp07h3379hmWmTNnDqKjow01arVaHD16FMePH8egQYMAAGfOnEGfPn3g4+ODN998E3Z2dvjll18watQo/Prrrxg9enStt0XUqEQiMqnJkyeL//yv1b9/fxGAuGTJkkrLFxYWVpr3/PPPi7a2tmJxcbFh3vjx48WAgADD48uXL4sARBcXFzE7O9sw/7fffhMBiL///rth3jvvvFOpJgCilZWVePHiRcO8EydOiADERYsWGeaNGDFCtLW1FVNTUw3zEhISRAsLi0rbrEpV7y86OloUBEFMSkoyen8AxHnz5hktGxERIXbt2tXweP369SIA8cMPPzTMKy8vF++55x4RgPj999/fsaYKCxYsEAGIly9fFkVRFK9cuSIqlUrxvffeM1ru1KlTooWFhWF+bGysCEBcvXp1jdu3s7MTx48fX6taKn6fCxYsqHaZTz/9VAQgLl++3DCvtLRUjIyMFO3t7UWtViuKoihOmzZNVKvVYnl5ebXb6tSpkzh8+PAaaxo4cKAYHh5u9DnU6/Vi7969xeDg4Dpti6gx8bQUUSNRqVR46qmnKs23sbEx/JyXl4esrCzcc889KCwsxPnz5++43cceewxOTk6Gx/fccw8AIDEx8Y7rRkVFGbUmdOzYEWq12rCuTqfD1q1bMWrUKHh7exuWa9OmDYYOHXrH7QPG76+goABZWVno3bs3RFFEbGxspeUnTZpk9Piee+4xei8bN26EhYWFoSUHAJRKJV566aVa1VOTtWvXQq/X49FHH0VWVpZh8vT0RHBwMHbs2AEA0Gg0AIDNmzejsLDwrl+3tjZu3AhPT0+MGTPGMM/S0hJTp05Ffn4+du3aBQBwdHREQUFBjaeFHB0dcebMGSQkJFT5fHZ2NrZv345HH33U8LnMysrCjRs3MHjwYCQkJCA1NbVW2yJqbAw3RI3Ex8cHVlZWleafOXMGo0ePhkajgVqthpubm6EzckX/jZr4+/sbPa4IOjdv3qzzuhXrV6ybmZmJoqIitGnTptJyVc2rSnJyMiZMmABnZ2dDP5r+/fsDqPz+rK2tK53uur0eAEhKSoKXlxfs7e2NlgsJCalVPTVJSEiAKIoIDg6Gm5ub0XTu3DlkZmYCAAIDAzFjxgx8++23cHV1xeDBg/Hll1/W6vd1N5KSkhAcHAyFwvhPd8WVeElJSQCAF198EW3btsXQoUPh6+uLp59+ulJfqnnz5iEnJwdt27ZFeHg4XnvtNZw8edLw/MWLFyGKImbNmlVpX7zzzjsAYNgfd9oWUWNjnxuiRnJ7C0aFnJwc9O/fH2q1GvPmzUNQUBCsra1x/PhxvPHGG7W69FupVFY5XxTFBl23NnQ6HQYNGoTs7Gy88cYbCA0NhZ2dHVJTUzFhwoRK76+6ehqLXq+HIAjYtGlTlbXcHqgWLlyICRMm4LfffsOWLVswdepUREdH4+DBg/D19W3Msitxd3dHXFwcNm/ejE2bNmHTpk34/vvvMW7cOEPn4379+uHSpUuG+r/99lt88sknWLJkCSZOnGj43bz66qsYPHhwla9TEXDvtC2ixsZwQySjnTt34saNG1i7di369etnmH/58mUZq7rF3d0d1tbWuHjxYqXnqpr3T6dOncKFCxfwv//9D+PGjTPMv5uraAICArBt2zbk5+cbhY34+Ph6b7NCUFAQRFFEYGAg2rZte8flw8PDER4ejrfffhv79+9Hnz59sGTJErz77rsAYPJRoQMCAnDy5Eno9Xqj1puK05cBAQGGeVZWVhgxYgRGjBgBvV6PF198EUuXLsWsWbMMocTZ2RlPPfUUnnrqKeTn56Nfv36YM2cOJk6ciNatWwOQTntFRUXdsbaatkXU2HhaikhGFa0Dt7eUlJaW4quvvpKrJCNKpRJRUVFYv349rl27Zph/8eJFbNq0qVbrA8bvTxRFo0uS62rYsGEoLy/H4sWLDfN0Oh0WLVpU721WePDBB6FUKjF37txKrVeiKOLGjRsAAK1Wi/LycqPnw8PDoVAoUFJSYphnZ2dn0kvUhw0bhvT0dPz888+GeeXl5Vi0aBHs7e0Np/sq6qygUCjQsWNHADDU989l7O3t0aZNG8Pz7u7uGDBgAJYuXYq0tLRKtVy/ft3w8522RdTY2HJDJKPevXvDyckJ48ePx9SpUyEIAn788UeTnRYyhTlz5mDLli3o06cPXnjhBeh0OnzxxRfo0KED4uLialw3NDQUQUFBePXVV5Gamgq1Wo1ff/21Vv2BqjNixAj06dMHb775Jq5cuYJ27dph7dq1JunvEhQUhHfffRczZ87ElStXMGrUKDg4OODy5ctYt24dnnvuObz66qvYvn07pkyZgkceeQRt27ZFeXk5fvzxRyiVSjz00EOG7XXt2hVbt27Fxx9/DG9vbwQGBqJnz5411rBt2zYUFxdXmj9q1Cg899xzWLp0KSZMmIBjx46hVatWWLNmDfbt24dPP/0UDg4OAICJEyciOzsb9913H3x9fZGUlIRFixahc+fOhv457dq1w4ABA9C1a1c4Ozvj6NGjWLNmDaZMmWJ4zS+//BJ9+/ZFeHg4nn32WbRu3RoZGRk4cOAArl69ihMnTtR6W0SNSp6LtIjMV3WXgrdv377K5fft2yf26tVLtLGxEb29vcXXX39d3Lx5swhA3LFjh2G56i4Fr+rSYQDiO++8Y3hc3aXgkydPrrRuQEBApcuXt23bJkZERIhWVlZiUFCQ+O2334qvvPKKaG1tXc1euOXs2bNiVFSUaG9vL7q6uorPPvus4ZLz2y/bHj9+vGhnZ1dp/apqv3Hjhvjkk0+KarVa1Gg04pNPPmm4PPtuLgWv8Ouvv4p9+/YV7ezsRDs7OzE0NFScPHmyGB8fL4qiKCYmJopPP/20GBQUJFpbW4vOzs7ivffeK27dutVoO+fPnxf79esn2tjYiABqvCy84vdZ3fTjjz+KoiiKGRkZ4lNPPSW6urqKVlZWYnh4eKX3vGbNGvH+++8X3d3dRSsrK9Hf3198/vnnxbS0NMMy7777rtijRw/R0dFRtLGxEUNDQ8X33ntPLC0tNdrWpUuXxHHjxomenp6ipaWl6OPjIz7wwAPimjVr6rwtosYiiGIT+opIRM3GqFGjePkvETVJ7HNDRHf0z1slJCQkYOPGjRgwYIA8BRER1YAtN0R0R15eXpgwYQJat26NpKQkLF68GCUlJYiNjUVwcLDc5RERGWGHYiK6oyFDhuCnn35Ceno6VCoVIiMj8f777zPYEFGTxJYbIiIiMivsc0NERERmheGGiIiIzEqL63Oj1+tx7do1ODg4mHxodCIiImoYoigiLy8P3t7elW4e+08tLtxcu3YNfn5+cpdBRERE9ZCSknLHm9O2uHBTMTx5SkoK1Gq1zNUQERFRbWi1Wvj5+RmO4zVpceGm4lSUWq1muCEiImpmatOlhB2KiYiIyKww3BAREZFZYbghIiIisyJrn5s5c+Zg7ty5RvNCQkJw/vz5atdZvXo1Zs2ahStXriA4OBj/+c9/MGzYsIYulYiImiidToeysjK5yyATsLKyuuNl3rUhe4fi9u3bY+vWrYbHFhbVl7R//36MGTMG0dHReOCBB7By5UqMGjUKx48fR4cOHRqjXCIiaiJEUUR6ejpycnLkLoVMRKFQIDAwEFZWVne1HdnDjYWFBTw9PWu17GeffYYhQ4bgtddeAwDMnz8fMTEx+OKLL7BkyZKGLJOIiJqYimDj7u4OW1tbDszazFUMspuWlgZ/f/+7+n3KHm4SEhLg7e0Na2trREZGIjo6Gv7+/lUue+DAAcyYMcNo3uDBg7F+/fpGqJSIiJoKnU5nCDYuLi5yl0Mm4ubmhmvXrqG8vByWlpb13o6s4aZnz55YtmwZQkJCkJaWhrlz5+Kee+7B6dOnqxykJz09HR4eHkbzPDw8kJ6eXu1rlJSUoKSkxPBYq9Wa7g0QEZEsKvrY2NraylwJmVLF6SidTtd8w83QoUMNP3fs2BE9e/ZEQEAAfvnlFzzzzDMmeY3o6OhKnZaJiMg88FSUeTHV77NJXQru6OiItm3b4uLFi1U+7+npiYyMDKN5GRkZNfbZmTlzJnJzcw1TSkqKSWsmIiKipqVJhZv8/HxcunQJXl5eVT4fGRmJbdu2Gc2LiYlBZGRktdtUqVSGWy3wlgtERGSOWrVqhU8//VTuMpoMWcPNq6++il27duHKlSvYv38/Ro8eDaVSiTFjxgAAxo0bh5kzZxqWnzZtGv766y8sXLgQ58+fx5w5c3D06FFMmTJFrrdARERUa4Ig1DjNmTOnXts9cuQInnvuubuqbcCAAZg+ffpdbaOpkLXPzdWrVzFmzBjcuHEDbm5u6Nu3Lw4ePAg3NzcAQHJystFgPr1798bKlSvx9ttv49///jeCg4Oxfv36JjHGjU4v4kZ+CYrKdAhwsZO7HCIiaoLS0tIMP//888+YPXs24uPjDfPs7e0NP4uiCJ1OV+P4bxUqjpskkbXlZtWqVbh27RpKSkpw9epVrFq1CkFBQYbnd+7ciWXLlhmt88gjjyA+Ph4lJSU4ffp0kxmd+GDiDfR4fxsm/u+o3KUQEVET5enpaZg0Gg0EQTA8Pn/+PBwcHLBp0yZ07doVKpUKe/fuxaVLlzBy5Eh4eHjA3t4e3bt3Nxr8Fqh8WkoQBHz77bcYPXo0bG1tERwcjA0bNtxV7b/++ivat28PlUqFVq1aYeHChUbPf/XVVwgODoa1tTU8PDzw8MMPG55bs2YNwsPDYWNjAxcXF0RFRaGgoOCu6qmJ7OPcmAtXexUAICu/5A5LEhFRQxBFEUVlOlle28ZSabIrfd5880189NFHaN26NZycnJCSkoJhw4bhvffeg0qlwg8//IARI0YgPj6+2nHhAGDu3Ln48MMPsWDBAixatAhjx45FUlISnJ2d61zTsWPH8Oijj2LOnDl47LHHsH//frz44otwcXHBhAkTcPToUUydOhU//vgjevfujezsbOzZsweA1Fo1ZswYfPjhhxg9ejTy8vKwZ88eiKJY7310Jww3JuLmIIWbm4VlKC3Xw8qiSfXVJiIye0VlOrSbvVmW1z47bzBsrUxzSJ03bx4GDRpkeOzs7IxOnToZHs+fPx/r1q3Dhg0bauxzOmHCBEMf1vfffx+ff/45Dh8+jCFDhtS5po8//hgDBw7ErFmzAABt27bF2bNnsWDBAkyYMAHJycmws7PDAw88AAcHBwQEBCAiIgKAFG7Ky8vx4IMPIiAgAAAQHh5e5xrqgkdgE3G0sYSFQkrtNwrYekNERPXTrVs3o8f5+fl49dVXERYWBkdHR9jb2+PcuXNITk6ucTsdO3Y0/GxnZwe1Wo3MzMx61XTu3Dn06dPHaF6fPn2QkJAAnU6HQYMGISAgAK1bt8aTTz6JFStWoLCwEADQqVMnDBw4EOHh4XjkkUfwzTff4ObNm/Wqo7bYcmMiCoUAV3sV0rXFuJ5XAi+NjdwlERG1KDaWSpydN1i21zYVOzvji1JeffVVxMTE4KOPPkKbNm1gY2ODhx9+GKWlpTVu558j/AqCAL1eb7I6b+fg4IDjx49j586d2LJlC2bPno05c+bgyJEjcHR0RExMDPbv348tW7Zg0aJFeOutt3Do0CEEBgY2SD1suTGhilNT7HdDRNT4BEGArZWFLFNDjpS8b98+TJgwAaNHj0Z4eDg8PT1x5cqVBnu9qoSFhWHfvn2V6mrbti2USinYWVhYICoqCh9++CFOnjyJK1euYPv27QCk302fPn0wd+5cxMbGwsrKCuvWrWuwetlyY0Ku9tI9Ma7nMdwQEZFpBAcHY+3atRgxYgQEQcCsWbMarAXm+vXriIuLM5rn5eWFV155Bd27d8f8+fPx2GOP4cCBA/jiiy/w1VdfAQD++OMPJCYmol+/fnBycsLGjRuh1+sREhKCQ4cOYdu2bbj//vvh7u6OQ4cO4fr16wgLC2uQ9wAw3JhURcsNww0REZnKxx9/jKeffhq9e/eGq6sr3njjjQa7CfTKlSuxcuVKo3nz58/H22+/jV9++QWzZ8/G/Pnz4eXlhXnz5mHChAkApNsnrV27FnPmzEFxcTGCg4Px008/oX379jh37hx2796NTz/9FFqtFgEBAVi4cKHR/SVNTRAb8lqsJkir1UKj0SA3N9fkt2JYsPk8vtxxCeMjAzB3pPwDCxIRmavi4mJcvnwZgYGBsLa2lrscMpGafq91OX6zz40JuRnGuqm5kxcRERE1HIYbE3LlaSkiIiLZMdyYUEXLzXVeLUVERCQbhhsTYodiIiIi+THcmFBFuMkvKUdRqTz3NyEiImrpGG5MyF5lAdXf95TiQH5ERETyYLgxIUEQDK03mTw1RUREJAuGGxNjvxsiIiJ5MdyY2K2xbhhuiIiI5MBwY2Ic64aIiEheDDcmxrFuiIioOoIg1DjNmTPnrra9fv16ky3XnPHGmSbGPjdERFSdtLQ0w88///wzZs+ejfj4eMM8e3t7OcoyO2y5MbGKcMM+N0RE9E+enp6GSaPRQBAEo3mrVq1CWFgYrK2tERoaiq+++sqwbmlpKaZMmQIvLy9YW1sjICAA0dHRAIBWrVoBAEaPHg1BEAyP60qv12PevHnw9fWFSqVC586d8ddff9WqBlEUMWfOHPj7+0OlUsHb2xtTp06t3466S2y5MTFXe7bcEBHJQhSBskJ5XtvSFhCEu9rEihUrMHv2bHzxxReIiIhAbGwsnn32WdjZ2WH8+PH4/PPPsWHDBvzyyy/w9/dHSkoKUlJSAABHjhyBu7s7vv/+ewwZMgRKpbJeNXz22WdYuHAhli5dioiICHz33Xf417/+hTNnziA4OLjGGn799Vd88sknWLVqFdq3b4/09HScOHHirvZJfTHcmJj7baelRFGEcJcfdiIiqqWyQuB9b3le+9/XACu7u9rEO++8g4ULF+LBBx8EAAQGBuLs2bNYunQpxo8fj+TkZAQHB6Nv374QBAEBAQGGdd3c3AAAjo6O8PT0rHcNH330Ed544w08/vjjAID//Oc/2LFjBz799FN8+eWXNdaQnJwMT09PREVFwdLSEv7+/ujRo0e9a7kbPC1lYhUtNyXleuSVlMtcDRERNQcFBQW4dOkSnnnmGdjb2xumd999F5cuXQIATJgwAXFxcQgJCcHUqVOxZcsWk9ag1Wpx7do19OnTx2h+nz59cO7cuTvW8Mgjj6CoqAitW7fGs88+i3Xr1qG8XJ7jIFtuTMzGSgkHlQXySspxPa8EamtLuUsiImoZLG2lFhS5Xvsu5OfnAwC++eYb9OzZ0+i5ilNMXbp0weXLl7Fp0yZs3boVjz76KKKiorBmzZq7eu26qKkGPz8/xMfHY+vWrYiJicGLL76IBQsWYNeuXbC0bNxjIcNNA3B1UCGvpBxZeSUIcmPPdyKiRiEId31qSC4eHh7w9vZGYmIixo4dW+1yarUajz32GB577DE8/PDDGDJkCLKzs+Hs7AxLS0vodPW/abNarYa3tzf27duH/v37G+bv27fP6PRSTTXY2NhgxIgRGDFiBCZPnozQ0FCcOnUKXbp0qXdd9cFw0wDc7FW4nFXAsW6IiKjW5s6di6lTp0Kj0WDIkCEoKSnB0aNHcfPmTcyYMQMff/wxvLy8EBERAYVCgdWrV8PT0xOOjo4ApCumtm3bhj59+kClUsHJyana17p8+TLi4uKM5gUHB+O1117DO++8g6CgIHTu3Bnff/894uLisGLFCgCosYZly5ZBp9OhZ8+esLW1xfLly2FjY2PUL6exMNw0AI51Q0REdTVx4kTY2tpiwYIFeO2112BnZ4fw8HBMnz4dAODg4IAPP/wQCQkJUCqV6N69OzZu3AiFQuo+u3DhQsyYMQPffPMNfHx8cOXKlWpfa8aMGZXm7dmzB1OnTkVubi5eeeUVZGZmol27dtiwYQOCg4PvWIOjoyM++OADzJgxAzqdDuHh4fj999/h4uJi8n11J4IoimKjv6qMtFotNBoNcnNzoVarG+Q15mw4g2X7r+DFAUF4fUhog7wGEVFLVlxcjMuXLyMwMBDW1tZyl0MmUtPvtS7Hb14t1QBc7a0AcCA/IiIiOTDcNACeliIiIpJPkwk3H3zwAQRBMJxbrMqyZcsq3WSsKTZHGsINW26IiIgaXZPoUHzkyBEsXboUHTt2vOOyarXa6CZjTXEEYDd7KXCx5YaIiKjxyd5yk5+fj7Fjx+Kbb76p8bK1Cv+8yZiHh0cjVFk3FS03N/JLode3qP7aRESNqoVdE2P2TPX7lD3cTJ48GcOHD0dUVFStls/Pz0dAQAD8/PwwcuRInDlzpsblS0pKoNVqjaaG5vJ3h+JyvYicorIGfz0iopamYsTbwkKZbpRJDaK0tBQA6n3jzwqynpZatWoVjh8/jiNHjtRq+ZCQEHz33Xfo2LEjcnNz8dFHH6F37944c+YMfH19q1wnOjoac+fONWXZd2SpVMDJ1hI3C8twPa8EznZWjfr6RETmTqlUwtHREZmZmQAAW1vbJtlNgWpPr9fj+vXrsLW1hYXF3cUT2cJNSkoKpk2bhpiYmFp3Co6MjERkZKThce/evREWFoalS5di/vz5Va4zc+ZMo8GKtFot/Pz87q74qtxMAs6sAxRKoPdLcHNQGcJNiKeD6V+PiKiFq7j7dUXAoeZPoVDA39//roOqbOHm2LFjyMzMNLrfhE6nw+7du/HFF1+gpKTkjs1SlpaWiIiIwMWLF6tdRqVSQaVSmazuauUkAVvfATR+hnBzISOfY90QETUQQRDg5eUFd3d3lJWxC4A5sLKyMoy4fDdkCzcDBw7EqVOnjOY99dRTCA0NxRtvvFGr8206nQ6nTp3CsGHDGqrM2vOOACAAuSlAXgZc7TnWDRFRY1AqlXfdR4PMi2zhxsHBAR06dDCaZ2dnBxcXF8P8cePGwcfHB9HR0QCAefPmoVevXmjTpg1ycnKwYMECJCUlYeLEiY1efyUqB8AtFLh+Dkg9Cjf7QAAc64aIiKixNYlxbqqTnJxs1Dx18+ZNPPvss0hPT4eTkxO6du2K/fv3o127djJWeRvfrn+Hm2Nwc5DuKcWWGyIiosbVpMLNzp07a3z8ySef4JNPPmm8gurKpxsQuxy4ehRu4U8D4P2liIiIGpvs49yYFZ+u0r/XYuFqJ43BwJYbIiKixsVwY0ru7QALG6BECx/dVQAMN0RERI2N4caUlBaAd2cAgLv2NAAgu7AUZTq9jEURERG1LAw3pvb3qSm7rBNQKgSIIpBdUCpzUURERC0Hw42p+XYDAChSjxpuu8BTU0RERI2H4cbUKjoVZ5yBj530I8e6ISIiajwMN6am8QPs3AF9ObqqUgAA17UMN0RERI2F4cbUBMFwaipCId3zKjWnSM6KiIiIWhSGm4bgI90MNKT8AgAgObtQzmqIiIhaFIabhuAjtdz4FJwFACTdKJCzGiIiohalSd1+wWz83XJjW3gVztAiOdtK5oKIiIhaDrbcNARrDeDaFgDQSXEJWfmlyC8pl7koIiKiloHhpqH8fWoq0ioRAJB8g/1uiIiIGgPDTUP5+9RUd8vLAIDkbPa7ISIiagwMNw3l78vBQ3QXAIhIYssNERFRo2C4aSgeHQClCrb6fAQK6Uji5eBERESNguGmoSgtAa9OAIAuQgL73BARETUShpuG1KovAGCAMg5J7HNDRETUKBhuGlLIMABAf8UJXM/JR5lOL3NBRERE5o/hpiH5dIVo5w61UIRuOIvUm7zHFBERUUNjuGlICgWEkCEAgEGKo+xUTERE1AgYbhpayHAAQJTyOJKz8mUuhoiIyPwx3DS01v1RqrCGj3ADxVfj5K6GiIjI7DHcNDRLG6S7RgIAPNJ2yFwMERGR+WO4aQQFgfcDAMJy98hcCRERkfljuGkENu2HQycKCNYnQsxJkbscIiIis8Zw0wi8vf1wXGwLAMg/+bvM1RAREZk3hptGYGWhwGGrngAA/fmNMldDRERk3hhuGskl5/4AAIe0A0CxVuZqiIiIzBfDTSNRebbFJb0XFGI5cHGr3OUQERGZrSYTbj744AMIgoDp06fXuNzq1asRGhoKa2trhIeHY+PG5nGax9/ZDjH6btKD+E3yFkNERGTGmkS4OXLkCJYuXYqOHTvWuNz+/fsxZswYPPPMM4iNjcWoUaMwatQonD59upEqrb8AF1vE6LpIDy5sBkp5KwYiIqKGIHu4yc/Px9ixY/HNN9/AycmpxmU/++wzDBkyBK+99hrCwsIwf/58dOnSBV988UUjVVt//s62OC4GIwUeQEkucPJnuUsiIiIyS7KHm8mTJ2P48OGIioq647IHDhyotNzgwYNx4MCBatcpKSmBVqs1muQQ4GILEQp8XyYN6IdDSwBRlKUWIiIicyZruFm1ahWOHz+O6OjoWi2fnp4ODw8Po3keHh5IT0+vdp3o6GhoNBrD5Ofnd1c115eDtSWc7aywWtcfOks74Pp5IJG3YyAiIjI12cJNSkoKpk2bhhUrVsDa2rrBXmfmzJnIzc01TCkp8o0Q7O9sizzYIsV/tDTj4BLZaiEiIjJXsoWbY8eOITMzE126dIGFhQUsLCywa9cufP7557CwsIBOp6u0jqenJzIyMozmZWRkwNPTs9rXUalUUKvVRpNcAlxsAQD7XR4GIAAJm4Ebl2Srh4iIyBzJFm4GDhyIU6dOIS4uzjB169YNY8eORVxcHJRKZaV1IiMjsW3bNqN5MTExiIyMbKyy70qAsxRuThW7AMEVfW+WylgRERGR+bGQ64UdHBzQoUMHo3l2dnZwcXExzB83bhx8fHwMfXKmTZuG/v37Y+HChRg+fDhWrVqFo0eP4uuvv270+uvD38UOAJB0oxC4b5LUchO3ArjvLcBaI3N1RERE5kH2q6VqkpycjLS0NMPj3r17Y+XKlfj666/RqVMnrFmzBuvXr68UkpqqitNSSTcKgdb3Am6hQGk+ELtC5sqIiIjMhyCKLet6ZK1WC41Gg9zc3Ebvf5OVX4Ju726FIACn5gyG/akfgT+mA44BwNRYQFH5VBwRERHV7fjdpFtuzI2rvQo+jjYQReDk1Ryg42OAjROQk8RbMhAREZkIw00j6+znCACITc4BrGyBrhOkJ/Z+wkH9iIiITIDhppFF+DsCAOJScqQZvV4ELGyA1KMc1I+IiMgEGG4a2e0tN6IoAvbut1pvdn3I1hsiIqK7xHDTyDr4aGChEJCVX4LUnCJpZp9pgFIFJB8AruyVt0AiIqJmjuGmkVlbKhHmJfXyNpyaUnsBXZ6Uft79oTyFERERmQmGGxlU9LuJTc65NbPPdEBhCVzeDSQflKMsIiIis8BwI4OKfjeGlhsAcPQDOv+f9PMutt4QERHVF8ONDCrCzanUXJSW62890fdlQFACl7YBV4/JUxwREVEzx3Ajg0BXO2hsLFFarsf5dO2tJ5wDpYH9APa9ISIiqieGGxkIgmA8mN/t7nkFEBTAhb+AE6savTYiIqLmjuFGJpUG86vg2kYKOACwYSqQerxR6yIiImruGG5kUmWn4goD/g20HQLoSoCfnwDyMxu1NiIiouaM4UYmFeHmclYBbhaUGj+pUAAPfg24BAPaVODnJ4Hy0sobISIiokoYbmTiaGuF1q52AIC4qzmVF7DWAGN+AlRqIOUgsOn1xi2QiIiomWK4kVG1nYoruAYDD/0XgAAc+x44/E1jlUZERNRsMdzIqNpOxbdrez8wcJb088bXgNNrG7wuIiKi5ozhRkad/ZwAAHHJN6HX13A38L4zgG5PAxCBtc8Bl7Y3ToFERETNEMONjEK9HKCyUEBbXI7LNwqqX1AQgGEfAe1HA/oyYNUTwNWjjVcoERFRM8JwIyNLpQLhPhoAQFx1/W4qKJTA6KVA63uBsgJgxcPA9fiGL5KIiKiZYbiRWZcA6dTU0aTsOy9soQIeWw74dAWKbgI/jAQu72ngComIiJoXhhuZ9WrtDAA4cOlG7VZQ2QNj1wBuoUBeGvC/B4A/XwVK8huwSiIiouaD4UZm3Vs5Q6kQcOVGIVJzimq3kq0zMHEr0PUp6fGRb4DFkUDiroYrlIiIqJlguJGZg7Wlod9NrVtvAEDlAIz4FHhyPaDxB3KSgR/+BWx/FxBruPKKiIjIzDHcNAG9g1wA1DHcVAi6F3hxP9DtGenx7gXA7o9MWB0REVHzwnDTBEQawk0WxPq0uqgcgAc+Bga/Lz3e8S5w4CsTVkhERNR8MNw0Ad0CnGGpFHAttxhJNwrrv6HIydIdxQFg80zg2P9MUyAREVEzwnDTBNhYKRHhL10SfiCxHqembtf/daD3S9LPv08DTq25y+qIiIiaF4abJiKytXRqan99+t3cThCAQfONb9dw4ue7L5CIiKiZYLhpIm7vVFyvfje3EwRg2EKg0/8Bog5Y9xyw73MTVElERNT0yRpuFi9ejI4dO0KtVkOtViMyMhKbNm2qdvlly5ZBEASjydrauhErbjid/R2hslAgK78EFzNNMCCfQgGM/BLoNVl6HDML+OvfgF5/99smIiJqwmQNN76+vvjggw9w7NgxHD16FPfddx9GjhyJM2fOVLuOWq1GWlqaYUpKSmrEihuOykKJ7q2k0Yrv+tRUBYUCGPI+cP+70uODXwJrnwXKS02zfSIioiZI1nAzYsQIDBs2DMHBwWjbti3ee+892Nvb4+DBg9WuIwgCPD09DZOHh0cjVtywKi4J338py7Qb7v0SMPprQGEBnF4DfD0AiPsJKC8x7esQERE1AU2mz41Op8OqVatQUFCAyMjIapfLz89HQEAA/Pz87tjK09xUhJuDidnQ6008ynCnx4D/+wVQqYHMM8D6ScCn4cCuD4H866Z9LSIiIhnJHm5OnToFe3t7qFQqTJo0CevWrUO7du2qXDYkJATfffcdfvvtNyxfvhx6vR69e/fG1atXq91+SUkJtFqt0dRUdfTRwF5lgdyiMpxNa4A62wwEpp0ABr4DOHgD+RnAjveAT9oBP/2fdNl4aYHpX5eIiKgRCeJdX5pzd0pLS5GcnIzc3FysWbMG3377LXbt2lVtwLldWVkZwsLCMGbMGMyfP7/KZebMmYO5c+dWmp+bmwu1Wn3X9Zva08uOYPv5TLw1LAzP9mvdcC+kKwPO/gYc+BK4dvzWfEtboO1goP2DQJsowMq24WogIiKqJa1WC41GU6vjt+zh5p+ioqIQFBSEpUuX1mr5Rx55BBYWFvjpp5+qfL6kpAQlJbf6lmi1Wvj5+TXZcPPN7kS8t/Ec7gt1x3cTujf8C4oikHkWOP0rcHotcPPyrecs7YC29wPtRgLB9wNWdg1fDxERURXqEm4sGqmmWtPr9UZhpCY6nQ6nTp3CsGHDql1GpVJBpVKZqrwGV9Hv5lDiDZTp9LBUNvCZQ0EAPNpL032zgLQ4Keic/U260/iZddJkYQNEvgjc8wpDDhERNWmyhpuZM2di6NCh8Pf3R15eHlauXImdO3di8+bNAIBx48bBx8cH0dHRAIB58+ahV69eaNOmDXJycrBgwQIkJSVh4sSJcr4Nk2rnpYarvRWy8kux72IWBoS4N96LCwLgHSFNg+YD12KlkHN2PXDzCrBnIXBiFTD4PaDdKGl5IiKiJkbWDsWZmZkYN24cQkJCMHDgQBw5cgSbN2/GoEGDAADJyclIS0szLH/z5k08++yzCAsLw7Bhw6DVarF///5a9c9pLhQKAcPCvQAAG05ck68QQQB8ugCD5gJT44DHVgCO/oA2FVg9AfjfCCDjrHz1ERERVaPJ9blpaHU5ZyeXo1ey8fCSA7BXWeDo21GwtlTKXZKkrAjY9xmw9xOgvBiAALQfLZ2q8uwgd3VERGTG6nL8lv1ScKqsi78TvDXWyC8px47zmXKXc4ulDTDgTWDyISBsBAAROLMWWNJHupQ89fgdN0FERNTQGG6aIIVCwIhO3gBkPjVVHadWwGPLgUn7pJYbCED8n8A390qjH+/9VOqjU0EUpcexK4DNbwGJO2UomoiIWgqelmqiTqfm4oFFe6GyUODo21FwsLaUu6TqXb8A7P0YOPmLdBfyCt4RgHMQkHwQ0P5joMUBM4F+r0v3vyIiIroDnpYyA+291WjtZoeScj1izmbIXU7N3NoCo5cAr8QDD3wCBPYDBIV0tdXpNVKwUVgAvj2A0AekdXZGA6vGAEU5spZORETmhy03TdinWy/g060JGBDihmVP9ZC7nLrJzwTO/Q4UZAF+PaSpYnycuJXAHy9LnZKdW0tXYnmYzxVvRERkes16hOKG1pzCTeL1fNy3cBcsFAIOvxUFZzsruUsynWtxwM9PArnJgIW1NApy5/8DWvUzPlVVnAsk7QcKrkvLWGtkK5mIiOTDcFOD5hRuAOCBRXtwOlWLd0d1wBO9AuQux7QKbgBrJwKXtt+ap/GX7mCuLwcu75ZObYl66TkHL2DYgr+v1CIiopaEfW7MyL+a8lVTd8vOBXhiLTBxG9DtaUClkVpydi+QxtJJPSYFG+fWgGMAkJcG/PwEsGosoE278/aJiKhFYstNE5eaU4Q+H2yHIAD737wPXhobuUtqOGVFwPk/pVs+WNlLHZMD7wE0vtJzuxdIgwjqywGVGoh4ArD3AOzcADtXwMYJ0OsAXal013NdqfScdwSgbHK3USMiojrgaakaNLdwAwCPLNmPI1du4q1hYXi2X2u5y5FX+mng96lSq05tWWuA1gOAoIFAm4FSWCIiomalWd8VnCob0ckbR67cxF9n0hluPDsAz8RIY+qknwIKs6QrsgpvAMU50iXnSitAaQkoLIEbF6X5Z3+TJkC6R5ZPN8C3uzQ5eAA3k4Cbl6XBBnNTpcvb2w4F3MN4g1AiomaGLTfNQFpuESKjpVNTR96Kgqu9Su6Smg+9TrotxKVtwMWtt/rx1JajvxRy2g4G/Hvdupy9rm5ckgY6TNwN+PcEOo8FAvtzEEMiolriaakaNMdwA9y6aurDhzvi0W5+cpfTfBVrgWvHgatH/56OSJebO/pLt5VwaiVdlXX1MJC4C9CV3FpXYQF4dwFa9QEC+kiXsOdn3JpKCwG3EMCrE+DRXgpC1+OB3R9Jgxn+M1SpfYHOY4BOYwCXoLq9j/JSqXWKrUpE1EIw3NSguYabigH97m/nga/HdZO7HPMhitJUVQtKaQFwaQdwYRNwaWflW0jUSACcAqTTXfj7v1jw/VIn6MRdUtgpzr21uHt76RL3dv8C3NtVHVpEEUjaBxxaInW8tnMHgu6T+hG1vle6+qwmOcnAlb3SOg6edXgvRETyY7ipQXMNNxX3mrKxVCJ29iBYWyrlLqllEUUgJwm4sk8KGCmHAAjS1VoOHoC9p9SSknEGSD8pteRUCH0A6PeqdNVWhbJi4Pwf0mjNiTuN78nlFAh4d5YugXduLd2f60YCcGgpkHG6mgIFwK8n0P91Kez8s/bj/5NuWlqaL90aI7AfEP6IFKjqMjBisVa6E/yVfUBAb6nVydK6+mWt7ABFHT6roii1cNVlnfrKSZFa8VyCm3ffKr0eSD8hfQbVXtUvV5AlfUab80CYJXnS/z07N6mFtDqN+Tlqam4mSaffXdtKfRTNCMNNDZpruBFFEb0/2I603GJ8N6Eb7gv1kLskqklehhRENH5S5+SaFGYDF/6SbldxcZvxqbB/srQFOj0OdH0KKMqW+hFd3A5knrm1TOt7gUHzAK+O0nhAG14CLsZIzzl4A3m3jZmkVEl/AK0dpYOetQawcQTUPlLtGl9pSj8FxC6XOmWXF91a384N6DkJ6P6MdCl+diJwdgNwboP0B9bCRjpF59VJqsers/RY+Y8bwRblACd+Ao78V+oE3uEhKai5hVTeB9mJQMZZoFVfqdbayssAkvZKg0Mm7pI6kFdwagWEDAdCh0mnHvMzgNwUIPcqoE2VlrGyl8KapS1g6wz4dK17UBBFoLwEKCuUWgbLimBo2augsAAsVNK+s1ABljZVH6TzrwNxy4Fjy6SO8IICaDsE6DoBaBMlrVOSL/0u4lYCV/YAglIKpW0HS33JXNtINeVnSi17OUnSe/TtceeWwOoU3QTO/SHtP/d2Uqh39K85PJbkS6+dkywN42Bpc2sqK5JaHBN3SqeR9eXSOqEPAFFzpfdQoaxI2h/7PpPqaDtY+iwF3y9tqzqiKF14UHADUHsDVrZ3fp96vfQZyjgtfWZL8m/7vRYCNs6Abzfp4gWXoFvvP/86kHZCCqSiHvDvLX2Wbv+SkJchffk5/4f0JaHi9HVVff5yU6WBUK/slb545abceq7LOGDgnPr/LstLpb8ztw+vUVYkfV7yrkl/X/KuSX9HOj0uXaDRgF8SGG5q0FzDDQDMWn8aPx5Mwpge/oh+MFzucqghlORLf6CyEqSDeHYikH1JOtB1eVI6rWXjVHm93FTgwJfA4a8BfRkAAQh7ALi8R/qjrVQBA2cBvV6U/vidWg2cXA1kxde9RtcQIHiQFHQq/pBa2kkB4faQVR0LG8Cni/SH0DMcuLxLquX20ARI7yH8Yenu8Sp74Mw64NQaqbUFkMY66vGs9J7sXI1X1eulA07yAembfvIBaV8abV4BuIVJy9UUKKsjKKTQ1qovENBXCmxZCVIrW9YF6UBdXiIdFPRlgK5ceo916dBewc5NCpuOftK/2mtSGNaXSc9b2koH1ApqX2kfX9wGlBVUv117D+n0aHlx5edc20qtgf69pAO0a9vqO8CXFgDxm4DTvwIJMbfqqmDjLLVGqtS3DpL6Mqkl5maSdNVjbWn8pMAp6qUg2H0i0Psl4Mx6KdQUZFZex8peCn62zlKtpfnSv0U50oE6P+PWZ0BpBfhHSi2gQfdJAS33qvS7zYqX+tFlnpUCdk371uj9O0mftZuXpcFI/0mpku6/59VJ6guYcgiVQq+1Rgqu3Z+VfmfxG6XT02lxxsspLKT/oxX/F60dgYGzpXVvD8llxdI+0JfdCi8ledIXmWux0v+zjDPSc7Xl3h7o9hTQ8dEGaSFkuKlBcw43uy9cx7jvDsPdQYWDMwdCoWimzejUcLIvA9vflfr0VPDqDIxeCriHGi8rikDmOelbf3HuranwhnTwqGi5KLwBWDkA4Q8BEU9K3zIFQfpjeGaddECpOF0mKKWDfbuRQMgw6Y9nWtzf31RPAqmxQEkuquTeXmoB8gyXtnn+j7+fqPic//2nSlBILVAVfaAsbaURrn27S6+Vegy4dqKK1xEAjw5/Dw7ZDwiIlP4Al+RL33zjN0otaEU3pc7iFa1Wal/p/VZ8Ky8tkPbL7S0/9aH8u1VG+Edg0JdL347/GRCq4tNNeu/tR0u/r+M/SK00Rdm3lnEOkr75d3xc2uaFLdL7vLL31msIilutdYU3qg69VvbSZ8knArB1vdXSczNJ+vf2g2BFi03GaSkE1Oa9WDtK/dQsbKR9XV78d8sWpBaQ1gOkKwydA4HM80DMbCBhc+XtaPyBe2ZIQeHseuD0WuPWjJr8MyQC0mf69tPGt1OqpFOa7mHSZ8nS9lbrnjZVamm6FveP8CwALm2klkxRL53irSqQ+XSVThtbWEunpKv9vAnS/gnsJ/3f8+0hfRlIPgj8+SqQcUpazLWt9DsszJJaqGobzASF9D4rhtiwUElfJhy8pdOgDt5SbafX3vqCYmkrtZiN+MykpwYZbmrQnMNNSbkOXedvRX5JOX6b3Aed/BzlLomaqtTjwP7PpaDQe2rl00B1UVpw6w9bVURRan3Jz5S+6f6zFeV2er3UspFyWPrDn35S+kPf7RmpheD2Ju20E8CuD2+FHP/eQIcHgXajAFsXqaP37gXSt8yqWFhLBwj/XtI3cd/udz6NpSsHSrTSN+07Na9rr0kHpit7pJYhCIBr8N9TW6nvlKXNbeMuWUg1VRz87jRqtl4nHeBLC6Rv+zkp0kE6J0WqreOjVfc7qejPdT1eamGr7lRBSZ4Ubu3dpWBz+++3MPvvFq+D0r9pJyof9P/JqRXQ4WHpoObR7tb88pK/+6Kdkn5WWv69T6yk/ePoJ91epS6nGCsk7gQ2vy0dwB0DpL5tncYYvxdRlD5rCTEARGn/V5xiVKml1it7d2mysJZaaC5tl4aPuLJXet8KS+lz6hosnSp1C5X+bzkH3fn3WF4qhbysC9I+8ugghY/b68tKkE6Zpp2QQn7ocEDjc2sZvQ64sBk4+JX0ebOwlk4/hw6TWqTs3at+bV05cPQ76QtPdV8qBIX0/pRWUnBxD5Na2by7SAHVqVXtTjUV5QAnfwaOfg9cPycF0fEb7rxeHTDc1KA5hxsAmLziOP48lYaX7muDV+6voj8CkbnJSZb++FbVWVYUpYPQ/i+k1gqvztLpGO8u0h/puwl1dIuuXGrNST0utYyV5kv9aBwD/h5CIUD6WY5O2XqdFNLcQkz/+y4vAfLS/w5/TWTM27x0QOVQtzG38q9LQdDKVmp1s3OVviCoHEzf6VoUpVCssAD8upt00ww3NWju4WZd7FW8/PMJhHo64K/p/eQuh4iIqFHwruBm7N4QdygVAs6n5yEl+w7NxERERC0Qw00z42hrhW4B0tUyW89l3GFpIiKilofhphka1E4a44bhhoiIqDKGm2ZoYJgUbg4lZiO3qBaXWBIREbUgDDfNUKCrHVq72aFcL+LApToMfkVERNQCMNw0U/2C3QAAey8y3BAREd2O4aaZ6tNGGihtbwLDDRER0e0YbpqpXq2doVQIuHKjkJeEExER3YbhpplysLZE579vv7CPp6aIiIgMGG6asb4Vp6YYboiIiAxkDTeLFy9Gx44doVaroVarERkZiU2bNtW4zurVqxEaGgpra2uEh4dj48aNjVRt09M3WAo3+y/dgF7fou6iQUREVK16hZuUlBRcvXrV8Pjw4cOYPn06vv766zptx9fXFx988AGOHTuGo0eP4r777sPIkSNx5syZKpffv38/xowZg2eeeQaxsbEYNWoURo0ahdOnT9fnbTR7nf0cYWelRHZBKc6maeUuh4iIqEmo140z77nnHjz33HN48sknkZ6ejpCQELRv3x4JCQl46aWXMHv27HoX5OzsjAULFuCZZ56p9Nxjjz2GgoIC/PHHH4Z5vXr1QufOnbFkyZJabb+53zjzn55ZdgTbzmdi5tBQPN8/SO5yiIiIGkSD3zjz9OnT6NGjBwDgl19+QYcOHbB//36sWLECy5Ytq88modPpsGrVKhQUFCAyMrLKZQ4cOICoqCijeYMHD8aBAweq3W5JSQm0Wq3RZE76sN8NERGRkXqFm7KyMqhUKgDA1q1b8a9//QsAEBoairS0tDpt69SpU7C3t4dKpcKkSZOwbt06tGvXrspl09PT4eHhYTTPw8MD6enp1W4/OjoaGo3GMPn5+dWpvqbunr/73Ry+nI3iMp3M1RAREcmvXuGmffv2WLJkCfbs2YOYmBgMGTIEAHDt2jW4uLjUaVshISGIi4vDoUOH8MILL2D8+PE4e/Zsfcqq0syZM5Gbm2uYUlJSTLbtpqCNuz081CqUlOtxLOmm3OUQERHJrl7h5j//+Q+WLl2KAQMGYMyYMejUqRMAYMOGDYbTVbVlZWWFNm3aoGvXroiOjkanTp3w2WefVbmsp6cnMjKM74SdkZEBT0/ParevUqkMV2NVTOZEEASemiIiIrqNRX1WGjBgALKysqDVauHk5GSY/9xzz8HW1vauCtLr9SgpKanyucjISGzbtg3Tp083zIuJiam2j05L0beNK9YeT+VgfkRERKhnuCkqKoIoioZgk5SUhHXr1iEsLAyDBw+u9XZmzpyJoUOHwt/fH3l5eVi5ciV27tyJzZs3AwDGjRsHHx8fREdHAwCmTZuG/v37Y+HChRg+fDhWrVqFo0eP1vkSdHNTMZjfqdRc3CwohZOdlcwVERERyadep6VGjhyJH374AQCQk5ODnj17YuHChRg1ahQWL15c6+1kZmZi3LhxCAkJwcCBA3HkyBFs3rwZgwYNAgAkJycbdVDu3bs3Vq5cia+//hqdOnXCmjVrsH79enTo0KE+b8NsuKut0dbDHqIIHEi8IXc5REREsqrXODeurq7YtWsX2rdvj2+//RaLFi1CbGwsfv31V8yePRvnzp1riFpNwtzGuakw9/cz+H7fFTzWzQ//ebij3OUQERGZVIOPc1NYWAgHBwcAwJYtW/Dggw9CoVCgV69eSEpKqs8m6S4NCpMukf/1+FWcvJojbzFEREQyqle4adOmDdavX4+UlBRs3rwZ999/PwDpNJM5tYY0J5FBLhje0QvlehEzfjnBMW+IiKjFqle4mT17Nl599VW0atUKPXr0MFyttGXLFkRERJi0QKodQRDw7sgOcHNQ4WJmPhZsjpe7JCIiIlnUq88NII0WnJaWhk6dOkGhkDLS4cOHoVarERoaatIiTclc+9xU2HE+E08tOwIAWPlsT/QOcpW5IiIiorvX4H1uAGlAvYiICFy7ds1wh/AePXo06WDTEtwb6o4xPfwBAK+tPom84jKZKyIiImpc9Qo3er0e8+bNg0ajQUBAAAICAuDo6Ij58+dDr9ebukaqo7eHh8Hf2RapOUWY97vpbmVBRETUHNQr3Lz11lv44osv8MEHHyA2NhaxsbF4//33sWjRIsyaNcvUNVId2aks8PGjnSAIwOpjV7HrwnW5SyIiImo09epz4+3tjSVLlhjuBl7ht99+w4svvojU1FSTFWhq5t7n5nbz/ziL/+69jDbu9vhr2j2wUNb7LCQREZGsGrzPTXZ2dpV9a0JDQ5GdnV2fTVIDmDowGM52VriYmY+Vh5PlLoeIiKhR1CvcdOrUCV988UWl+V988QU6duTouE2FxsYSMwa1BQB8HHMBuYXsXExEROavXjfO/PDDDzF8+HBs3brVMMbNgQMHkJKSgo0bN5q0QLo7j3f3w48HkhCfkYfPtiVg9oh2cpdERETUoOrVctO/f39cuHABo0ePRk5ODnJycvDggw/izJkz+PHHH01dI90FC6UCbz8QBgD44cAVXLqeL3NFREREDaveg/hV5cSJE+jSpQt0uqY79H9L6lB8u2eWHcG285kYGOqO/07oLnc5REREddIog/hR8/Lv4WGwUAjYdj4Tu3lpOBERmTGGmxYiyM0e4yJbAQA+2sL7ThERkfliuGlBJt8bBIUAnLyai5TsQrnLISIiahB1ulrqwQcfrPH5nJycu6mFGpiLvQrdApxx+Eo2tp3LwIQ+gXKXREREZHJ1CjcajeaOz48bN+6uCqKGNaidBw5fyUYMww0REZmpOoWb77//vqHqoEYS1c4D7208h0OJ2cgtKoPGxlLukoiIiEyKfW5amEBXO7Rxt0e5XuQNNYmIyCwx3LRAUWEeAICYsxkyV0JERGR6DDct0KB27gCAnfGZKC3Xy1wNERGRaTHctECd/Zzgam+FvOJyHL7Mu7gTEZF5YbhpgZQKAfeFSq03W8/x1BQREZkXhpsWalA7TwBSvxsT3l6MiIhIdgw3LVTfNq6wtlQgNacI59Ly5C6HiIjIZBhuWigbKyX6tnEDwFNTRERkXhhuWrCKq6Z4STgREZkThpsW7L5QDwgCcCo1F2m5RXKXQ0REZBIMNy2Ym4MKEX6OAICx3xzCbo5YTEREZkDWcBMdHY3u3bvDwcEB7u7uGDVqFOLj42tcZ9myZRAEwWiytrZupIrNz1vDw+Bqr0JiVgHGfXcYLyw/htQctuIQEVHzJWu42bVrFyZPnoyDBw8iJiYGZWVluP/++1FQUFDjemq1GmlpaYYpKSmpkSo2P10DnLH91f54uk8glAoBm06nI2rhLqw8lCx3aURERPVSp7uCm9pff/1l9HjZsmVwd3fHsWPH0K9fv2rXEwQBnp6eDV1ei6G2tsTsEe3wSDdfzP7tNI5cuYm315/CPcGu8HO2lbs8IiKiOmlSfW5yc3MBAM7OzjUul5+fj4CAAPj5+WHkyJE4c+ZMY5Rn9sK81Pjl+Uj0beMKvQj8d+9luUsiIiKqsyYTbvR6PaZPn44+ffqgQ4cO1S4XEhKC7777Dr/99huWL18OvV6P3r174+rVq1UuX1JSAq1WazRR9QRBwPP9WwMAfjmagpzCUpkrIiIiqpsmE24mT56M06dPY9WqVTUuFxkZiXHjxqFz587o378/1q5dCzc3NyxdurTK5aOjo6HRaAyTn59fQ5RvVvq2cUWYlxqFpTqsYN8bIiJqZppEuJkyZQr++OMP7NixA76+vnVa19LSEhEREbh48WKVz8+cORO5ubmGKSUlxRQlmzVBEPBcv0AAwPf7rqCkXCdzRURERLUna7gRRRFTpkzBunXrsH37dgQGBtZ5GzqdDqdOnYKXl1eVz6tUKqjVaqOJ7uyBjt7w0lgjK78E62NT5S6HiIio1mQNN5MnT8by5cuxcuVKODg4ID09Henp6SgqujXOyrhx4zBz5kzD43nz5mHLli1ITEzE8ePH8cQTTyApKQkTJ06U4y2YLUulAk/3kcLm17sTodfzzuFERNQ8yBpuFi9ejNzcXAwYMABeXl6G6eeffzYsk5ycjLS0NMPjmzdv4tlnn0VYWBiGDRsGrVaL/fv3o127dnK8BbP2eA8/OKgscOl6AXbEZ8pdDhERUa0Ioii2qK/kWq0WGo0Gubm5PEVVC9Ebz2Hp7kT0CHTGL89Hyl0OERG1UHU5fjeJDsXUdE3o0woWCgGHL2cjLiVH7nKIiIjuiOGGauSlscG/OnsDAL7aUfUVaURERE0Jww3d0YsDgiAIwJazGTh7jYMgEhFR08ZwQ3fUxt0Bw8OlS+2/2JEgczVEREQ1Y7ihWnnpvmAAwMZT6YhPz5O5GiIiouox3FCthHg6YGgH6U7sX7DvDRERNWEMN1RrU+5rAwD44+Q1XMzMl7kaIiKiqjHcUK2199ZgUDsPiCLwxXb2vSEioqaJ4YbqZOrffW82nLiGxOtsvSEioqaH4YbqJNxXg/tC3aEXgS93XJK7HCIiokoYbqjOXvq77836uFRczOSVU0RE1LQw3FCdRfg7ISrMHTq9iOiN5+Uuh4iIyAjDDdXLzGFhsFAI2HY+E/suZsldDhERkQHDDdVLkJs9xvb0BwC8++c56PQt6ubyRETUhDHcUL1Ni2oLB2sLnEvT4tfjV+Uuh4iICADDDd0FZzsrQ+fijzbHo7C0XOaKiIiIGG7oLo3v3Qp+zjbIzCvB0l2JcpdDRETEcEN3R2WhxJtDwgAAX+9ORIa2WOaKiIiopWO4obs2LNwTXQOcUFSmwycxF+Quh4iIWjiGG7prgiDg38NCAQCrj11F0o0CmSsiIqKWjOGGTKJrgDP6tXWDTi9i0faLcpdDREQtGMMNmczLUdJNNdfFpuJyFltviIhIHgw3ZDIR/k64L1S6LcOibQlyl0NERC0Uww2Z1PS/W2/Wx6Xi0vV8mashIqKWiOGGTKqjryOiwjygF4HP2XpDREQyYLghk6tovdlw4hoSMvJkroaIiFoahhsyuQ4+Ggxu7wFRBD7ZegGiyJtqEhFR42G4oQYxPaotAGDjqXRERm/Hv9edwrZzGSgu08lcGRERmTtBbGFfq7VaLTQaDXJzc6FWq+Uux6x9ueMivtxxEYWltwKNtaUCL90XjBcHBEEQBBmrIyKi5qQux2+GG2pQxWU6HEy8gW3nMrHtXAau5Ur3npoeFWxo3SEiIroThpsaMNzIRxRFfLvnMt7beA4A8NrgEEy+t43MVRERUXNQl+O3rH1uoqOj0b17dzg4OMDd3R2jRo1CfHz8HddbvXo1QkNDYW1tjfDwcGzcuLERqqW7JQgCnu3XGm8Mke5DtWBzPJbsuiRzVUREZG5kDTe7du3C5MmTcfDgQcTExKCsrAz3338/CgqqH7p///79GDNmDJ555hnExsZi1KhRGDVqFE6fPt2IldPdeGFAEF4ZJJ2S+mDTeXy7J1HmioiIyJw0qdNS169fh7u7O3bt2oV+/fpVucxjjz2GgoIC/PHHH4Z5vXr1QufOnbFkyZI7vgZPSzUdH8dcMAz0t3JiT/Ru4ypzRURE1FQ1m9NS/5SbmwsAcHZ2rnaZAwcOICoqymje4MGDceDAgSqXLykpgVarNZqoaXg5KhiPd/cDAHzK0YyJiMhEmky40ev1mD59Ovr06YMOHTpUu1x6ejo8PDyM5nl4eCA9Pb3K5aOjo6HRaAyTn5+fSeum+hMEAdOj2sJKqcDhy9k4lHhD7pKIiMgMNJlwM3nyZJw+fRqrVq0y6XZnzpyJ3Nxcw5SSkmLS7dPd8dRY45FuvgCARdsvylwNERGZgyYRbqZMmYI//vgDO3bsgK+vb43Lenp6IiMjw2heRkYGPD09q1xepVJBrVYbTdS0vDAgCBYKAXsvZuFY0k25yyEiomZO1nAjiiKmTJmCdevWYfv27QgMDLzjOpGRkdi2bZvRvJiYGERGRjZUmdTAfJ1s8WAXHwDAou3se0NERHdH1nAzefJkLF++HCtXroSDgwPS09ORnp6OoqIiwzLjxo3DzJkzDY+nTZuGv/76CwsXLsT58+cxZ84cHD16FFOmTJHjLZCJTL63DZQKATvjr+Pk1Ry5yyEiomZM1nCzePFi5ObmYsCAAfDy8jJMP//8s2GZ5ORkpKWlGR737t0bK1euxNdff41OnTphzZo1WL9+fY2dkKnpC3Cxw8hO3gDY94aIiO5OkxrnpjFwnJum62JmPgZ9sguiCGyadg/CvPj7ISIiSbMd54Zatjbu9hge7gUAiN50HuU6vcwVERFRc8RwQ03K1IHBsFQK2H3hOqb9HMeAQ0REdcZwQ01KWw8HLB7bFZZKAX+eTMO0VXEoY8AhIqI6YLihJieqnQeWPNEVVkoF/jyVhqk/xTLgEBFRrTHcUJM0MMwDS57sAiulAptOp2PKyuMMOEREVCsMN9Rk3RfqgaXjusLKQoHNZzKwdNcluUsiIqJmgOGGmrR7Q9wRPTocAPDVzkvI1BbLXBERETV1DDfU5D3YxQed/RxRWKrDwi0X5C6HiIiaOIYbavIEQcCsB8IAAL8cS8HZa1qZKyIioqaM4Yaaha4Bzhje0QuiCLz751m0sIG1iYioDhhuqNl4c0gorCwU2H/pBrady5S7HCIiaqIYbqjZ8HO2xdN9AgEA7288x0vDiYioSgw31KxMvjcILnZWSMwqwPKDSXKXQ0RETRDDDTUrDtaWmHF/WwBS680X2xN4/ykiIjLCcEPNzmPd/DC0gyfKdCI+2nIBDy7ejwsZeXKXRURETQTDDTU7FkoFvhrbBR8/2glqawucvJqLBz7fiy93XIROz6uoiIhaOoYbapYEQcCDXXwRM6M/Boa6o1Snx4LN8Zi59iQvEyciauEYbqhZ81Bb49vx3fDhQx2hEIBfjl7FVzt5DyoiopaM4YaaPUEQ8Gh3P8wd2QEAsGBzPH6LS5W5KiIikgvDDZmNJ3sFYGJfaRyc11afxJEr2TJXREREcmC4IbMyc1gYBrf3QKlOj+d+OIorWQVyl0RERI2M4YbMilIh4NPHItDJV4ObhWUY//1hXL1ZKHdZRETUiBhuyOzYWCnxzfhu8HWyQdKNQjy8+AASOA4OEVGLwXBDZsndwRqrJ0Wijbs90rXFeGTpAcSl5MhdFhERNQKGGzJbXhobrH4+Ep39HJFTWIb/++Yg9iZkyV0WERE1MIYbMmtOdlZYMbEn7gl2RWGpDk8tO4yNp9LkLouIiBoQww2ZPTuVBb4d3w3Dw71QphMxZeVx/HIkRe6yiIiogTDcUIugslDi8zERGNPDD3oReP3Xk/h2T6LcZRERUQNguKEWQ6kQ8P7ocDzfrzUA4N0/z+HjmAu8FxURkZlhuKEWRRAEvDk0FK8NDgEAfL4tAXM2nEFpuV7myoiIyFRkDTe7d+/GiBEj4O3tDUEQsH79+hqX37lzJwRBqDSlp6c3TsFkFgRBwOR722D+yPYAgP8dSMIDi/bgWNJNmSsjIiJTkDXcFBQUoFOnTvjyyy/rtF58fDzS0tIMk7u7ewNVSObsychWWPJEF7jYWeFCRj4eXrIfs387jbziMrlLIyKiu2Ah54sPHToUQ4cOrfN67u7ucHR0NH1B1OIM6eCFnoEueG/jOaw5dhU/HEjCljMZ+PTxzujV2kXu8oiIqB6aZZ+bzp07w8vLC4MGDcK+fftqXLakpARardZoIrqdk50VPnqkE1ZM7IkAF1uka4sxafkxpOcWy10aERHVQ7MKN15eXliyZAl+/fVX/Prrr/Dz88OAAQNw/PjxateJjo6GRqMxTH5+fo1YMTUnfdq4YvP0fgj30SCnsAwzfomDXs8rqYiImhtBbCLXwQqCgHXr1mHUqFF1Wq9///7w9/fHjz/+WOXzJSUlKCkpMTzWarXw8/NDbm4u1Gr13ZRMZirxej6Gf74XRWU6vDk0FJP6B8ldEhFRi6fVaqHRaGp1/G5WLTdV6dGjBy5evFjt8yqVCmq12mgiqklrN3vM+Vc7AMBHm+Nx6mquzBUREVFdNPtwExcXBy8vL7nLIDPzaDc/DO3giXK9iGmrYlFYWi53SUREVEuyXi2Vn59v1Opy+fJlxMXFwdnZGf7+/pg5cyZSU1Pxww8/AAA+/fRTBAYGon379iguLsa3336L7du3Y8uWLXK9BTJTgiAg+sFwxKXkIDGrAPN+P4sPHuood1lERFQLsrbcHD16FBEREYiIiAAAzJgxAxEREZg9ezYAIC0tDcnJyYblS0tL8corryA8PBz9+/fHiRMnsHXrVgwcOFCW+sm8Odpa4ZPHOkMQgFVHUvCfv86zgzERUTPQZDoUN5a6dEgiAoAluy7hg03nAQCD2nng08c6w04la6MnEVGL06I6FBM1tEn9g/DZ451hZaFAzNkMPLzkAFJziuQui4iIqsFwQ1QLIzv7YNVzveBqr8K5NC1GfrEXx5Ky5S6LiIiqwHBDVEtd/J3w25Q+CPNSIyu/FI8tPYjFOy+xHw4RURPDcENUBz6ONlgzKRIPdPRCuV7Ef/46j/HfH0ZmHm/VQETUVDDcENWRncoCi8ZE4D8PhcPaUoE9CVkY9tke7L5wXe7SiIgIDDdE9SIIAh7r7o/fp/RFqKcDsvJLMe67w1iw+Tx0PE1FRCQrhhuiuxDs4YD1k/vgiV7+AIAvd1zCk/89hOt5JXdYk4iIGgrDDdFdsrZU4t1R4fjs8c6wtVJi/6UbeGDRHhy5wqupiIjkwHBDZCIjO/vgt8l90MbdHhnaEjz+9UF8uycRLWycTCIi2THcEJlQsIcDfpvcB//q5A2dXsS7f57D9J/jUFSqk7s0IqIWg+GGyMTsVBb47PHOmDOiHZQKAb/FXcNDi/fj6s1CuUsjImoRGG6IGoAgCJjQJxArJvaEi50VzqZp8a8v9mH/pSy5SyMiMnsMN0QNqFdrF2x4qS86+KiRXVCKJ/97GIu2JaBcp5e7NCIis8VwQ9TApFGNe+PBCB/o9CIWxlzAQ0sO4NL1fLlLIyIySww3RI3A2lKJhY92wiePdYKDtQVOpORg2Gd78P2+y7w3FRGRiQliC7tOVavVQqPRIDc3F2q1Wu5yqAW6llOEN349iT0JUv+bIDc7BLs7wM/ZBr5OtmjlaofeQS6wVPK7BxFRhbocvxluiGQgiiKWH0zC+xvPo6is8mXiPQOd8d8J3WGvspChOiKipofhpgYMN9SUZOYV42RKLq7eLETKzSJcvVmIfRdvIL+kHF38HfH9Uz2gsbGUu0wiItkx3NSA4YaauhMpORj33WHkFpWhg48aPz7dE052VnKXRUQkq7ocv3lSn6iJ6eTniJ+e7QUXOyucTtXi8a8P8kacRER1wHBD1AS181bj5+d7wd1BhfiMPPzri71494+z2JNwHcVV9NEhIqJbeFqKqAm7klWAsd8eQmpOkWGetaUCPQNd8MKAIPRq7SJjdUREjYd9bmrAcEPNTX5JOXbGZ2JX/HXsTriODK10ispCIeDDhzviwS6+MldIRNTwGG5qwHBDzZkoiriQkY/Ptyfgz5NpAIDXBofgxQFBEARB5uqIiBoOOxQTmSlBEBDi6YBFj0fg+X6tAQALNsfj7fWneb8qIqK/MdwQNUMKhYCZw8IwZ0Q7CAKw4lAyJi0/jqJSdjYmImK4IWrGJvQJxFf/1wVWFgpsPZeB8d8dhra4TO6yiIhkxXBD1MwNDffC8md6wkFlgcNXsjHm64PIyq88Lo5eLzL4EFGLwHBDZAZ6BDrjp+ekgf/OXNPi0SUHDJePp+UWYdG2BPRbsAOd527Bt3sSZa6WiKhh8WopIjOSeD0fT/73MFJziuCtsUaolxo74zOh/8f/8uf7t8abQ0J5hRURNRu8WoqohWrtZo/VkyIR5GaHa7nF2H5eCjY9Ap3x8aOd8NrgEADA0l2JeG3NSV5hRURmSdZws3v3bowYMQLe3t4QBAHr16+/4zo7d+5Ely5doFKp0KZNGyxbtqzB6yRqTrwdbfDL85F4uKsvnu/fGtte6Y9fno/Eg118MfneNvjwoY5QCMCaY1fx/I/HeIUVEZkdWcNNQUEBOnXqhC+//LJWy1++fBnDhw/Hvffei7i4OEyfPh0TJ07E5s2bG7hSoubFxV6Fjx7phJlDwxDkZm/03KPd/bD0yW5QWSiw7Xwmxn13CPkl5TJVSkRkek2mz40gCFi3bh1GjRpV7TJvvPEG/vzzT5w+fdow7/HHH0dOTg7++uuvWr0O+9wQSQ5fzsYz/zuCvOJydA1wwrKnusPB2lLusoiIqmS2fW4OHDiAqKgoo3mDBw/GgQMHql2npKQEWq3WaCIiqR/Oiok9oba2wLGkmxj/3WHk8VJxIjIDzSrcpKenw8PDw2ieh4cHtFotioqKqlwnOjoaGo3GMPn5+TVGqUTNQkdfR6yY2AsaG0scT87BOA4CSERmwELuAhrazJkzMWPGDMNjrVbLgEN0m3BfDVZM7Imx3x5CbHIOxn5zCBH+jkjLLUZ6bjHScosR7G6P75/qDmtLpdzlEhHdUbMKN56ensjIyDCal5GRAbVaDRsbmyrXUalUUKlUjVEeUbPVwUcKOE/89xBOpebiVGqu0fNZ+SX4OOYC/j0sTKYKqanS60XEpuQgzMsBtlbN6pBCZqxZfRIjIyOxceNGo3kxMTGIjIyUqSIi89HBR4M1kyLx0+EU2Fgq4amxhpfGGpl5JZi59hS+2ZOI+9t5oFsrZ7lLpSbiel4JZvwShz0JWWjjbo8fnu4Bb8eqv2gSNSZZ+9zk5+cjLi4OcXFxAKRLvePi4pCcnAxAOqU0btw4w/KTJk1CYmIiXn/9dZw/fx5fffUVfvnlF7z88stylE9kdtq4O2DWA+3w6uAQPNErAAPDPDCmhz8e6uILUQReXX0ChaXyXzau/+eQy83QlawCvL/xHOLT8+QupV52X7iOoZ/twZ6ELADAxcx8PLx4Py5m5stcWWXlOj0OJd6445AH1/NKUMaBLc2CrJeC79y5E/fee2+l+ePHj8eyZcswYcIEXLlyBTt37jRa5+WXX8bZs2fh6+uLWbNmYcKECbV+TV4KTlR3uUVlGPzJbqRrizGhdyvM+Vf7Rnnd/JJypGQX4kJGHs6n5+F8mhbn0vKQlV+C2SPaYVxkqwZ9/RMpOfjxYBJsrZToHeSCXq1d4GhrddfbPXw5G8/9eBQ5hWVwsLbAsqe6o2vA3beI6fUiEjLzcejyDWTlleCZvq2hsTXt5f1lOj0+2hKPpbuke5SFeDjg38PDMPf3M0i8XgAnW0t8/1QPdPZzBCAFi8NXsrH7QhYcrC3QzluNDt4auDk0fHeBMp0e62JT8eWOi0i6UQgfRxt8PqZzpX1dUq7Dx1su4Os9iQh0tcPnj0egg4+m2u2KooiScj0KS3UoKCmHXhTh7WgDS+XdtReIoljnW6JU1FJVf7ibBaX481QafotLxanUXLT31qBPkAv6tHFFhL8TrCwUKCrVIeVmIVKyC3GjoBR92rjCp4m2vtXl+N1kxrlpLAw3RPWz68J1jP/uMABg5bM90TvItcrlruUU4WjSTZy6mgO1tSUCXO3QysUWAc521R5oC0rKceJqDmKTc3A2TYuUbOmP7c3Cmq/cent4GCbe07rS/OQbhVh+KAnZBaUoKtOhuFSHwlIdHKwt0K+tGwaEuMHXybba7Z5L0+LjmAuIOWvcx08QgPbeavRt44an+7SCu9q6xvqqsj42Fa+vOYlSnR7WlgoUl+lhY6nEN+O6oW9w1fu0OqIoIjGrALsvXMfBxBs4fDnbaJ8Fudlh2VM94Odc/Xuti70JWXh/4zmcTZOG1Hiilz/eHt4O1pZKZBeU4qnvD+PE1VzYWinx+uAQnE3TIuZsRpW/Rw+1Cp39HPF4d3/0b+sGhcJ09zkrKddh7XEp1Fy9aXwlrVIh4OWoYLwwoA2UCgHn07WYvioO529rQbNSKvD6kBA83SfQUFdecRlWHU7BjweTcPVmYaX7tVkpFWjtZocQTwe09XCAtaUSGVqpU366thh5xeUYGOqOcb0D4O5g/Lm5erMQi3dewrrYVDjZWqGdtxrtvNRo761GoKsdlAoBgiBAIQB6EUjIyMOp1FycuJqLU1dzcLOwDO4OKgS62iHQ1Q5+zraITc7BrguZKNNVfYi3sVTCTmWBrPwSo/kKARgQ4o7/6+GPASFusKghsN3IL8Hn2xJwLj0PHX006NbKGd1aOcHVvmGCK8NNDRhuiOrv3+tOYeWhZPg42uDdUR2gLS5DTmEZcovKcOl6Po5euWm4G3lVHFQWcLKzgqOtJTQ2lnCwtsDlrELEp2srHSwqONpaorWrHcK81Aj1UiPM0wE74jPx5Y5LAIDXBodg8r1tAAA6vYhl+69gwebzKC6r+fRCWw979G/rBk+NDSwUApQKAZZKAXsSsvDHyTQA0h/6UZ194GBtgf2XbiDhtlMutlZKvNA/CBPvaQ0bq1vfmi9m5mP5wSQcuZKNEA8H9ApyQWRrF/g62WDR9ov4OOYCAGBoB0+8Nzoc01bFYk9CFqyUCnw5tgsGtTMe7uKfikp12J1wHbsvXMeuC9crHbxtLJXo1soJFzPzkZZbDBc7K3w7vhsi/J1q3K5OL+JQ4g0UlOrQzlsNb421oRXhdGou/vPXecMpKLW1BT58uCOGdPAy2kZ+STkm/XgMey9mGc13tLXEfaHu0OlFnE7NRWJWAW4/8gS52eHpvoF4MMLXsC9FUUROYRnyisvh7Whd7UE2U1uMU6m5iM/Iw4X0PMRn5ONSZj5K/z695Gpvhef7BWFkZ2+8++c5bDhxDQDQq7Uz7gl2w2dbE1Cq08PFzgqzHmiHP06mYes5KdT2b+uG1waHYMOJa/jpUDLyqjitZW0p1XWnz1sFK6UCoyN8MPGeQFhZKPDljotYezwV5Q10qrWdlxqjIrzRO8gVZ67lYu/FGzhwKQtZ+aWGZRysLRDgYgtLpQKxyTmG+V4aazzc1ReD23uivbfa8Hko1+nx48EkfBxzAXnFlfdJa1c79A12xbyRHUz6XhhuasBwQ1R/+SXlGPLp7koH1NspFQLae6vR2c8RhaU6JN8oxJUbBcjMK6l2HQDw1lgjIsAJHX00aOVqBz8nW/g521Q7avLn2xIMQWF6VDAe6OiN19ecwPG//zj3au2M/m3dYWOpgI2VEtaWSly9WYQd5zNxPPlmtWGqwgMdvTA9qi3auN+6fUWmthj7L93Asv1XEJcivY6XxhqvDwmBykKJHw8k4UDijSq352xnhewC6YDyfL/WeGNIKBQKASXlOkz9KRabz2RAqRDw/ugOGNnZp9Jphsy8YvywPwk/HkxCbtGtlhArpQLdA53Qp40rega6INxHAysLBTK0xXh62RGcuaaFykKBTx/rjKHhxmEEkFoB1hy/ivWxqcjQ3vodOdpaop2XGrZWFoaDvaVSwBO9AvDSfcFwtqv69FxJuQ5vrTuNw5ezMSDEDUPae6JHoLNROCkoKce5NC02n0nHqsMphtBQEWQztCW4nldiCChWSgXauNsj1MsBYZ5qlOr0OJGSg5NXc5GuLa6yDncHFZ7vH4T/6+FvFJh+PZ6K2b+dRuFt91QbGOqODx7qCDcHFURRxPJDyXj3j7MoKTcOLG3c7fHsPYG4N8QdtioL2FgqoVQI0OtFXMstQnx6niFklelFeKqt4am2hofGGnq9iP8duGIUHipaYgCgTxsXvPh3a9LZa1qcTdPizDUt0nKLoNeLEEVABKAXRfg52aKjrwYd/RzRyVcDH0cbXL1ZhMtZBUjMKkDSjQL4OtlgZGcftPVwqLRvRFE6fVlSpoe/s61Ri+rlrAL8dDgZq4+mGLW4+Tja4P72HujgrcHS3ZdwIUMK+u291RjTwx/n0rQ4euUm4jOkFrCegc74+XnTXuzDcFMDhhuiu3Ms6SbeWncKSoUAjY2loRXGU22Dbq2c0NnPEXaqyhdiFpaWIy23+O+WnlLcLJBafLw01ojwd4Knpu6neL7aeREf/hUPQApVOr0Ie5UF/j0sDGN6+FXbfyGnsBR7ErKw/9INFJSUQ6cXUa7XQ6cX4Whrhaf7BKKdd/V/H0RRxIYT1/DhX/GVWqoUAnBfqAeGd/TExcx8HLh0Ayev5qJcL0KpEDBvZHuM7RlgtE65To/X15zE2thUAIDKQoEegc7o08YVHbw1+P3ENayLTTUc7H0cbRAV5o7+IW7o1dql2kuwC0rK8dJPsdh+PhOCIB3ELZUK6EXpYJmWW2x02b+TrSU81Na4mJlfqSVhZGdvvDIoBP4upjnFVSG/pBy/HEnB9/svIyW7cmi2UioM77sqCkEKHWFearT1cECIhwNCPB3g42hT7amuxOv5ePnnOFy6XlDtZ+VCRh6m/hSL8+l5iGztguf6tTbJ6bNjSdn4encitpzNgCgCA0Lc8NJ9wegaUHPLWmMrKdfhr9Pp2HgqDbsuXK/UMuVsZ4XXBofg0W5+UN62T3IKS3E8+SYsFAr0a+tm0poYbmrAcENkXr7dk4h3/zwHQDpQvD86vNEuRy4u0+G/ey9jyc5LUFkq8Xh3P4zp6V+pQ2ZBSTmOJ9+Es50V2ntX3VFVrxfx6dYL+OlICq5X08oV4e+I5/u1xqB2nkYHlJqU6/SY98dZ/HAgqcrnLRQCBoS44+Guvrgv1B1WFgqUlOuQkJGPM9dykZpTjPvbedTYwdYUdHoRey9mobCkHO5qa3ioVXBzUMFSocDVm0U4l65FfHoezqdroVQo0MlXg3AfDTr4aKoM03ciiiLK9WKNnYDLdXpczy+Bl8b0n6drOUUo0+kR4GJn8m2bWlGpDnsvZmHLmXTEpeSgTxtXvBzV1uSd1e+E4aYGDDdE5mdHfCZ0OhEDw9zrfLWJqdTnSpfqtnMxMx97L2Zh38UbOJWag06+jni+f+t6X1EliiJ2J2ThSlYBFAL+7pwqwNpS+nbdUB1AiUyJ4aYGDDdERETNj9neFZyIiIjoThhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyIiIjIrDDdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMioXcBTQ2URQBSLdOJyIiouah4rhdcRyvSYsLN3l5eQAAPz8/mSshIiKiusrLy4NGo6lxGUGsTQQyI3q9HteuXYODgwMEQaj3drRaLfz8/JCSkgK1Wm3CCumfuK8bD/d14+L+bjzc142nofa1KIrIy8uDt7c3FIqae9W0uJYbhUIBX19fk21PrVbzP0oj4b5uPNzXjYv7u/FwXzeehtjXd2qxqcAOxURERGRWGG6IiIjIrDDc1JNKpcI777wDlUoldylmj/u68XBfNy7u78bDfd14msK+bnEdiomIiMi8seWGiIiIzArDDREREZkVhhsiIiIyKww3REREZFYYburpyy+/RKtWrWBtbY2ePXvi8OHDcpfU7EVHR6N79+5wcHCAu7s7Ro0ahfj4eKNliouLMXnyZLi4uMDe3h4PPfQQMjIyZKrYPHzwwQcQBAHTp083zON+Nq3U1FQ88cQTcHFxgY2NDcLDw3H06FHD86IoYvbs2fDy8oKNjQ2ioqKQkJAgY8XNk06nw6xZsxAYGAgbGxsEBQVh/vz5Rvci4r6un927d2PEiBHw9vaGIAhYv3690fO12a/Z2dkYO3Ys1Go1HB0d8cwzzyA/P79hChapzlatWiVaWVmJ3333nXjmzBnx2WefFR0dHcWMjAy5S2vWBg8eLH7//ffi6dOnxbi4OHHYsGGiv7+/mJ+fb1hm0qRJop+fn7ht2zbx6NGjYq9evcTevXvLWHXzdvjwYbFVq1Zix44dxWnTphnmcz+bTnZ2thgQECBOmDBBPHTokJiYmChu3rxZvHjxomGZDz74QNRoNOL69evFEydOiP/617/EwMBAsaioSMbKm5/33ntPdHFxEf/44w/x8uXL4urVq0V7e3vxs88+MyzDfV0/GzduFN966y1x7dq1IgBx3bp1Rs/XZr8OGTJE7NSpk3jw4EFxz549Yps2bcQxY8Y0SL0MN/XQo0cPcfLkyYbHOp1O9Pb2FqOjo2WsyvxkZmaKAMRdu3aJoiiKOTk5oqWlpbh69WrDMufOnRMBiAcOHJCrzGYrLy9PDA4OFmNiYsT+/fsbwg33s2m98cYbYt++fat9Xq/Xi56enuKCBQsM83JyckSVSiX+9NNPjVGi2Rg+fLj49NNPG8178MEHxbFjx4qiyH1tKv8MN7XZr2fPnhUBiEeOHDEss2nTJlEQBDE1NdXkNfK0VB2Vlpbi2LFjiIqKMsxTKBSIiorCgQMHZKzM/OTm5gIAnJ2dAQDHjh1DWVmZ0b4PDQ2Fv78/9309TJ48GcOHDzfanwD3s6lt2LAB3bp1wyOPPAJ3d3dERETgm2++MTx/+fJlpKenG+1vjUaDnj17cn/XUe/evbFt2zZcuHABAHDixAns3bsXQ4cOBcB93VBqs18PHDgAR0dHdOvWzbBMVFQUFAoFDh06ZPKaWtyNM+9WVlYWdDodPDw8jOZ7eHjg/PnzMlVlfvR6PaZPn44+ffqgQ4cOAID09HRYWVnB0dHRaFkPDw+kp6fLUGXztWrVKhw/fhxHjhyp9Bz3s2klJiZi8eLFmDFjBv7973/jyJEjmDp1KqysrDB+/HjDPq3qbwr3d928+eab0Gq1CA0NhVKphE6nw3vvvYexY8cCAPd1A6nNfk1PT4e7u7vR8xYWFnB2dm6Qfc9wQ03S5MmTcfr0aezdu1fuUsxOSkoKpk2bhpiYGFhbW8tdjtnT6/Xo1q0b3n//fQBAREQETp8+jSVLlmD8+PEyV2defvnlF6xYsQIrV65E+/btERcXh+nTp8Pb25v7uoXhaak6cnV1hVKprHTlSEZGBjw9PWWqyrxMmTIFf/zxB3bs2AFfX1/DfE9PT5SWliInJ8doee77ujl27BgyMzPRpUsXWFhYwMLCArt27cLnn38OCwsLeHh4cD+bkJeXF9q1a2c0LywsDMnJyQBg2Kf8m3L3XnvtNbz55pt4/PHHER4ejieffBIvv/wyoqOjAXBfN5Ta7FdPT09kZmYaPV9eXo7s7OwG2fcMN3VkZWWFrl27Ytu2bYZ5er0e27ZtQ2RkpIyVNX+iKGLKlClYt24dtm/fjsDAQKPnu3btCktLS6N9Hx8fj+TkZO77Ohg4cCBOnTqFuLg4w9StWzeMHTvW8DP3s+n06dOn0pAGFy5cQEBAAAAgMDAQnp6eRvtbq9Xi0KFD3N91VFhYCIXC+LCmVCqh1+sBcF83lNrs18jISOTk5ODYsWOGZbZv3w69Xo+ePXuaviiTd1FuAVatWiWqVCpx2bJl4tmzZ8XnnntOdHR0FNPT0+UurVl74YUXRI1GI+7cuVNMS0szTIWFhYZlJk2aJPr7+4vbt28Xjx49KkZGRoqRkZEyVm0ebr9aShS5n03p8OHDooWFhfjee++JCQkJ4ooVK0RbW1tx+fLlhmU++OAD0dHRUfztt9/EkydPiiNHjuTlyfUwfvx40cfHx3Ap+Nq1a0VXV1fx9ddfNyzDfV0/eXl5YmxsrBgbGysCED/++GMxNjZWTEpKEkWxdvt1yJAhYkREhHjo0CFx7969YnBwMC8Fb2oWLVok+vv7i1ZWVmKPHj3EgwcPyl1Sswegyun77783LFNUVCS++OKLopOTk2hrayuOHj1aTEtLk69oM/HPcMP9bFq///672KFDB1GlUomhoaHi119/bfS8Xq8XZ82aJXp4eIgqlUocOHCgGB8fL1O1zZdWqxWnTZsm+vv7i9bW1mLr1q3Ft956SywpKTEsw31dPzt27Kjy7/P48eNFUazdfr1x44Y4ZswY0d7eXlSr1eJTTz0l5uXlNUi9gijeNnQjERERUTPHPjdERERkVhhuiIiIyKww3BAREZFZYbghIiIis8JwQ0RERGaF4YaIiIjMCsMNERERmRWGGyJq8QRBwPr16+Uug4hMhOGGiGQ1YcIECIJQaRoyZIjcpRFRM2UhdwFEREOGDMH3339vNE+lUslUDRE1d2y5ISLZqVQqeHp6Gk1OTk4ApFNGixcvxtChQ2FjY4PWrVtjzZo1RuufOnUK9913H2xsbODi4oLnnnsO+fn5Rst89913aN++PVQqFby8vDBlyhSj57OysjB69GjY2toiODgYGzZsaNg3TUQNhuGGiJq8WbNm4aGHHsKJEycwduxYPP744zh37hwAoKCgAIMHD4aTkxOOHDmC1atXY+vWrUbhZfHixZg8eTKee+45nDp1Chs2bECbNm2MXmPu3Ll49NFHcfLkSQwbNgxjx45FdnZ2o75PIjKRBrkdJxFRLY0fP15UKpWinZ2d0fTee++JoijdLX7SpElG6/Ts2VN84YUXRFEUxa+//lp0cnIS8/PzDc//+eefokKhENPT00VRFEVvb2/xrbfeqrYGAOLbb79teJyfny8CEDdt2mSy90lEjYd9bohIdvfeey8WL15sNM/Z2dnwc2RkpNFzkZGRiIuLAwCcO3cOnTp1gp2dneH5Pn36QK/XIz4+HoIg4Nq1axg4cGCNNXTs2NHws52dHdRqNTIzM+v7lohIRgw3RCQ7Ozu7SqeJTMXGxqZWy1laWho9FgQBer2+IUoiogbGPjdE1OQdPHiw0uOwsDAAQFhYGE6cOIGCggLD8/v27YNCoUBISAgcHBzQqlUrbNu2rVFrJiL5sOWGiGRXUlKC9PR0o3kWFhZwdXUFAKxevRrdunVD3759sWLFChw+fBj//e9/AQBjx47FO++8g/Hjx2POnDm4fv06XnrpJTz55JPw8PAAAMyZMweTJk2Cu7s7hg4diry8POzbtw8vvfRS475RImoUDDdEJLu//voLXl5eRvNCQkJw/vx5ANKVTKtWrcKLL74ILy8v/PTTT2jXrh0AwNbWFps3b8a0adPQvXt32Nra4qGHHsLHH39s2Nb48eNRXFyMTz75BK+++ipcXV3x8MMPN94bJKJGJYiiKMpdBBFRdQRBwLp16zBq1Ci5SyGiZoJ9boiIiMisMNwQERGRWWGfGyJq0njmnIjqii03REREZFYYboiIiMisMNwQERGRWWG4ISIiIrPCcENERERmheGGiIiIzArDDREREZkVhhsiIiIyKww3REREZFb+HwpUsj9Ry7p1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# Preprocess and load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=100, img_h=100, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        #add relu\n",
        "\n",
        "        self.bn1 = nn.BatchNorm2d(num_out_ch[0])  # Batch normalization after conv1\n",
        "        #added pooling\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn2 = nn.BatchNorm2d(num_out_ch[1])  # Batch normalization after conv2\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer with p=0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout(x)  # Apply dropout after pooling\n",
        "        x = self.fc(x.reshape(x.shape[0], -1))\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "num_classes = len(set(train_dataset._labels))\n",
        "model = MyCNN(num_channels=3, num_out_ch=[16, 32], img_w=224, img_h=224, num_classes=num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "best_test_loss = float(\"inf\")\n",
        "patience = 3\n",
        "bad_counter = 0\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')\n",
        "\n",
        "    # Early stopping and learning rate adjustment\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "        if bad_counter >= patience:\n",
        "            print(\"Adjusting learning rate...\")\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10\n",
        "            bad_counter = 0  # Reset bad_counter\n",
        "\n",
        "\n",
        "# Plot the training and test losses\n",
        "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2xo_PeDyk6-"
      },
      "source": [
        "4 layers Adaptive pool with sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "rf458Ca3yezC",
        "outputId": "c7875eae-fa03-4a71-8ea2-7878ef03252a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:11<00:00, 30171027.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 1229871.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 22533484.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Train Loss: 4.7880, Test Loss: 4.6210, Test Accuracy: 1.11%\n",
            "Epoch [2/20], Train Loss: 4.7164, Test Loss: 4.5939, Test Accuracy: 1.92%\n",
            "Epoch [3/20], Train Loss: 4.6418, Test Loss: 4.5629, Test Accuracy: 2.57%\n",
            "Epoch [4/20], Train Loss: 4.6082, Test Loss: 4.5305, Test Accuracy: 2.75%\n",
            "Epoch [5/20], Train Loss: 4.5881, Test Loss: 4.5068, Test Accuracy: 2.85%\n",
            "Epoch [6/20], Train Loss: 4.5456, Test Loss: 4.4775, Test Accuracy: 3.29%\n",
            "Epoch [7/20], Train Loss: 4.5226, Test Loss: 4.4578, Test Accuracy: 3.37%\n",
            "Epoch [8/20], Train Loss: 4.4890, Test Loss: 4.4389, Test Accuracy: 3.56%\n",
            "Epoch [9/20], Train Loss: 4.4735, Test Loss: 4.4258, Test Accuracy: 4.07%\n",
            "Epoch [10/20], Train Loss: 4.4577, Test Loss: 4.4113, Test Accuracy: 4.10%\n",
            "Epoch [11/20], Train Loss: 4.4406, Test Loss: 4.4010, Test Accuracy: 4.68%\n",
            "Epoch [12/20], Train Loss: 4.4021, Test Loss: 4.3862, Test Accuracy: 4.86%\n",
            "Epoch [13/20], Train Loss: 4.4145, Test Loss: 4.3722, Test Accuracy: 4.96%\n",
            "Epoch [14/20], Train Loss: 4.3759, Test Loss: 4.3565, Test Accuracy: 5.16%\n",
            "Epoch [15/20], Train Loss: 4.3765, Test Loss: 4.3489, Test Accuracy: 6.02%\n",
            "Epoch [16/20], Train Loss: 4.3470, Test Loss: 4.3337, Test Accuracy: 6.00%\n",
            "Epoch [17/20], Train Loss: 4.3384, Test Loss: 4.3164, Test Accuracy: 6.44%\n",
            "Epoch [18/20], Train Loss: 4.3224, Test Loss: 4.3083, Test Accuracy: 6.64%\n",
            "Epoch [19/20], Train Loss: 4.3172, Test Loss: 4.2984, Test Accuracy: 7.27%\n",
            "Epoch [20/20], Train Loss: 4.3013, Test Loss: 4.2878, Test Accuracy: 7.63%\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# Preprocess and load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_channels=3, num_out_ch=[8, 16, 32, 64], img_w=100, img_h=100, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "            nn.BatchNorm2d(num_out_ch[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "\n",
        "            nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "            nn.BatchNorm2d(num_out_ch[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "\n",
        "            nn.Conv2d(in_channels=num_out_ch[1], out_channels=num_out_ch[2],\n",
        "                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "            nn.BatchNorm2d(num_out_ch[2]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "\n",
        "            nn.Conv2d(in_channels=num_out_ch[2], out_channels=num_out_ch[3],\n",
        "                      kernel_size=(3,3), stride=(1,1), padding=(1,1)),\n",
        "            nn.BatchNorm2d(num_out_ch[3]),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=num_out_ch[3], out_features=num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the features\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the model\n",
        "num_classes = len(set(train_dataset._labels))\n",
        "model = MyCNN(num_channels=3, num_out_ch=[16, 32, 64, 128], img_w=224, img_h=224, num_classes=num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Train the model\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "best_test_loss = float(\"inf\")\n",
        "patience = 3\n",
        "bad_counter = 0\n",
        "\n",
        "# Cosine Annealing Learning Rate Scheduler\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')\n",
        "\n",
        "    # Early stopping and learning rate adjustment\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "        if bad_counter >= patience:\n",
        "            print(\"Adjusting learning rate...\")\n",
        "            scheduler.step()  # Update learning rate\n",
        "            bad_counter = 0  # Reset bad_counter\n",
        "\n",
        "# Plot the training and test losses\n",
        "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RSUkPC2i2dJ"
      },
      "source": [
        "USING RAY TUNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwkoYsi6eDKM",
        "outputId": "0ff84822-5618-4526-d75e-ec07b8be1f1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-05-02 09:29:34,153\tINFO worker.py:1749 -- Started a local Ray instance.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------+\n",
            "| Configuration for experiment     train_2024-05-02_09-29-36   |\n",
            "+--------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator       |\n",
            "| Scheduler                        FIFOScheduler               |\n",
            "| Number of trials                 10                          |\n",
            "+--------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_2024-05-02_09-29-36\n",
            "To visualize your results with TensorBoard, run: `tensorboard --logdir /tmp/ray/session_2024-05-02_09-29-30_595549_193/artifacts/2024-05-02_09-29-36/train_2024-05-02_09-29-36/driver_artifacts`\n",
            "\n",
            "Trial status: 10 PENDING\n",
            "Current time: 2024-05-02 09:29:37. Total running time: 0s\n",
            "Logical resource usage: 0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   PENDING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00000 started with configuration:\n",
            "+------------------------------------------+\n",
            "| Trial train_7e449_00000 config           |\n",
            "+------------------------------------------+\n",
            "| conv1_out_ch                          32 |\n",
            "| conv2_out_ch                          64 |\n",
            "| lr                                 1e-05 |\n",
            "+------------------------------------------+\n",
            "\u001b[36m(train pid=41848)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=41848)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<20:14, 283916.09it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:51, 447133.61it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:30, 499192.34it/s]\n",
            "  0%|          | 360448/344862509 [00:00<05:57, 964628.19it/s]\n",
            "  0%|          | 720896/344862509 [00:00<03:19, 1723150.64it/s]\n",
            "  0%|          | 1441792/344862509 [00:00<01:46, 3232533.55it/s]\n",
            "  1%|          | 2883584/344862509 [00:00<00:55, 6195458.75it/s]\n",
            "  2%|▏         | 5603328/344862509 [00:00<00:29, 11606123.25it/s]\n",
            "  2%|▏         | 7667712/344862509 [00:01<00:24, 13489754.48it/s]\n",
            "  3%|▎         | 10190848/344862509 [00:01<00:21, 15933635.50it/s]\n",
            "  4%|▎         | 12517376/344862509 [00:01<00:19, 17157128.49it/s]\n",
            "  4%|▍         | 15073280/344862509 [00:01<00:17, 18563480.62it/s]\n",
            "  5%|▌         | 17629184/344862509 [00:01<00:16, 19535568.63it/s]\n",
            "  6%|▌         | 20217856/344862509 [00:01<00:15, 20299473.81it/s]\n",
            "  7%|▋         | 22511616/344862509 [00:01<00:16, 20082376.25it/s]\n",
            "  7%|▋         | 25001984/344862509 [00:01<00:15, 20421716.11it/s]\n",
            "  8%|▊         | 27721728/344862509 [00:01<00:14, 21256168.40it/s]\n",
            "  9%|▉         | 30244864/344862509 [00:02<00:14, 21334198.28it/s]\n",
            " 10%|▉         | 32899072/344862509 [00:02<00:14, 21660480.45it/s]\n",
            " 10%|█         | 35487744/344862509 [00:02<00:14, 21850219.57it/s]\n",
            " 11%|█         | 37683200/344862509 [00:02<00:14, 20811886.27it/s]\n",
            " 12%|█▏        | 40042496/344862509 [00:02<00:14, 20699429.87it/s]\n",
            " 12%|█▏        | 43024384/344862509 [00:02<00:13, 22117527.61it/s]\n",
            " 13%|█▎        | 45809664/344862509 [00:02<00:13, 22579218.04it/s]\n",
            " 14%|█▍        | 48431104/344862509 [00:02<00:13, 22464263.91it/s]\n",
            " 15%|█▍        | 50823168/344862509 [00:03<00:13, 21918430.01it/s]\n",
            " 16%|█▌        | 53510144/344862509 [00:03<00:13, 22196502.52it/s]\n",
            " 16%|█▋        | 56262656/344862509 [00:03<00:12, 22581991.01it/s]\n",
            " 17%|█▋        | 59244544/344862509 [00:03<00:12, 23443884.56it/s]\n",
            " 18%|█▊        | 61865984/344862509 [00:03<00:12, 23101334.94it/s]\n",
            " 19%|█▉        | 64880640/344862509 [00:03<00:11, 23872569.44it/s]\n",
            " 20%|█▉        | 67829760/344862509 [00:03<00:11, 24207664.54it/s]\n",
            " 21%|██        | 70746112/344862509 [00:03<00:11, 24303061.70it/s]\n",
            " 21%|██▏       | 73859072/344862509 [00:03<00:10, 24844733.34it/s]\n",
            " 22%|██▏       | 76939264/344862509 [00:04<00:10, 25277226.18it/s]\n",
            " 23%|██▎       | 79757312/344862509 [00:04<00:10, 24810156.23it/s]\n",
            " 24%|██▍       | 82837504/344862509 [00:04<00:10, 25227487.21it/s]\n",
            " 25%|██▍       | 85655552/344862509 [00:04<00:10, 24871565.62it/s]\n",
            " 26%|██▌       | 88571904/344862509 [00:04<00:10, 24755075.91it/s]\n",
            " 26%|██▋       | 91258880/344862509 [00:04<00:10, 24283671.11it/s]\n",
            " 27%|██▋       | 94175232/344862509 [00:04<00:10, 24457852.60it/s]\n",
            " 28%|██▊       | 97189888/344862509 [00:04<00:10, 24703027.21it/s]\n",
            " 29%|██▉       | 100270080/344862509 [00:05<00:09, 25158716.83it/s]\n",
            " 30%|██▉       | 103153664/344862509 [00:05<00:09, 24762224.53it/s]\n",
            " 31%|███       | 105807872/344862509 [00:05<00:09, 24270243.44it/s]\n",
            " 31%|███▏      | 108593152/344862509 [00:05<00:09, 24076162.63it/s]\n",
            " 32%|███▏      | 111542272/344862509 [00:05<00:09, 24434207.66it/s]\n",
            " 33%|███▎      | 114294784/344862509 [00:05<00:09, 24133361.78it/s]\n",
            " 34%|███▍      | 116719616/344862509 [00:05<00:09, 22943361.05it/s]\n",
            " 35%|███▍      | 119046144/344862509 [00:05<00:10, 22157581.27it/s]\n",
            " 35%|███▌      | 122093568/344862509 [00:05<00:09, 23303399.90it/s]\n",
            " 36%|███▋      | 125108224/344862509 [00:06<00:09, 24019506.68it/s]\n",
            " 37%|███▋      | 128155648/344862509 [00:06<00:08, 24603288.88it/s]\n",
            " 38%|███▊      | 131170304/344862509 [00:06<00:08, 24930411.12it/s]\n",
            " 39%|███▉      | 133890048/344862509 [00:06<00:08, 24405333.02it/s]\n",
            " 40%|███▉      | 136708096/344862509 [00:06<00:08, 24292590.33it/s]\n",
            " 40%|████      | 139591680/344862509 [00:06<00:08, 24371281.20it/s]\n",
            " 41%|████▏     | 142573568/344862509 [00:06<00:08, 24672461.09it/s]\n",
            " 42%|████▏     | 145686528/344862509 [00:06<00:07, 25188259.17it/s]\n",
            " 43%|████▎     | 148733952/344862509 [00:07<00:07, 25479878.50it/s]\n",
            " 44%|████▍     | 151715840/344862509 [00:07<00:07, 25463305.34it/s]\n",
            " 45%|████▍     | 154763264/344862509 [00:07<00:07, 25609673.80it/s]\n",
            " 46%|████▌     | 157614080/344862509 [00:07<00:07, 25223452.87it/s]\n",
            " 47%|████▋     | 160595968/344862509 [00:07<00:07, 25273795.23it/s]\n",
            " 47%|████▋     | 163577856/344862509 [00:07<00:07, 25142172.50it/s]\n",
            " 48%|████▊     | 166690816/344862509 [00:07<00:06, 25539412.86it/s]\n",
            " 49%|████▉     | 169508864/344862509 [00:07<00:06, 25239383.90it/s]\n",
            " 50%|█████     | 172589056/344862509 [00:07<00:06, 25554485.65it/s]\n",
            " 51%|█████     | 175636480/344862509 [00:08<00:06, 25682642.24it/s]\n",
            " 52%|█████▏    | 178749440/344862509 [00:08<00:06, 25929700.71it/s]\n",
            " 53%|█████▎    | 181895168/344862509 [00:08<00:06, 26053905.23it/s]\n",
            " 54%|█████▎    | 184811520/344862509 [00:08<00:06, 25810950.73it/s]\n",
            " 54%|█████▍    | 187760640/344862509 [00:08<00:06, 25595374.73it/s]\n",
            " 55%|█████▌    | 190513152/344862509 [00:08<00:06, 24927065.66it/s]\n",
            " 56%|█████▌    | 193593344/344862509 [00:08<00:05, 25343267.04it/s]\n",
            " 57%|█████▋    | 196411392/344862509 [00:08<00:05, 24932911.68it/s]\n",
            " 58%|█████▊    | 199262208/344862509 [00:09<00:05, 24749572.64it/s]\n",
            " 59%|█████▊    | 202080256/344862509 [00:09<00:05, 24536751.11it/s]\n",
            " 59%|█████▉    | 204734464/344862509 [00:09<00:05, 23938988.29it/s]\n",
            " 60%|██████    | 207388672/344862509 [00:09<00:05, 23556166.85it/s]\n",
            " 61%|██████    | 210370560/344862509 [00:09<00:05, 24106386.45it/s]\n",
            " 62%|██████▏   | 213450752/344862509 [00:09<00:05, 24767483.22it/s]\n",
            " 63%|██████▎   | 216432640/344862509 [00:09<00:05, 24953351.84it/s]\n",
            " 64%|██████▎   | 219447296/344862509 [00:09<00:04, 25172295.96it/s]\n",
            " 65%|██████▍   | 222527488/344862509 [00:09<00:04, 25489187.74it/s]\n",
            " 65%|██████▌   | 225673216/344862509 [00:10<00:04, 25882105.72it/s]\n",
            " 66%|██████▋   | 228720640/344862509 [00:10<00:04, 25934776.08it/s]\n",
            " 67%|██████▋   | 231604224/344862509 [00:10<00:04, 25523333.13it/s]\n",
            " 68%|██████▊   | 234553344/344862509 [00:10<00:04, 25409806.57it/s]\n",
            " 69%|██████▉   | 237568000/344862509 [00:10<00:04, 25507283.26it/s]\n",
            " 70%|██████▉   | 240680960/344862509 [00:10<00:04, 25817457.51it/s]\n",
            " 71%|███████   | 243793920/344862509 [00:10<00:03, 26030457.02it/s]\n",
            " 72%|███████▏  | 246808576/344862509 [00:10<00:03, 25928217.09it/s]\n",
            " 72%|███████▏  | 249823232/344862509 [00:11<00:03, 25851262.71it/s]\n",
            " 73%|███████▎  | 252936192/344862509 [00:11<00:03, 26037777.08it/s]\n",
            " 74%|███████▍  | 255557632/344862509 [00:11<00:03, 24922588.11it/s]\n",
            " 75%|███████▍  | 258080768/344862509 [00:11<00:03, 23852170.48it/s]\n",
            " 76%|███████▌  | 260636672/344862509 [00:11<00:03, 23296470.35it/s]\n",
            " 76%|███████▋  | 263487488/344862509 [00:11<00:03, 23616309.29it/s]\n",
            " 77%|███████▋  | 266305536/344862509 [00:11<00:03, 23708608.92it/s]\n",
            " 78%|███████▊  | 269418496/344862509 [00:11<00:03, 24553197.52it/s]\n",
            " 79%|███████▉  | 272433152/344862509 [00:11<00:02, 24881974.24it/s]\n",
            " 80%|███████▉  | 275251200/344862509 [00:12<00:02, 24578653.82it/s]\n",
            " 81%|████████  | 278233088/344862509 [00:12<00:02, 24840522.96it/s]\n",
            " 81%|████████▏ | 281018368/344862509 [00:12<00:02, 24463918.97it/s]\n",
            " 82%|████████▏ | 283607040/344862509 [00:12<00:02, 23742671.74it/s]\n",
            " 83%|████████▎ | 286621696/344862509 [00:12<00:02, 24325573.21it/s]\n",
            " 84%|████████▍ | 289505280/344862509 [00:12<00:02, 24394812.79it/s]\n",
            " 85%|████████▍ | 292454400/344862509 [00:12<00:02, 24628821.37it/s]\n",
            " 86%|████████▌ | 295403520/344862509 [00:12<00:02, 24689927.18it/s]\n",
            " 87%|████████▋ | 298483712/344862509 [00:13<00:01, 25186763.69it/s]\n",
            " 87%|████████▋ | 301465600/344862509 [00:13<00:01, 25269802.93it/s]\n",
            " 88%|████████▊ | 304250880/344862509 [00:13<00:01, 24813815.43it/s]\n",
            " 89%|████████▉ | 307232768/344862509 [00:13<00:01, 24973767.43it/s]\n",
            " 90%|████████▉ | 309919744/344862509 [00:13<00:01, 21224114.48it/s]\n",
            " 91%|█████████ | 312147968/344862509 [00:13<00:02, 15074867.28it/s]\n",
            " 92%|█████████▏| 315785216/344862509 [00:13<00:01, 18364587.31it/s]\n",
            " 92%|█████████▏| 318865408/344862509 [00:14<00:01, 20207697.12it/s]\n",
            " 93%|█████████▎| 321912832/344862509 [00:14<00:01, 21678511.65it/s]\n",
            " 94%|█████████▍| 324599808/344862509 [00:14<00:00, 22001357.42it/s]\n",
            " 95%|█████████▍| 327483392/344862509 [00:14<00:00, 22706166.61it/s]\n",
            " 96%|█████████▌| 330563584/344862509 [00:14<00:00, 23707273.58it/s]\n",
            " 97%|█████████▋| 333447168/344862509 [00:14<00:00, 23962561.02it/s]\n",
            " 97%|█████████▋| 336068608/344862509 [00:14<00:00, 24505561.23it/s]\n",
            " 98%|█████████▊| 338591744/344862509 [00:14<00:00, 23897701.90it/s]\n",
            " 99%|█████████▉| 341016576/344862509 [00:14<00:00, 23033039.29it/s]\n",
            "100%|██████████| 344862509/344862509 [00:15<00:00, 22812456.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=41848)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:30:07. Total running time: 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "\u001b[36m(train pid=41848)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=41848)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1929918.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=41848)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=41848)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 47233976.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:30:37. Total running time: 1min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:31:07. Total running time: 1min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:31:37. Total running time: 2min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:32:07. Total running time: 2min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:32:37. Total running time: 3min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:33:07. Total running time: 3min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:33:37. Total running time: 4min 0s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:34:07. Total running time: 4min 30s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:34:38. Total running time: 5min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:35:08. Total running time: 5min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:35:38. Total running time: 6min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:36:08. Total running time: 6min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:36:38. Total running time: 7min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:37:08. Total running time: 7min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "Trial status: 1 RUNNING | 9 PENDING\n",
            "Current time: 2024-05-02 09:37:38. Total running time: 8min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------+\n",
            "| Trial name          status       conv1_out_ch     conv2_out_ch            lr |\n",
            "+------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   RUNNING                32               64   1.20162e-05 |\n",
            "| train_7e449_00001   PENDING                16               64   0.000133662 |\n",
            "| train_7e449_00002   PENDING                16               32   0.000913118 |\n",
            "| train_7e449_00003   PENDING                16               64   2.22106e-05 |\n",
            "| train_7e449_00004   PENDING                 8               16   1.54268e-05 |\n",
            "| train_7e449_00005   PENDING                16               16   0.000103507 |\n",
            "| train_7e449_00006   PENDING                 8               64   0.000142062 |\n",
            "| train_7e449_00007   PENDING                32               64   0.000170753 |\n",
            "| train_7e449_00008   PENDING                16               32   5.40184e-05 |\n",
            "| train_7e449_00009   PENDING                16               64   1.87446e-05 |\n",
            "+------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00000 finished iteration 1 at 2024-05-02 09:37:53. Total running time: 8min 16s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00000 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   489.728 |\n",
            "| time_total_s                       489.728 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.07757 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00000 completed after 1 iterations at 2024-05-02 09:37:53. Total running time: 8min 16s\n",
            "\n",
            "Trial train_7e449_00001 started with configuration:\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00001 config             |\n",
            "+--------------------------------------------+\n",
            "| conv1_out_ch                            16 |\n",
            "| conv2_out_ch                            64 |\n",
            "| lr                                 0.00013 |\n",
            "+--------------------------------------------+\n",
            "\u001b[36m(train pid=43944)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=43944)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<19:56, 288167.02it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:39, 453740.11it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:21, 505486.87it/s]\n",
            "  0%|          | 262144/344862509 [00:00<08:56, 642500.96it/s]\n",
            "  0%|          | 524288/344862509 [00:00<04:40, 1229078.15it/s]\n",
            "  0%|          | 1048576/344862509 [00:00<02:26, 2353239.00it/s]\n",
            "  1%|          | 2129920/344862509 [00:00<01:13, 4645037.14it/s]\n",
            "  1%|          | 4259840/344862509 [00:00<00:37, 9031816.99it/s]\n",
            "  2%|▏         | 6619136/344862509 [00:01<00:26, 12585987.58it/s]\n",
            "  3%|▎         | 8978432/344862509 [00:01<00:22, 14980089.82it/s]\n",
            "  3%|▎         | 11534336/344862509 [00:01<00:19, 17186781.74it/s]\n",
            "  4%|▍         | 13828096/344862509 [00:01<00:18, 17956873.92it/s]\n",
            "  5%|▍         | 16285696/344862509 [00:01<00:17, 18950391.53it/s]\n",
            "  5%|▌         | 18808832/344862509 [00:01<00:16, 19848401.42it/s]\n",
            "  6%|▌         | 21463040/344862509 [00:01<00:15, 20773671.78it/s]\n",
            "  7%|▋         | 23855104/344862509 [00:01<00:15, 20772525.53it/s]\n",
            "  8%|▊         | 26181632/344862509 [00:01<00:15, 20588390.39it/s]\n",
            "  8%|▊         | 28770304/344862509 [00:02<00:14, 21129475.78it/s]\n",
            "  9%|▉         | 31227904/344862509 [00:02<00:14, 21182316.96it/s]\n",
            " 10%|▉         | 34078720/344862509 [00:02<00:13, 22235899.74it/s]\n",
            " 11%|█         | 36306944/344862509 [00:02<00:14, 21322159.93it/s]\n",
            " 11%|█▏        | 38797312/344862509 [00:02<00:14, 21401018.04it/s]\n",
            " 12%|█▏        | 41779200/344862509 [00:02<00:13, 22722965.96it/s]\n",
            " 13%|█▎        | 44761088/344862509 [00:02<00:12, 23629634.66it/s]\n",
            " 14%|█▍        | 47677440/344862509 [00:02<00:12, 24108691.24it/s]\n",
            " 15%|█▍        | 50659328/344862509 [00:03<00:11, 24594678.78it/s]\n",
            " 16%|█▌        | 53641216/344862509 [00:03<00:11, 24953886.40it/s]\n",
            " 16%|█▋        | 56754176/344862509 [00:03<00:11, 25545076.47it/s]\n",
            " 17%|█▋        | 59572224/344862509 [00:03<00:11, 25074036.40it/s]\n",
            " 18%|█▊        | 62095360/344862509 [00:03<00:11, 24142022.14it/s]\n",
            " 19%|█▉        | 64880640/344862509 [00:03<00:11, 24198833.67it/s]\n",
            " 20%|█▉        | 67665920/344862509 [00:03<00:11, 24131714.21it/s]\n",
            " 21%|██        | 70778880/344862509 [00:03<00:10, 24927631.08it/s]\n",
            " 21%|██▏       | 73891840/344862509 [00:03<00:10, 25503268.31it/s]\n",
            " 22%|██▏       | 76939264/344862509 [00:04<00:10, 25757630.78it/s]\n",
            " 23%|██▎       | 80019456/344862509 [00:04<00:10, 26024889.82it/s]\n",
            " 24%|██▍       | 82935808/344862509 [00:04<00:10, 25796173.82it/s]\n",
            " 25%|██▍       | 85819392/344862509 [00:04<00:10, 25473050.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:38:08. Total running time: 8min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=43944)\u001b[0m \r 26%|██▌       | 88375296/344862509 [00:04<00:10, 24460653.46it/s]\n",
            " 26%|██▋       | 91029504/344862509 [00:04<00:10, 24069302.94it/s]\n",
            " 27%|██▋       | 93749248/344862509 [00:04<00:10, 23910228.63it/s]\n",
            " 28%|██▊       | 96862208/344862509 [00:04<00:10, 24790703.02it/s]\n",
            " 29%|██▉       | 99713024/344862509 [00:04<00:09, 24735135.16it/s]\n",
            " 30%|██▉       | 102400000/344862509 [00:05<00:10, 24129789.48it/s]\n",
            " 31%|███       | 105349120/344862509 [00:05<00:09, 24695435.21it/s]\n",
            " 31%|███▏      | 107839488/344862509 [00:05<00:09, 23735257.12it/s]\n",
            " 32%|███▏      | 110755840/344862509 [00:05<00:09, 24196964.22it/s]\n",
            " 33%|███▎      | 113737728/344862509 [00:05<00:09, 24680424.45it/s]\n",
            " 34%|███▍      | 116752384/344862509 [00:05<00:09, 25079602.03it/s]\n",
            " 35%|███▍      | 119734272/344862509 [00:05<00:08, 25297677.69it/s]\n",
            " 35%|███▌      | 122388480/344862509 [00:05<00:09, 24593534.69it/s]\n",
            " 36%|███▋      | 125075456/344862509 [00:06<00:09, 24176065.14it/s]\n",
            " 37%|███▋      | 127926272/344862509 [00:06<00:08, 24299031.90it/s]\n",
            " 38%|███▊      | 130875392/344862509 [00:06<00:08, 24667435.89it/s]\n",
            " 39%|███▊      | 133431296/344862509 [00:06<00:08, 23893810.17it/s]\n",
            " 39%|███▉      | 136052736/344862509 [00:06<00:08, 23512877.10it/s]\n",
            " 40%|████      | 139001856/344862509 [00:06<00:08, 24126806.16it/s]\n",
            " 41%|████      | 141885440/344862509 [00:06<00:08, 24281605.05it/s]\n",
            " 42%|████▏     | 144343040/344862509 [00:06<00:08, 23376868.78it/s]\n",
            " 43%|████▎     | 147423232/344862509 [00:06<00:08, 24366426.74it/s]\n",
            " 44%|████▎     | 150339584/344862509 [00:07<00:07, 24551558.23it/s]\n",
            " 44%|████▍     | 153387008/344862509 [00:07<00:07, 25088874.58it/s]\n",
            " 45%|████▌     | 156368896/344862509 [00:07<00:07, 25203929.79it/s]\n",
            " 46%|████▌     | 159285248/344862509 [00:07<00:07, 25230363.65it/s]\n",
            " 47%|████▋     | 162136064/344862509 [00:07<00:07, 24924172.83it/s]\n",
            " 48%|████▊     | 164986880/344862509 [00:07<00:07, 24980035.58it/s]\n",
            " 49%|████▊     | 167772160/344862509 [00:07<00:07, 24708976.33it/s]\n",
            " 49%|████▉     | 170557440/344862509 [00:07<00:07, 24513066.24it/s]\n",
            " 50%|█████     | 173375488/344862509 [00:07<00:07, 24467029.34it/s]\n",
            " 51%|█████     | 176128000/344862509 [00:08<00:06, 24265507.13it/s]\n",
            " 52%|█████▏    | 178716672/344862509 [00:08<00:07, 23697053.94it/s]\n",
            " 53%|█████▎    | 181370880/344862509 [00:08<00:06, 23475972.96it/s]\n",
            " 53%|█████▎    | 184123392/344862509 [00:08<00:06, 23561294.52it/s]\n",
            " 54%|█████▍    | 187203584/344862509 [00:08<00:06, 24486105.11it/s]\n",
            " 55%|█████▌    | 190119936/344862509 [00:08<00:06, 24712151.54it/s]\n",
            " 56%|█████▌    | 193101824/344862509 [00:08<00:06, 25028276.05it/s]\n",
            " 57%|█████▋    | 196083712/344862509 [00:08<00:05, 25251408.66it/s]\n",
            " 58%|█████▊    | 198868992/344862509 [00:09<00:05, 24896218.69it/s]\n",
            " 59%|█████▊    | 201850880/344862509 [00:09<00:05, 25162686.21it/s]\n",
            " 59%|█████▉    | 204603392/344862509 [00:09<00:05, 24752992.67it/s]\n",
            " 60%|██████    | 207093760/344862509 [00:09<00:05, 23519663.05it/s]\n",
            " 61%|██████    | 209977344/344862509 [00:09<00:05, 24210925.75it/s]\n",
            " 62%|██████▏   | 212729856/344862509 [00:09<00:05, 24102036.65it/s]\n",
            " 63%|██████▎   | 215678976/344862509 [00:09<00:05, 24363474.30it/s]\n",
            " 63%|██████▎   | 218628096/344862509 [00:09<00:05, 24872952.28it/s]\n",
            " 64%|██████▍   | 221577216/344862509 [00:09<00:04, 25051870.07it/s]\n",
            " 65%|██████▌   | 224526336/344862509 [00:10<00:04, 25171355.60it/s]\n",
            " 66%|██████▌   | 227508224/344862509 [00:10<00:04, 25353212.15it/s]\n",
            " 67%|██████▋   | 230129664/344862509 [00:10<00:04, 24548844.90it/s]\n",
            " 68%|██████▊   | 233111552/344862509 [00:10<00:04, 24911297.66it/s]\n",
            " 68%|██████▊   | 236191744/344862509 [00:10<00:04, 25444558.50it/s]\n",
            " 69%|██████▉   | 239271936/344862509 [00:10<00:04, 25803347.61it/s]\n",
            " 70%|███████   | 242024448/344862509 [00:10<00:04, 25159505.23it/s]\n",
            " 71%|███████   | 245104640/344862509 [00:10<00:03, 25615091.28it/s]\n",
            " 72%|███████▏  | 248086528/344862509 [00:10<00:03, 25655995.67it/s]\n",
            " 73%|███████▎  | 251035648/344862509 [00:11<00:03, 25610257.33it/s]\n",
            " 74%|███████▎  | 254083072/344862509 [00:11<00:03, 25840291.74it/s]\n",
            " 75%|███████▍  | 256966656/344862509 [00:11<00:03, 25580976.03it/s]\n",
            " 75%|███████▌  | 260014080/344862509 [00:11<00:03, 25808792.23it/s]\n",
            " 76%|███████▋  | 263127040/344862509 [00:11<00:03, 26145428.39it/s]\n",
            " 77%|███████▋  | 266076160/344862509 [00:11<00:03, 25940740.54it/s]\n",
            " 78%|███████▊  | 268763136/344862509 [00:11<00:03, 25128232.01it/s]\n",
            " 79%|███████▉  | 271745024/344862509 [00:11<00:02, 25344029.64it/s]\n",
            " 80%|███████▉  | 274694144/344862509 [00:12<00:02, 25382026.49it/s]\n",
            " 81%|████████  | 277676032/344862509 [00:12<00:02, 25477997.38it/s]\n",
            " 81%|████████▏ | 280559616/344862509 [00:12<00:02, 25320029.93it/s]\n",
            " 82%|████████▏ | 283541504/344862509 [00:12<00:02, 25477232.86it/s]\n",
            " 83%|████████▎ | 286556160/344862509 [00:12<00:02, 25662493.71it/s]\n",
            " 84%|████████▍ | 289538048/344862509 [00:12<00:02, 25689950.27it/s]\n",
            " 85%|████████▍ | 292552704/344862509 [00:12<00:02, 25802999.41it/s]\n",
            " 86%|████████▌ | 295272448/344862509 [00:12<00:01, 25132231.82it/s]\n",
            " 86%|████████▋ | 298156032/344862509 [00:12<00:01, 25077153.57it/s]\n",
            " 87%|████████▋ | 301236224/344862509 [00:13<00:01, 25558950.35it/s]\n",
            " 88%|████████▊ | 304185344/344862509 [00:13<00:01, 25534530.75it/s]\n",
            " 89%|████████▉ | 306970624/344862509 [00:13<00:01, 25088070.10it/s]\n",
            " 90%|████████▉ | 310018048/344862509 [00:13<00:01, 25478618.34it/s]\n",
            " 91%|█████████ | 313098240/344862509 [00:13<00:01, 25834247.00it/s]\n",
            " 92%|█████████▏| 315850752/344862509 [00:13<00:01, 25165078.53it/s]\n",
            " 92%|█████████▏| 318898176/344862509 [00:13<00:01, 25459727.34it/s]\n",
            " 93%|█████████▎| 322043904/344862509 [00:13<00:00, 25940323.86it/s]\n",
            " 94%|█████████▍| 325058560/344862509 [00:13<00:00, 26027546.91it/s]\n",
            " 95%|█████████▌| 327876608/344862509 [00:14<00:00, 25527509.59it/s]\n",
            " 96%|█████████▌| 330563584/344862509 [00:14<00:00, 24858802.69it/s]\n",
            " 97%|█████████▋| 333512704/344862509 [00:14<00:00, 25038053.83it/s]\n",
            " 98%|█████████▊| 336429056/344862509 [00:14<00:00, 25072442.40it/s]\n",
            " 98%|█████████▊| 339476480/344862509 [00:14<00:00, 25498671.94it/s]\n",
            " 99%|█████████▉| 342392832/344862509 [00:14<00:00, 25413251.88it/s]\n",
            "100%|██████████| 344862509/344862509 [00:14<00:00, 23403531.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=43944)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=43944)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=43944)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1716007.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=43944)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=43944)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 49308566.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:38:38. Total running time: 9min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:39:08. Total running time: 9min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:39:38. Total running time: 10min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:40:08. Total running time: 10min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:40:38. Total running time: 11min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:41:08. Total running time: 11min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:41:38. Total running time: 12min 1s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:42:08. Total running time: 12min 31s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:42:39. Total running time: 13min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:43:09. Total running time: 13min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 1 TERMINATED | 1 RUNNING | 8 PENDING\n",
            "Current time: 2024-05-02 09:43:39. Total running time: 14min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00001   RUNNING                  16               64   0.000133662                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00002   PENDING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00001 finished iteration 1 at 2024-05-02 09:43:55. Total running time: 14min 18s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00001 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   353.861 |\n",
            "| time_total_s                       353.861 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.09628 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00001 completed after 1 iterations at 2024-05-02 09:43:55. Total running time: 14min 18s\n",
            "\n",
            "Trial train_7e449_00002 started with configuration:\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00002 config             |\n",
            "+--------------------------------------------+\n",
            "| conv1_out_ch                            16 |\n",
            "| conv2_out_ch                            32 |\n",
            "| lr                                 0.00091 |\n",
            "+--------------------------------------------+\n",
            "\u001b[36m(train pid=45473)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=45473)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<19:51, 289497.53it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:46, 449728.25it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:23, 504119.45it/s]\n",
            "  0%|          | 229376/344862509 [00:00<10:47, 532274.85it/s]\n",
            "  0%|          | 360448/344862509 [00:00<07:38, 750909.30it/s]\n",
            "  0%|          | 720896/344862509 [00:00<03:40, 1558741.42it/s]\n",
            "  0%|          | 1376256/344862509 [00:00<01:58, 2908325.40it/s]\n",
            "  1%|          | 2719744/344862509 [00:00<01:00, 5680304.90it/s]\n",
            "  1%|▏         | 4784128/344862509 [00:01<00:35, 9508771.11it/s]\n",
            "  2%|▏         | 7143424/344862509 [00:01<00:26, 12885544.30it/s]\n",
            "  3%|▎         | 10190848/344862509 [00:01<00:19, 17022522.00it/s]\n",
            "  4%|▎         | 12582912/344862509 [00:01<00:18, 18164302.06it/s]\n",
            "  4%|▍         | 15138816/344862509 [00:01<00:17, 19370849.10it/s]\n",
            "  5%|▌         | 18251776/344862509 [00:01<00:15, 21659204.09it/s]\n",
            "  6%|▌         | 21233664/344862509 [00:01<00:14, 22918949.68it/s]\n",
            "  7%|▋         | 24313856/344862509 [00:01<00:13, 24051726.72it/s]\n",
            "  8%|▊         | 27197440/344862509 [00:01<00:13, 24333255.72it/s]\n",
            "  9%|▉         | 30310400/344862509 [00:02<00:12, 25117978.79it/s]\n",
            " 10%|▉         | 33423360/344862509 [00:02<00:12, 25648458.24it/s]\n",
            " 11%|█         | 36438016/344862509 [00:02<00:11, 25792616.63it/s]\n",
            " 11%|█▏        | 39321600/344862509 [00:02<00:11, 25551160.77it/s]\n",
            " 12%|█▏        | 42434560/344862509 [00:02<00:11, 25982801.69it/s]\n",
            " 13%|█▎        | 45580288/344862509 [00:02<00:11, 26331108.42it/s]\n",
            " 14%|█▍        | 48693248/344862509 [00:02<00:11, 26521314.33it/s]\n",
            " 15%|█▍        | 51445760/344862509 [00:02<00:11, 25724254.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:44:09. Total running time: 14min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=45473)\u001b[0m \r 16%|█▌        | 54394880/344862509 [00:02<00:11, 25670072.23it/s]\n",
            " 17%|█▋        | 57376768/344862509 [00:03<00:11, 25717969.98it/s]\n",
            " 17%|█▋        | 60194816/344862509 [00:03<00:11, 25328355.90it/s]\n",
            " 18%|█▊        | 63143936/344862509 [00:03<00:11, 25402719.04it/s]\n",
            " 19%|█▉        | 66256896/344862509 [00:03<00:10, 25874097.63it/s]\n",
            " 20%|██        | 69369856/344862509 [00:03<00:10, 26205028.30it/s]\n",
            " 21%|██        | 72384512/344862509 [00:03<00:10, 26189811.56it/s]\n",
            " 22%|██▏       | 75366400/344862509 [00:03<00:10, 26076596.22it/s]\n",
            " 23%|██▎       | 78512128/344862509 [00:03<00:10, 26438363.59it/s]\n",
            " 24%|██▎       | 81625088/344862509 [00:04<00:09, 26558545.99it/s]\n",
            " 24%|██▍       | 84344832/344862509 [00:04<00:10, 25714672.28it/s]\n",
            " 25%|██▌       | 87195648/344862509 [00:04<00:10, 25405924.13it/s]\n",
            " 26%|██▌       | 90243072/344862509 [00:04<00:09, 25620654.88it/s]\n",
            " 27%|██▋       | 93290496/344862509 [00:04<00:09, 25946884.61it/s]\n",
            " 28%|██▊       | 96206848/344862509 [00:04<00:09, 25737074.71it/s]\n",
            " 29%|██▉       | 99287040/344862509 [00:04<00:09, 26032886.77it/s]\n",
            " 30%|██▉       | 102137856/344862509 [00:04<00:09, 25619718.81it/s]\n",
            " 31%|███       | 105250816/344862509 [00:04<00:09, 26026123.25it/s]\n",
            " 31%|███▏      | 108232704/344862509 [00:05<00:09, 25965600.84it/s]\n",
            " 32%|███▏      | 111345664/344862509 [00:05<00:08, 26267554.58it/s]\n",
            " 33%|███▎      | 114491392/344862509 [00:05<00:08, 26309278.88it/s]\n",
            " 34%|███▍      | 117538816/344862509 [00:05<00:08, 26408893.28it/s]\n",
            " 35%|███▍      | 120258560/344862509 [00:05<00:08, 25548292.71it/s]\n",
            " 36%|███▌      | 123011072/344862509 [00:05<00:08, 25051523.79it/s]\n",
            " 37%|███▋      | 125992960/344862509 [00:05<00:08, 25291549.70it/s]\n",
            " 37%|███▋      | 128974848/344862509 [00:05<00:08, 25464050.45it/s]\n",
            " 38%|███▊      | 131858432/344862509 [00:06<00:08, 25313185.48it/s]\n",
            " 39%|███▉      | 134414336/344862509 [00:06<00:08, 24319388.90it/s]\n",
            " 40%|███▉      | 137068544/344862509 [00:06<00:08, 23960479.21it/s]\n",
            " 41%|████      | 139788288/344862509 [00:06<00:08, 23847933.44it/s]\n",
            " 41%|████▏     | 142835712/344862509 [00:06<00:08, 24620650.14it/s]\n",
            " 42%|████▏     | 145620992/344862509 [00:06<00:08, 24430080.74it/s]\n",
            " 43%|████▎     | 148733952/344862509 [00:06<00:07, 25188474.10it/s]\n",
            " 44%|████▍     | 151453696/344862509 [00:06<00:07, 24671677.32it/s]\n",
            " 45%|████▍     | 154468352/344862509 [00:06<00:07, 25072924.74it/s]\n",
            " 46%|████▌     | 157450240/344862509 [00:07<00:07, 25245863.08it/s]\n",
            " 47%|████▋     | 160563200/344862509 [00:07<00:07, 25766963.96it/s]\n",
            " 47%|████▋     | 163676160/344862509 [00:07<00:06, 26134217.06it/s]\n",
            " 48%|████▊     | 166526976/344862509 [00:07<00:06, 25714096.97it/s]\n",
            " 49%|████▉     | 169377792/344862509 [00:07<00:06, 25366613.78it/s]\n",
            " 50%|█████     | 172490752/344862509 [00:07<00:06, 25815032.51it/s]\n",
            " 51%|█████     | 175472640/344862509 [00:07<00:06, 25856538.06it/s]\n",
            " 52%|█████▏    | 178257920/344862509 [00:07<00:06, 25342539.01it/s]\n",
            " 52%|█████▏    | 181010432/344862509 [00:07<00:06, 24908008.13it/s]\n",
            " 53%|█████▎    | 183861248/344862509 [00:08<00:06, 24846187.27it/s]\n",
            " 54%|█████▍    | 186843136/344862509 [00:08<00:06, 25149570.71it/s]\n",
            " 55%|█████▌    | 189825024/344862509 [00:08<00:06, 25365055.44it/s]\n",
            " 56%|█████▌    | 192937984/344862509 [00:08<00:05, 25857517.96it/s]\n",
            " 57%|█████▋    | 195821568/344862509 [00:08<00:05, 25583402.37it/s]\n",
            " 58%|█████▊    | 198836224/344862509 [00:08<00:05, 25754057.03it/s]\n",
            " 58%|█████▊    | 201588736/344862509 [00:08<00:05, 25048163.73it/s]\n",
            " 59%|█████▉    | 204701696/344862509 [00:08<00:05, 25764186.33it/s]\n",
            " 60%|██████    | 207781888/344862509 [00:09<00:05, 26049634.82it/s]\n",
            " 61%|██████    | 210796544/344862509 [00:09<00:05, 26083978.63it/s]\n",
            " 62%|██████▏   | 213483520/344862509 [00:09<00:05, 25257584.64it/s]\n",
            " 63%|██████▎   | 216465408/344862509 [00:09<00:05, 25380205.85it/s]\n",
            " 64%|██████▎   | 219447296/344862509 [00:09<00:04, 25518038.99it/s]\n",
            " 65%|██████▍   | 222527488/344862509 [00:09<00:04, 25861393.35it/s]\n",
            " 65%|██████▌   | 225542144/344862509 [00:09<00:04, 25950421.98it/s]\n",
            " 66%|██████▋   | 228622336/344862509 [00:09<00:04, 26181479.42it/s]\n",
            " 67%|██████▋   | 231505920/344862509 [00:09<00:04, 25523206.39it/s]\n",
            " 68%|██████▊   | 234553344/344862509 [00:10<00:04, 25828751.04it/s]\n",
            " 69%|██████▉   | 237568000/344862509 [00:10<00:04, 25921469.73it/s]\n",
            " 70%|██████▉   | 240615424/344862509 [00:10<00:03, 26070195.34it/s]\n",
            " 71%|███████   | 243367936/344862509 [00:10<00:04, 25361790.17it/s]\n",
            " 71%|███████▏  | 246415360/344862509 [00:10<00:03, 25671570.88it/s]\n",
            " 72%|███████▏  | 249462784/344862509 [00:10<00:03, 25897520.51it/s]\n",
            " 73%|███████▎  | 252477440/344862509 [00:10<00:03, 25976864.98it/s]\n",
            " 74%|███████▍  | 255328256/344862509 [00:10<00:03, 25561519.10it/s]\n",
            " 75%|███████▍  | 258441216/344862509 [00:10<00:03, 26000240.27it/s]\n",
            " 76%|███████▌  | 261357568/344862509 [00:11<00:03, 25787447.33it/s]\n",
            " 77%|███████▋  | 264241152/344862509 [00:11<00:03, 25553844.39it/s]\n",
            " 77%|███████▋  | 267091968/344862509 [00:11<00:03, 25270929.19it/s]\n",
            " 78%|███████▊  | 270041088/344862509 [00:11<00:02, 25339698.60it/s]\n",
            " 79%|███████▉  | 273088512/344862509 [00:11<00:02, 25576177.29it/s]\n",
            " 80%|████████  | 276168704/344862509 [00:11<00:02, 25976729.93it/s]\n",
            " 81%|████████  | 279085056/344862509 [00:11<00:02, 25670545.34it/s]\n",
            " 82%|████████▏ | 282230784/344862509 [00:11<00:02, 26120012.62it/s]\n",
            " 83%|████████▎ | 285245440/344862509 [00:12<00:02, 26138431.56it/s]\n",
            " 84%|████████▎ | 288325632/344862509 [00:12<00:02, 26291797.20it/s]\n",
            " 85%|████████▍ | 291471360/344862509 [00:12<00:02, 26556348.38it/s]\n",
            " 85%|████████▌ | 294486016/344862509 [00:12<00:01, 26426098.37it/s]\n",
            " 86%|████████▋ | 297598976/344862509 [00:12<00:01, 26593693.05it/s]\n",
            " 87%|████████▋ | 300580864/344862509 [00:12<00:01, 26328428.53it/s]\n",
            " 88%|████████▊ | 303497216/344862509 [00:12<00:01, 26057666.74it/s]\n",
            " 89%|████████▉ | 306479104/344862509 [00:12<00:01, 25972937.91it/s]\n",
            " 90%|████████▉ | 309362688/344862509 [00:12<00:01, 25672672.18it/s]\n",
            " 91%|█████████ | 312475648/344862509 [00:13<00:01, 26063044.28it/s]\n",
            " 91%|█████████▏| 315359232/344862509 [00:13<00:01, 25738325.00it/s]\n",
            " 92%|█████████▏| 318341120/344862509 [00:13<00:01, 25771627.71it/s]\n",
            " 93%|█████████▎| 321323008/344862509 [00:13<00:00, 25798642.46it/s]\n",
            " 94%|█████████▍| 324403200/344862509 [00:13<00:00, 26065194.99it/s]\n",
            " 95%|█████████▍| 327286784/344862509 [00:13<00:00, 25719205.84it/s]\n",
            " 96%|█████████▌| 330366976/344862509 [00:13<00:00, 26013082.42it/s]\n",
            " 97%|█████████▋| 333512704/344862509 [00:13<00:00, 26402200.68it/s]\n",
            " 98%|█████████▊| 336560128/344862509 [00:13<00:00, 25432485.39it/s]\n",
            " 99%|█████████▊| 339705856/344862509 [00:14<00:00, 25929711.80it/s]\n",
            "100%|██████████| 344862509/344862509 [00:14<00:00, 24195686.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=45473)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=45473)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=45473)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1855101.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=45473)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=45473)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 46881746.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:44:39. Total running time: 15min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:45:09. Total running time: 15min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:45:39. Total running time: 16min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:46:09. Total running time: 16min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:46:39. Total running time: 17min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:47:09. Total running time: 17min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:47:39. Total running time: 18min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:48:09. Total running time: 18min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 2 TERMINATED | 1 RUNNING | 7 PENDING\n",
            "Current time: 2024-05-02 09:48:39. Total running time: 19min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00002   RUNNING                  16               32   0.000913118                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00003   PENDING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00002 finished iteration 1 at 2024-05-02 09:48:52. Total running time: 19min 15s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00002 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   288.532 |\n",
            "| time_total_s                       288.532 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.07985 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00002 completed after 1 iterations at 2024-05-02 09:48:52. Total running time: 19min 15s\n",
            "\n",
            "Trial train_7e449_00003 started with configuration:\n",
            "+------------------------------------------+\n",
            "| Trial train_7e449_00003 config           |\n",
            "+------------------------------------------+\n",
            "| conv1_out_ch                          16 |\n",
            "| conv2_out_ch                          64 |\n",
            "| lr                                 2e-05 |\n",
            "+------------------------------------------+\n",
            "\u001b[36m(train pid=46749)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=46749)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<20:00, 287302.59it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:44, 451041.86it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:24, 503232.20it/s]\n",
            "  0%|          | 327680/344862509 [00:00<06:39, 861965.04it/s]\n",
            "  0%|          | 688128/344862509 [00:00<03:25, 1670954.01it/s]\n",
            "  0%|          | 1409024/344862509 [00:00<01:46, 3212721.68it/s]\n",
            "  1%|          | 2850816/344862509 [00:00<00:54, 6220397.27it/s]\n",
            "  2%|▏         | 5701632/344862509 [00:00<00:28, 12055690.06it/s]\n",
            "  2%|▏         | 7700480/344862509 [00:01<00:24, 13638114.16it/s]\n",
            "  3%|▎         | 10747904/344862509 [00:01<00:19, 17555825.68it/s]\n",
            "  4%|▍         | 13107200/344862509 [00:01<00:18, 18394219.96it/s]\n",
            "  5%|▍         | 16252928/344862509 [00:01<00:15, 21010625.47it/s]\n",
            "  6%|▌         | 19300352/344862509 [00:01<00:14, 22594725.10it/s]\n",
            "  6%|▋         | 22413312/344862509 [00:01<00:13, 23863135.00it/s]\n",
            "  7%|▋         | 25329664/344862509 [00:01<00:13, 24227587.10it/s]\n",
            "  8%|▊         | 28475392/344862509 [00:01<00:12, 25094075.67it/s]\n",
            "  9%|▉         | 31588352/344862509 [00:01<00:12, 25427216.02it/s]\n",
            " 10%|█         | 34537472/344862509 [00:02<00:12, 25598205.99it/s]\n",
            " 11%|█         | 37519360/344862509 [00:02<00:11, 25618445.54it/s]\n",
            " 12%|█▏        | 40108032/344862509 [00:02<00:12, 24591541.47it/s]\n",
            " 12%|█▏        | 42893312/344862509 [00:02<00:12, 24416248.10it/s]\n",
            " 13%|█▎        | 45645824/344862509 [00:02<00:12, 24198049.14it/s]\n",
            " 14%|█▍        | 48660480/344862509 [00:02<00:11, 24735248.67it/s]\n",
            " 15%|█▍        | 51412992/344862509 [00:02<00:12, 24407922.84it/s]\n",
            " 16%|█▌        | 54198272/344862509 [00:02<00:11, 24281875.17it/s]\n",
            " 17%|█▋        | 57180160/344862509 [00:03<00:11, 24642898.51it/s]\n",
            " 17%|█▋        | 59998208/344862509 [00:03<00:11, 24405400.11it/s]\n",
            " 18%|█▊        | 62750720/344862509 [00:03<00:11, 24333270.69it/s]\n",
            " 19%|█▉        | 65863680/344862509 [00:03<00:11, 24891747.24it/s]\n",
            " 20%|█▉        | 68943872/344862509 [00:03<00:10, 25370675.70it/s]\n",
            " 21%|██        | 71860224/344862509 [00:03<00:10, 25251600.86it/s]\n",
            " 22%|██▏       | 74874880/344862509 [00:03<00:10, 25518481.44it/s]\n",
            " 23%|██▎       | 77824000/344862509 [00:03<00:10, 25458391.01it/s]\n",
            " 23%|██▎       | 80478208/344862509 [00:03<00:10, 24617200.82it/s]\n",
            " 24%|██▍       | 83361792/344862509 [00:04<00:10, 24730138.56it/s]\n",
            " 25%|██▍       | 86114304/344862509 [00:04<00:10, 24417464.69it/s]\n",
            " 26%|██▌       | 88834048/344862509 [00:04<00:10, 24076611.67it/s]\n",
            " 27%|██▋       | 91979776/344862509 [00:04<00:10, 24937969.93it/s]\n",
            " 28%|██▊       | 95125504/344862509 [00:04<00:09, 25565511.59it/s]\n",
            " 28%|██▊       | 98172928/344862509 [00:04<00:09, 25769983.87it/s]\n",
            " 29%|██▉       | 101220352/344862509 [00:04<00:09, 25923468.04it/s]\n",
            " 30%|███       | 104300544/344862509 [00:04<00:09, 26115543.58it/s]\n",
            " 31%|███       | 106987520/344862509 [00:04<00:09, 25191618.97it/s]\n",
            " 32%|███▏      | 110100480/344862509 [00:05<00:09, 25692104.99it/s]\n",
            " 33%|███▎      | 113082368/344862509 [00:05<00:09, 25690777.32it/s]\n",
            " 34%|███▎      | 116162560/344862509 [00:05<00:08, 25941339.97it/s]\n",
            " 35%|███▍      | 119242752/344862509 [00:05<00:08, 26099692.20it/s]\n",
            " 35%|███▌      | 122257408/344862509 [00:05<00:08, 25453190.90it/s]\n",
            " 36%|███▋      | 125370368/344862509 [00:05<00:08, 25831716.82it/s]\n",
            " 37%|███▋      | 127959040/344862509 [00:05<00:08, 24769000.78it/s]\n",
            " 38%|███▊      | 131039232/344862509 [00:05<00:08, 25295852.77it/s]\n",
            " 39%|███▉      | 134119424/344862509 [00:06<00:08, 25659193.43it/s]\n",
            " 40%|███▉      | 137166848/344862509 [00:06<00:08, 25822701.39it/s]\n",
            " 41%|████      | 140148736/344862509 [00:06<00:07, 25772295.39it/s]\n",
            " 41%|████▏     | 143065088/344862509 [00:06<00:07, 25468367.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:49:09. Total running time: 19min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=46749)\u001b[0m \r 42%|████▏     | 146145280/344862509 [00:06<00:07, 25734143.59it/s]\n",
            " 43%|████▎     | 148930560/344862509 [00:06<00:07, 25213118.46it/s]\n",
            " 44%|████▍     | 152010752/344862509 [00:06<00:07, 25591138.33it/s]\n",
            " 45%|████▍     | 154828800/344862509 [00:06<00:07, 25199512.80it/s]\n",
            " 46%|████▌     | 157876224/344862509 [00:06<00:07, 25502861.66it/s]\n",
            " 47%|████▋     | 160661504/344862509 [00:07<00:07, 25053088.51it/s]\n",
            " 47%|████▋     | 163807232/344862509 [00:07<00:07, 25620236.62it/s]\n",
            " 48%|████▊     | 166723584/344862509 [00:07<00:06, 25488050.29it/s]\n",
            " 49%|████▉     | 169508864/344862509 [00:07<00:07, 25036911.36it/s]\n",
            " 50%|█████     | 172654592/344862509 [00:07<00:06, 25642418.90it/s]\n",
            " 51%|█████     | 175636480/344862509 [00:07<00:06, 25618260.30it/s]\n",
            " 52%|█████▏    | 178552832/344862509 [00:07<00:06, 25454945.48it/s]\n",
            " 53%|█████▎    | 181567488/344862509 [00:07<00:06, 25603253.03it/s]\n",
            " 54%|█████▎    | 184713216/344862509 [00:08<00:06, 26021684.00it/s]\n",
            " 54%|█████▍    | 187793408/344862509 [00:08<00:05, 26180285.27it/s]\n",
            " 55%|█████▌    | 190742528/344862509 [00:08<00:05, 25929069.09it/s]\n",
            " 56%|█████▌    | 193495040/344862509 [00:08<00:05, 25257630.00it/s]\n",
            " 57%|█████▋    | 196542464/344862509 [00:08<00:05, 25563011.57it/s]\n",
            " 58%|█████▊    | 199655424/344862509 [00:08<00:05, 25923618.43it/s]\n",
            " 59%|█████▊    | 202276864/344862509 [00:08<00:05, 24877731.17it/s]\n",
            " 59%|█████▉    | 205062144/344862509 [00:08<00:05, 24644871.41it/s]\n",
            " 60%|██████    | 208076800/344862509 [00:08<00:05, 24979756.46it/s]\n",
            " 61%|██████    | 211124224/344862509 [00:09<00:05, 25404026.02it/s]\n",
            " 62%|██████▏   | 214138880/344862509 [00:09<00:05, 25573613.21it/s]\n",
            " 63%|██████▎   | 217153536/344862509 [00:09<00:04, 25678198.39it/s]\n",
            " 64%|██████▍   | 220266496/344862509 [00:09<00:04, 26003405.17it/s]\n",
            " 65%|██████▍   | 223281152/344862509 [00:09<00:04, 25986435.60it/s]\n",
            " 66%|██████▌   | 226295808/344862509 [00:09<00:04, 25966675.59it/s]\n",
            " 67%|██████▋   | 229376000/344862509 [00:09<00:04, 26139577.79it/s]\n",
            " 67%|██████▋   | 232390656/344862509 [00:09<00:04, 26068766.70it/s]\n",
            " 68%|██████▊   | 235405312/344862509 [00:10<00:04, 26028609.12it/s]\n",
            " 69%|██████▉   | 238223360/344862509 [00:10<00:04, 25490123.71it/s]\n",
            " 70%|██████▉   | 241336320/344862509 [00:10<00:04, 25879948.63it/s]\n",
            " 71%|███████   | 244383744/344862509 [00:10<00:03, 25977252.98it/s]\n",
            " 72%|███████▏  | 247496704/344862509 [00:10<00:03, 26225033.33it/s]\n",
            " 73%|███████▎  | 250380288/344862509 [00:10<00:03, 25793869.61it/s]\n",
            " 73%|███████▎  | 253394944/344862509 [00:10<00:03, 25841520.95it/s]\n",
            " 74%|███████▍  | 256507904/344862509 [00:10<00:03, 26111673.42it/s]\n",
            " 75%|███████▌  | 259620864/344862509 [00:10<00:03, 26265061.00it/s]\n",
            " 76%|███████▌  | 262504448/344862509 [00:11<00:03, 25756492.87it/s]\n",
            " 77%|███████▋  | 265617408/344862509 [00:11<00:03, 26096012.34it/s]\n",
            " 78%|███████▊  | 268730368/344862509 [00:11<00:02, 26327024.13it/s]\n",
            " 79%|███████▉  | 271876096/344862509 [00:11<00:02, 26468010.82it/s]\n",
            " 80%|███████▉  | 274530304/344862509 [00:11<00:02, 25198275.06it/s]\n",
            " 80%|████████  | 277053440/344862509 [00:11<00:02, 24371581.84it/s]\n",
            " 81%|████████  | 279937024/344862509 [00:11<00:02, 24505977.08it/s]\n",
            " 82%|████████▏ | 282624000/344862509 [00:11<00:02, 24109070.78it/s]\n",
            " 83%|████████▎ | 285671424/344862509 [00:11<00:02, 24746265.03it/s]\n",
            " 84%|████████▎ | 288686080/344862509 [00:12<00:02, 25100968.08it/s]\n",
            " 85%|████████▍ | 291504128/344862509 [00:12<00:02, 24820160.07it/s]\n",
            " 85%|████████▌ | 294354944/344862509 [00:12<00:02, 24729191.11it/s]\n",
            " 86%|████████▌ | 297336832/344862509 [00:12<00:01, 24964449.03it/s]\n",
            " 87%|████████▋ | 300449792/344862509 [00:12<00:01, 25554823.64it/s]\n",
            " 88%|████████▊ | 303398912/344862509 [00:12<00:01, 25504210.41it/s]\n",
            " 89%|████████▉ | 306282496/344862509 [00:12<00:01, 25307788.14it/s]\n",
            " 90%|████████▉ | 309297152/344862509 [00:12<00:01, 25494187.95it/s]\n",
            " 91%|█████████ | 312410112/344862509 [00:13<00:01, 25887082.09it/s]\n",
            " 91%|█████████▏| 315195392/344862509 [00:13<00:01, 25244342.72it/s]\n",
            " 92%|█████████▏| 318275584/344862509 [00:13<00:01, 25644140.62it/s]\n",
            " 93%|█████████▎| 321290240/344862509 [00:13<00:00, 25730673.48it/s]\n",
            " 94%|█████████▍| 324075520/344862509 [00:13<00:00, 25154253.92it/s]\n",
            " 95%|█████████▍| 327090176/344862509 [00:13<00:00, 25394721.40it/s]\n",
            " 96%|█████████▌| 329940992/344862509 [00:13<00:00, 25135183.00it/s]\n",
            " 97%|█████████▋| 332890112/344862509 [00:13<00:00, 25178714.07it/s]\n",
            " 97%|█████████▋| 335970304/344862509 [00:13<00:00, 25584273.99it/s]\n",
            " 98%|█████████▊| 339017728/344862509 [00:14<00:00, 25778452.37it/s]\n",
            " 99%|█████████▉| 341803008/344862509 [00:14<00:00, 25222470.33it/s]\n",
            "100%|██████████| 344862509/344862509 [00:14<00:00, 24095006.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=46749)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=46749)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=46749)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1720212.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=46749)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=46749)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 50014656.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:49:39. Total running time: 20min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:50:09. Total running time: 20min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:50:39. Total running time: 21min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:51:09. Total running time: 21min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:51:39. Total running time: 22min 2s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:52:09. Total running time: 22min 32s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:52:40. Total running time: 23min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:53:10. Total running time: 23min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:53:40. Total running time: 24min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:54:10. Total running time: 24min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 3 TERMINATED | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-05-02 09:54:40. Total running time: 25min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00003   RUNNING                  16               64   2.22106e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00004   PENDING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00003 finished iteration 1 at 2024-05-02 09:54:48. Total running time: 25min 11s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00003 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   347.978 |\n",
            "| time_total_s                       347.978 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.09221 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00003 completed after 1 iterations at 2024-05-02 09:54:48. Total running time: 25min 11s\n",
            "\n",
            "Trial train_7e449_00004 started with configuration:\n",
            "+------------------------------------------+\n",
            "| Trial train_7e449_00004 config           |\n",
            "+------------------------------------------+\n",
            "| conv1_out_ch                           8 |\n",
            "| conv2_out_ch                          16 |\n",
            "| lr                                 2e-05 |\n",
            "+------------------------------------------+\n",
            "\u001b[36m(train pid=48262)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=48262)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<20:10, 284979.87it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:50, 447272.07it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:28, 500304.04it/s]\n",
            "  0%|          | 294912/344862509 [00:00<07:41, 747413.25it/s]\n",
            "  0%|          | 589824/344862509 [00:00<04:07, 1391511.04it/s]\n",
            "  0%|          | 1179648/344862509 [00:00<02:10, 2628568.59it/s]\n",
            "  1%|          | 2392064/344862509 [00:00<01:06, 5179777.66it/s]\n",
            "  1%|▏         | 4751360/344862509 [00:00<00:34, 9980271.83it/s]\n",
            "  2%|▏         | 7143424/344862509 [00:01<00:25, 13278630.98it/s]\n",
            "  3%|▎         | 10289152/344862509 [00:01<00:19, 17511932.45it/s]\n",
            "  4%|▍         | 13172736/344862509 [00:01<00:16, 19723442.84it/s]\n",
            "  5%|▍         | 16318464/344862509 [00:01<00:14, 21916587.34it/s]\n",
            "  6%|▌         | 19464192/344862509 [00:01<00:13, 23416520.09it/s]\n",
            "  6%|▋         | 22347776/344862509 [00:01<00:13, 23809141.50it/s]\n",
            "  7%|▋         | 25395200/344862509 [00:01<00:13, 24520392.04it/s]\n",
            "  8%|▊         | 28377088/344862509 [00:01<00:12, 24824838.60it/s]\n",
            "  9%|▉         | 31129600/344862509 [00:01<00:12, 24453345.85it/s]\n",
            " 10%|▉         | 34045952/344862509 [00:02<00:12, 24631858.13it/s]\n",
            " 11%|█         | 36634624/344862509 [00:02<00:12, 23912182.05it/s]\n",
            " 11%|█▏        | 39583744/344862509 [00:02<00:12, 24329402.87it/s]\n",
            " 12%|█▏        | 42500096/344862509 [00:02<00:12, 24535759.42it/s]\n",
            " 13%|█▎        | 45252608/344862509 [00:02<00:12, 24266446.65it/s]\n",
            " 14%|█▍        | 48168960/344862509 [00:02<00:12, 24462710.75it/s]\n",
            " 15%|█▍        | 51150848/344862509 [00:02<00:11, 24790633.61it/s]\n",
            " 16%|█▌        | 54099968/344862509 [00:02<00:11, 24912119.64it/s]\n",
            " 16%|█▋        | 56852480/344862509 [00:03<00:11, 24538395.29it/s]\n",
            " 17%|█▋        | 59539456/344862509 [00:03<00:11, 24109433.64it/s]\n",
            " 18%|█▊        | 62423040/344862509 [00:03<00:11, 24304821.68it/s]\n",
            " 19%|█▉        | 65503232/344862509 [00:03<00:11, 24941898.64it/s]\n",
            " 20%|█▉        | 68517888/344862509 [00:03<00:10, 25204828.09it/s]\n",
            " 21%|██        | 71467008/344862509 [00:03<00:10, 25259536.52it/s]\n",
            " 22%|██▏       | 74547200/344862509 [00:03<00:10, 25485497.02it/s]\n",
            " 22%|██▏       | 77103104/344862509 [00:03<00:10, 24403960.69it/s]\n",
            " 23%|██▎       | 79560704/344862509 [00:03<00:11, 23476071.42it/s]\n",
            " 24%|██▍       | 82575360/344862509 [00:04<00:10, 24194129.38it/s]\n",
            " 25%|██▍       | 85590016/344862509 [00:04<00:10, 24729509.18it/s]\n",
            " 26%|██▌       | 88539136/344862509 [00:04<00:10, 24887228.93it/s]\n",
            " 27%|██▋       | 91488256/344862509 [00:04<00:10, 25017962.44it/s]\n",
            " 27%|██▋       | 94601216/344862509 [00:04<00:09, 25516257.37it/s]\n",
            " 28%|██▊       | 97615872/344862509 [00:04<00:09, 25617562.05it/s]\n",
            " 29%|██▉       | 100433920/344862509 [00:04<00:09, 25110204.42it/s]\n",
            " 30%|██▉       | 103448576/344862509 [00:04<00:09, 25393140.93it/s]\n",
            " 31%|███       | 106463232/344862509 [00:05<00:09, 25538230.51it/s]\n",
            " 32%|███▏      | 109281280/344862509 [00:05<00:09, 25053339.09it/s]\n",
            " 33%|███▎      | 112230400/344862509 [00:05<00:09, 25152087.39it/s]\n",
            " 33%|███▎      | 114753536/344862509 [00:05<00:09, 24029419.97it/s]\n",
            " 34%|███▍      | 117571584/344862509 [00:05<00:09, 24020638.74it/s]\n",
            " 35%|███▍      | 120225792/344862509 [00:05<00:09, 23699395.12it/s]\n",
            " 36%|███▌      | 122617856/344862509 [00:05<00:09, 22395341.54it/s]\n",
            " 36%|███▌      | 124878848/344862509 [00:05<00:11, 19990381.82it/s]\n",
            " 37%|███▋      | 127172608/344862509 [00:05<00:10, 20572270.02it/s]\n",
            " 37%|███▋      | 129269760/344862509 [00:06<00:10, 20319411.75it/s]\n",
            " 38%|███▊      | 131366912/344862509 [00:06<00:10, 20238388.52it/s]\n",
            " 39%|███▉      | 133955584/344862509 [00:06<00:10, 20795929.75it/s]\n",
            " 40%|███▉      | 136609792/344862509 [00:06<00:09, 21280203.83it/s]\n",
            " 40%|████      | 139362304/344862509 [00:06<00:09, 22073401.46it/s]\n",
            " 41%|████▏     | 142311424/344862509 [00:06<00:08, 23061769.31it/s]\n",
            " 42%|████▏     | 144637952/344862509 [00:06<00:09, 21956910.15it/s]\n",
            " 43%|████▎     | 147324928/344862509 [00:06<00:08, 22446885.41it/s]\n",
            " 44%|████▎     | 150142976/344862509 [00:06<00:08, 22945041.59it/s]\n",
            " 44%|████▍     | 153092096/344862509 [00:07<00:08, 23655150.75it/s]\n",
            " 45%|████▌     | 155910144/344862509 [00:07<00:07, 23775816.59it/s]\n",
            " 46%|████▌     | 158859264/344862509 [00:07<00:07, 24251554.33it/s]\n",
            " 47%|████▋     | 161579008/344862509 [00:07<00:07, 23971930.29it/s]\n",
            " 48%|████▊     | 164626432/344862509 [00:07<00:07, 24630344.16it/s]\n",
            " 49%|████▊     | 167313408/344862509 [00:07<00:07, 24161115.81it/s]\n",
            " 49%|████▉     | 170426368/344862509 [00:07<00:06, 24928202.90it/s]\n",
            " 50%|█████     | 173342720/344862509 [00:07<00:06, 24776520.23it/s]\n",
            " 51%|█████     | 175833088/344862509 [00:08<00:07, 23734896.10it/s]\n",
            " 52%|█████▏    | 178716672/344862509 [00:08<00:07, 22371133.32it/s]\n",
            " 53%|█████▎    | 181731328/344862509 [00:08<00:07, 22942822.67it/s]\n",
            " 54%|█████▎    | 184516608/344862509 [00:08<00:06, 24150358.17it/s]\n",
            " 54%|█████▍    | 186974208/344862509 [00:08<00:06, 23747651.25it/s]\n",
            " 55%|█████▍    | 189399040/344862509 [00:08<00:06, 22890992.24it/s]\n",
            " 56%|█████▌    | 191791104/344862509 [00:08<00:06, 22811253.24it/s]\n",
            " 56%|█████▋    | 194609152/344862509 [00:08<00:06, 23129217.96it/s]\n",
            " 57%|█████▋    | 196935680/344862509 [00:09<00:07, 20753756.24it/s]\n",
            " 58%|█████▊    | 200048640/344862509 [00:09<00:06, 23158822.14it/s]\n",
            " 59%|█████▉    | 202932224/344862509 [00:09<00:05, 24247731.42it/s]\n",
            " 60%|██████    | 208306176/344862509 [00:09<00:05, 24744325.31it/s]\n",
            " 61%|██████    | 210829312/344862509 [00:09<00:05, 24006558.15it/s]\n",
            " 62%|██████▏   | 213254144/344862509 [00:09<00:05, 23478658.27it/s]\n",
            " 63%|██████▎   | 215777280/344862509 [00:09<00:05, 23186291.12it/s]\n",
            " 63%|██████▎   | 218136576/344862509 [00:09<00:05, 22613777.94it/s]\n",
            " 64%|██████▍   | 220954624/344862509 [00:09<00:05, 24121723.35it/s]\n",
            " 65%|██████▍   | 223739904/344862509 [00:10<00:04, 24379334.73it/s]\n",
            " 66%|██████▌   | 226426880/344862509 [00:10<00:04, 24400071.05it/s]\n",
            " 66%|██████▋   | 228884480/344862509 [00:10<00:04, 23258696.73it/s]\n",
            " 67%|██████▋   | 231243776/344862509 [00:10<00:04, 22952200.16it/s]\n",
            " 68%|██████▊   | 233570304/344862509 [00:10<00:05, 21381969.73it/s]\n",
            " 68%|██████▊   | 235732992/344862509 [00:10<00:07, 14462152.20it/s]\n",
            " 69%|██████▉   | 237502464/344862509 [00:11<00:08, 13311147.74it/s]\n",
            " 70%|██████▉   | 240353280/344862509 [00:11<00:06, 15242579.57it/s]\n",
            " 70%|███████   | 242057216/344862509 [00:11<00:07, 13787433.05it/s]\n",
            " 71%|███████▏  | 245989376/344862509 [00:11<00:05, 19097993.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-05-02 09:55:10. Total running time: 25min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00004   RUNNING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=48262)\u001b[0m \r 72%|███████▏  | 248217600/344862509 [00:11<00:07, 13653282.95it/s]\n",
            " 73%|███████▎  | 252411904/344862509 [00:11<00:04, 18585004.60it/s]\n",
            " 74%|███████▍  | 255557632/344862509 [00:11<00:04, 20516877.67it/s]\n",
            " 75%|███████▍  | 258048000/344862509 [00:12<00:06, 14174059.77it/s]\n",
            " 75%|███████▌  | 260177920/344862509 [00:12<00:05, 15336683.93it/s]\n",
            " 77%|███████▋  | 264044544/344862509 [00:12<00:04, 19932366.42it/s]\n",
            " 77%|███████▋  | 266600448/344862509 [00:12<00:03, 19581274.73it/s]\n",
            " 78%|███████▊  | 269221888/344862509 [00:12<00:03, 20728756.68it/s]\n",
            " 79%|███████▉  | 271613952/344862509 [00:12<00:03, 20599777.11it/s]\n",
            " 80%|███████▉  | 274759680/344862509 [00:12<00:03, 22280370.81it/s]\n",
            " 80%|████████  | 277544960/344862509 [00:13<00:02, 23254496.76it/s]\n",
            " 81%|████████  | 280002560/344862509 [00:13<00:02, 23520845.20it/s]\n",
            " 82%|████████▏ | 282787840/344862509 [00:13<00:02, 23723217.42it/s]\n",
            " 83%|████████▎ | 285245440/344862509 [00:13<00:02, 20294341.93it/s]\n",
            " 83%|████████▎ | 287866880/344862509 [00:13<00:02, 21528663.61it/s]\n",
            " 84%|████████▍ | 290881536/344862509 [00:13<00:02, 22698780.84it/s]\n",
            " 85%|████████▌ | 293601280/344862509 [00:13<00:02, 23802473.37it/s]\n",
            " 86%|████████▌ | 296058880/344862509 [00:13<00:02, 22765246.51it/s]\n",
            " 87%|████████▋ | 298418176/344862509 [00:14<00:02, 19612864.08it/s]\n",
            " 87%|████████▋ | 301170688/344862509 [00:14<00:02, 20670339.96it/s]\n",
            " 88%|████████▊ | 303726592/344862509 [00:14<00:01, 21406434.25it/s]\n",
            " 89%|████████▉ | 306446336/344862509 [00:14<00:01, 21622306.08it/s]\n",
            " 90%|████████▉ | 309428224/344862509 [00:14<00:01, 22768147.02it/s]\n",
            " 90%|█████████ | 311951360/344862509 [00:14<00:01, 22434138.95it/s]\n",
            " 91%|█████████▏| 314802176/344862509 [00:14<00:01, 23022205.99it/s]\n",
            " 92%|█████████▏| 317620224/344862509 [00:14<00:01, 23321341.06it/s]\n",
            " 93%|█████████▎| 320372736/344862509 [00:14<00:01, 23412832.53it/s]\n",
            " 94%|█████████▍| 323485696/344862509 [00:15<00:00, 24401286.91it/s]\n",
            " 95%|█████████▍| 326402048/344862509 [00:15<00:00, 24591752.01it/s]\n",
            " 96%|█████████▌| 329383936/344862509 [00:15<00:00, 24891326.32it/s]\n",
            " 96%|█████████▋| 332300288/344862509 [00:15<00:00, 24906325.81it/s]\n",
            " 97%|█████████▋| 335183872/344862509 [00:15<00:00, 24855652.60it/s]\n",
            " 98%|█████████▊| 338264064/344862509 [00:15<00:00, 25292519.55it/s]\n",
            " 99%|█████████▉| 341245952/344862509 [00:15<00:00, 25416935.40it/s]\n",
            "100%|█████████▉| 344195072/344862509 [00:15<00:00, 25393567.33it/s]\n",
            "100%|██████████| 344862509/344862509 [00:15<00:00, 21631638.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=48262)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=48262)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=48262)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1747336.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=48262)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=48262)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 42193572.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-05-02 09:55:40. Total running time: 26min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00004   RUNNING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-05-02 09:56:10. Total running time: 26min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00004   RUNNING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-05-02 09:56:40. Total running time: 27min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00004   RUNNING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-05-02 09:57:10. Total running time: 27min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00004   RUNNING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 4 TERMINATED | 1 RUNNING | 5 PENDING\n",
            "Current time: 2024-05-02 09:57:40. Total running time: 28min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00004   RUNNING                   8               16   1.54268e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00004 finished iteration 1 at 2024-05-02 09:58:05. Total running time: 28min 28s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00004 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   189.252 |\n",
            "| time_total_s                       189.252 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.03871 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00004 completed after 1 iterations at 2024-05-02 09:58:05. Total running time: 28min 28s\n",
            "\n",
            "Trial status: 5 TERMINATED | 5 PENDING\n",
            "Current time: 2024-05-02 09:58:10. Total running time: 28min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   PENDING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00005 started with configuration:\n",
            "+-------------------------------------------+\n",
            "| Trial train_7e449_00005 config            |\n",
            "+-------------------------------------------+\n",
            "| conv1_out_ch                           16 |\n",
            "| conv2_out_ch                           16 |\n",
            "| lr                                 0.0001 |\n",
            "+-------------------------------------------+\n",
            "\u001b[36m(train pid=49123)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=49123)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<19:57, 287882.12it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:43, 451445.22it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:26, 502176.04it/s]\n",
            "  0%|          | 262144/344862509 [00:00<09:00, 637605.09it/s]\n",
            "  0%|          | 524288/344862509 [00:00<04:41, 1221664.61it/s]\n",
            "  0%|          | 1048576/344862509 [00:00<02:27, 2335319.11it/s]\n",
            "  1%|          | 2097152/344862509 [00:00<01:15, 4518847.66it/s]\n",
            "  1%|          | 4227072/344862509 [00:00<00:38, 8906213.73it/s]\n",
            "  2%|▏         | 6422528/344862509 [00:01<00:28, 12020676.22it/s]\n",
            "  3%|▎         | 8912896/344862509 [00:01<00:22, 14907338.31it/s]\n",
            "  3%|▎         | 10944512/344862509 [00:01<00:21, 15678464.32it/s]\n",
            "  4%|▍         | 13697024/344862509 [00:01<00:18, 18031125.46it/s]\n",
            "  5%|▍         | 15958016/344862509 [00:01<00:17, 18517184.56it/s]\n",
            "  5%|▌         | 18382848/344862509 [00:01<00:16, 19218216.93it/s]\n",
            "  6%|▌         | 20938752/344862509 [00:01<00:16, 19881914.40it/s]\n",
            "  7%|▋         | 23592960/344862509 [00:01<00:15, 20922034.27it/s]\n",
            "  7%|▋         | 25690112/344862509 [00:01<00:15, 20002955.23it/s]\n",
            "  8%|▊         | 28409856/344862509 [00:02<00:15, 21037481.32it/s]\n",
            "  9%|▉         | 30998528/344862509 [00:02<00:14, 21395928.05it/s]\n",
            " 10%|▉         | 33849344/344862509 [00:02<00:13, 22322532.83it/s]\n",
            " 11%|█         | 36470784/344862509 [00:02<00:13, 22369035.12it/s]\n",
            " 11%|█▏        | 39452672/344862509 [00:02<00:13, 23343942.90it/s]\n",
            " 12%|█▏        | 42401792/344862509 [00:02<00:12, 23929236.94it/s]\n",
            " 13%|█▎        | 45056000/344862509 [00:02<00:12, 23584435.32it/s]\n",
            " 14%|█▍        | 47448064/344862509 [00:02<00:13, 22682508.63it/s]\n",
            " 15%|█▍        | 50429952/344862509 [00:03<00:12, 23536634.12it/s]\n",
            " 15%|█▌        | 53248000/344862509 [00:03<00:12, 23768126.17it/s]\n",
            " 16%|█▋        | 56229888/344862509 [00:03<00:11, 24315718.08it/s]\n",
            " 17%|█▋        | 59375616/344862509 [00:03<00:11, 25122014.58it/s]\n",
            " 18%|█▊        | 62488576/344862509 [00:03<00:11, 25600516.89it/s]\n",
            " 19%|█▉        | 65339392/344862509 [00:03<00:11, 25257514.57it/s]\n",
            " 20%|█▉        | 68386816/344862509 [00:03<00:10, 25533671.24it/s]\n",
            " 21%|██        | 71434240/344862509 [00:03<00:10, 25722860.70it/s]\n",
            " 22%|██▏       | 74350592/344862509 [00:03<00:10, 25516843.24it/s]\n",
            " 22%|██▏       | 77496320/344862509 [00:04<00:10, 25953867.34it/s]\n",
            " 23%|██▎       | 80642048/344862509 [00:04<00:10, 26263105.27it/s]\n",
            " 24%|██▍       | 83755008/344862509 [00:04<00:09, 26402009.45it/s]\n",
            " 25%|██▌       | 86867968/344862509 [00:04<00:09, 26487446.29it/s]\n",
            " 26%|██▌       | 89882624/344862509 [00:04<00:09, 26305152.13it/s]\n",
            " 27%|██▋       | 92995584/344862509 [00:04<00:09, 26428964.52it/s]\n",
            " 28%|██▊       | 95649792/344862509 [00:04<00:10, 24877700.43it/s]\n",
            " 29%|██▊       | 98336768/344862509 [00:04<00:09, 24790780.99it/s]\n",
            " 29%|██▉       | 101187584/344862509 [00:05<00:09, 24690618.07it/s]\n",
            " 30%|███       | 104071168/344862509 [00:05<00:09, 24707442.24it/s]\n",
            " 31%|███       | 106921984/344862509 [00:05<00:09, 24633128.81it/s]\n",
            " 32%|███▏      | 109871104/344862509 [00:05<00:09, 24853033.17it/s]\n",
            " 33%|███▎      | 112623616/344862509 [00:05<00:09, 24483987.43it/s]\n",
            " 34%|███▎      | 115769344/344862509 [00:05<00:09, 25243721.12it/s]\n",
            " 34%|███▍      | 118685696/344862509 [00:05<00:08, 25175444.89it/s]\n",
            " 35%|███▌      | 121307136/344862509 [00:05<00:09, 24367302.44it/s]\n",
            " 36%|███▌      | 124026880/344862509 [00:05<00:09, 24079327.07it/s]\n",
            " 37%|███▋      | 127041536/344862509 [00:06<00:08, 24614789.36it/s]\n",
            " 38%|███▊      | 129990656/344862509 [00:06<00:08, 24818061.15it/s]\n",
            " 39%|███▊      | 132972544/344862509 [00:06<00:08, 25054458.22it/s]\n",
            " 39%|███▉      | 135757824/344862509 [00:06<00:08, 24712520.19it/s]\n",
            " 40%|████      | 138477568/344862509 [00:06<00:08, 24293966.51it/s]\n",
            " 41%|████      | 141590528/344862509 [00:06<00:08, 24844433.34it/s]\n",
            " 42%|████▏     | 144637952/344862509 [00:06<00:07, 25397287.30it/s]\n",
            " 43%|████▎     | 147685376/344862509 [00:06<00:07, 25637142.26it/s]\n",
            " 44%|████▎     | 150372352/344862509 [00:06<00:07, 24864893.36it/s]\n",
            " 44%|████▍     | 153452544/344862509 [00:07<00:07, 25241469.16it/s]\n",
            " 45%|████▌     | 156565504/344862509 [00:07<00:07, 25695316.06it/s]\n",
            " 46%|████▋     | 159645696/344862509 [00:07<00:07, 25815603.25it/s]\n",
            " 47%|████▋     | 162693120/344862509 [00:07<00:07, 25923707.28it/s]\n",
            " 48%|████▊     | 165773312/344862509 [00:07<00:06, 26077448.72it/s]\n",
            " 49%|████▉     | 168853504/344862509 [00:07<00:06, 26184529.47it/s]\n",
            " 50%|████▉     | 171966464/344862509 [00:07<00:06, 26348450.33it/s]\n",
            " 51%|█████     | 175013888/344862509 [00:07<00:06, 26307128.97it/s]\n",
            " 52%|█████▏    | 178061312/344862509 [00:08<00:06, 26271767.95it/s]\n",
            " 53%|█████▎    | 181174272/344862509 [00:08<00:06, 26367629.86it/s]\n",
            " 53%|█████▎    | 184188928/344862509 [00:08<00:06, 26219467.41it/s]\n",
            " 54%|█████▍    | 187236352/344862509 [00:08<00:06, 26205736.60it/s]\n",
            " 55%|█████▌    | 190283776/344862509 [00:08<00:05, 26199237.44it/s]\n",
            " 56%|█████▌    | 193429504/344862509 [00:08<00:05, 26407254.60it/s]\n",
            " 57%|█████▋    | 196542464/344862509 [00:08<00:05, 26490953.57it/s]\n",
            " 58%|█████▊    | 199655424/344862509 [00:08<00:05, 26541454.04it/s]\n",
            " 59%|█████▉    | 202768384/344862509 [00:08<00:05, 26603230.53it/s]\n",
            " 60%|█████▉    | 205684736/344862509 [00:09<00:05, 26071949.55it/s]\n",
            " 60%|██████    | 208601088/344862509 [00:09<00:05, 25816662.77it/s]\n",
            " 61%|██████▏   | 211648512/344862509 [00:09<00:05, 25921002.64it/s]\n",
            " 62%|██████▏   | 214695936/344862509 [00:09<00:05, 25968402.34it/s]\n",
            " 63%|██████▎   | 217776128/344862509 [00:09<00:04, 26145619.81it/s]\n",
            " 64%|██████▍   | 220823552/344862509 [00:09<00:04, 26149418.62it/s]\n",
            " 65%|██████▍   | 223805440/344862509 [00:09<00:04, 25980581.16it/s]\n",
            " 66%|██████▌   | 226656256/344862509 [00:09<00:04, 24983659.85it/s]\n",
            " 67%|██████▋   | 229638144/344862509 [00:10<00:04, 25251852.97it/s]\n",
            " 67%|██████▋   | 232521728/344862509 [00:10<00:04, 25096184.76it/s]\n",
            " 68%|██████▊   | 235274240/344862509 [00:10<00:04, 24671592.91it/s]\n",
            " 69%|██████▉   | 238223360/344862509 [00:10<00:04, 24880266.26it/s]\n",
            " 70%|██████▉   | 241205248/344862509 [00:10<00:04, 25088730.58it/s]\n",
            " 71%|███████   | 243957760/344862509 [00:10<00:04, 24612746.93it/s]\n",
            " 72%|███████▏  | 246874112/344862509 [00:10<00:03, 24702234.27it/s]\n",
            " 72%|███████▏  | 249921536/344862509 [00:10<00:03, 25160807.55it/s]\n",
            " 73%|███████▎  | 252968960/344862509 [00:10<00:03, 25454480.33it/s]\n",
            " 74%|███████▍  | 255918080/344862509 [00:11<00:03, 25419141.23it/s]\n",
            " 75%|███████▌  | 258736128/344862509 [00:11<00:03, 25022126.12it/s]\n",
            " 76%|███████▌  | 261849088/344862509 [00:11<00:03, 25543701.24it/s]\n",
            " 77%|███████▋  | 264896512/344862509 [00:11<00:03, 25713945.57it/s]\n",
            " 78%|███████▊  | 267943936/344862509 [00:11<00:02, 25841380.22it/s]\n",
            " 79%|███████▊  | 270729216/344862509 [00:11<00:02, 25273292.64it/s]\n",
            " 79%|███████▉  | 273842176/344862509 [00:11<00:02, 25708770.99it/s]\n",
            " 80%|████████  | 276824064/344862509 [00:11<00:02, 25673789.39it/s]\n",
            " 81%|████████  | 279871488/344862509 [00:12<00:02, 25712024.03it/s]\n",
            " 82%|████████▏ | 282689536/344862509 [00:12<00:02, 25252420.88it/s]\n",
            " 83%|████████▎ | 285573120/344862509 [00:12<00:02, 25114029.03it/s]\n",
            " 84%|████████▎ | 288423936/344862509 [00:12<00:02, 24935039.82it/s]\n",
            " 84%|████████▍ | 291307520/344862509 [00:12<00:02, 24860523.94it/s]\n",
            " 85%|████████▌ | 294420480/344862509 [00:12<00:01, 25438378.44it/s]\n",
            " 86%|████████▌ | 297369600/344862509 [00:12<00:01, 25405962.12it/s]\n",
            " 87%|████████▋ | 300351488/344862509 [00:12<00:01, 25478933.76it/s]\n",
            " 88%|████████▊ | 303333376/344862509 [00:12<00:01, 25508757.35it/s]\n",
            " 89%|████████▉ | 306446336/344862509 [00:13<00:01, 25782617.27it/s]\n",
            " 90%|████████▉ | 309493760/344862509 [00:13<00:01, 25978505.87it/s]\n",
            " 91%|█████████ | 312475648/344862509 [00:13<00:01, 25462850.33it/s]\n",
            " 91%|█████████▏| 315490304/344862509 [00:13<00:01, 25601290.24it/s]\n",
            " 92%|█████████▏| 318472192/344862509 [00:13<00:01, 25512586.50it/s]\n",
            " 93%|█████████▎| 321388544/344862509 [00:13<00:00, 25359975.13it/s]\n",
            " 94%|█████████▍| 324272128/344862509 [00:13<00:00, 25141867.00it/s]\n",
            " 95%|█████████▍| 327254016/344862509 [00:13<00:00, 25211198.79it/s]\n",
            " 96%|█████████▌| 330170368/344862509 [00:13<00:00, 25152372.03it/s]\n",
            " 97%|█████████▋| 332955648/344862509 [00:14<00:00, 24779471.66it/s]\n",
            " 97%|█████████▋| 335872000/344862509 [00:14<00:00, 24859766.61it/s]\n",
            " 98%|█████████▊| 338788352/344862509 [00:14<00:00, 24881386.23it/s]\n",
            " 99%|█████████▉| 341671936/344862509 [00:14<00:00, 24790892.74it/s]\n",
            "100%|██████████| 344862509/344862509 [00:14<00:00, 23644396.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=49123)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=49123)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=49123)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 2152904.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 09:58:40. Total running time: 29min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train pid=49123)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=49123)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 49974898.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 09:59:10. Total running time: 29min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 09:59:40. Total running time: 30min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 10:00:10. Total running time: 30min 33s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 10:00:40. Total running time: 31min 3s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 10:01:11. Total running time: 31min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 10:01:41. Total running time: 32min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 5 TERMINATED | 1 RUNNING | 4 PENDING\n",
            "Current time: 2024-05-02 10:02:11. Total running time: 32min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00005   RUNNING                  16               16   0.000103507                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00006   PENDING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00005 finished iteration 1 at 2024-05-02 10:02:20. Total running time: 32min 42s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00005 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   246.368 |\n",
            "| time_total_s                       246.368 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                             0.094 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00005 completed after 1 iterations at 2024-05-02 10:02:20. Total running time: 32min 43s\n",
            "\n",
            "Trial train_7e449_00006 started with configuration:\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00006 config             |\n",
            "+--------------------------------------------+\n",
            "| conv1_out_ch                             8 |\n",
            "| conv2_out_ch                            64 |\n",
            "| lr                                 0.00014 |\n",
            "+--------------------------------------------+\n",
            "\u001b[36m(train pid=50218)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=50218)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<19:55, 288516.06it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:43, 451836.76it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:23, 503965.18it/s]\n",
            "  0%|          | 294912/344862509 [00:00<07:38, 751432.32it/s]\n",
            "  0%|          | 589824/344862509 [00:00<04:06, 1396643.24it/s]\n",
            "  0%|          | 1179648/344862509 [00:00<02:09, 2650938.60it/s]\n",
            "  1%|          | 2392064/344862509 [00:00<01:05, 5194167.23it/s]\n",
            "  1%|▏         | 4816896/344862509 [00:00<00:33, 10182495.76it/s]\n",
            "  2%|▏         | 7340032/344862509 [00:01<00:24, 13779092.89it/s]\n",
            "  3%|▎         | 9633792/344862509 [00:01<00:21, 15607813.33it/s]\n",
            "  3%|▎         | 11730944/344862509 [00:01<00:20, 16356220.92it/s]\n",
            "  4%|▍         | 14450688/344862509 [00:01<00:17, 18496292.80it/s]\n",
            "  5%|▌         | 17596416/344862509 [00:01<00:15, 21060797.24it/s]\n",
            "  6%|▌         | 20381696/344862509 [00:01<00:14, 21952984.30it/s]\n",
            "  7%|▋         | 23330816/344862509 [00:01<00:13, 23007102.68it/s]\n",
            "  8%|▊         | 26378240/344862509 [00:01<00:13, 23978947.60it/s]\n",
            "  8%|▊         | 29261824/344862509 [00:01<00:13, 24241497.63it/s]\n",
            "  9%|▉         | 32309248/344862509 [00:02<00:12, 24829629.90it/s]\n",
            " 10%|█         | 35323904/344862509 [00:02<00:12, 25157745.39it/s]\n",
            " 11%|█         | 38305792/344862509 [00:02<00:12, 25308600.38it/s]\n",
            " 12%|█▏        | 41451520/344862509 [00:02<00:11, 25831304.58it/s]\n",
            " 13%|█▎        | 44564480/344862509 [00:02<00:11, 25285694.50it/s]\n",
            " 14%|█▍        | 47448064/344862509 [00:02<00:11, 25987837.95it/s]\n",
            " 15%|█▍        | 50495488/344862509 [00:02<00:11, 26056616.17it/s]\n",
            " 15%|█▌        | 53248000/344862509 [00:02<00:11, 25333376.44it/s]\n",
            " 16%|█▋        | 56197120/344862509 [00:03<00:11, 25355097.91it/s]\n",
            " 17%|█▋        | 59211776/344862509 [00:03<00:11, 25532341.58it/s]\n",
            " 18%|█▊        | 62226432/344862509 [00:03<00:11, 25656858.70it/s]\n",
            " 19%|█▉        | 65208320/344862509 [00:03<00:10, 25646425.02it/s]\n",
            " 20%|█▉        | 68288512/344862509 [00:03<00:10, 25906263.50it/s]\n",
            " 21%|██        | 71335936/344862509 [00:03<00:10, 26005940.73it/s]\n",
            " 21%|██▏       | 73957376/344862509 [00:03<00:10, 24978937.58it/s]\n",
            " 22%|██▏       | 76939264/344862509 [00:03<00:10, 25132198.65it/s]\n",
            " 23%|██▎       | 79724544/344862509 [00:03<00:10, 24825540.30it/s]\n",
            " 24%|██▍       | 82804736/344862509 [00:04<00:10, 25335768.97it/s]\n",
            " 25%|██▍       | 85917696/344862509 [00:04<00:10, 25762468.55it/s]\n",
            " 26%|██▌       | 88932352/344862509 [00:04<00:09, 25819443.62it/s]\n",
            " 27%|██▋       | 91881472/344862509 [00:04<00:09, 25673187.84it/s]\n",
            " 28%|██▊       | 94896128/344862509 [00:04<00:09, 25756959.20it/s]\n",
            " 28%|██▊       | 97878016/344862509 [00:04<00:09, 25735099.35it/s]\n",
            " 29%|██▉       | 100630528/344862509 [00:04<00:09, 25126746.96it/s]\n",
            " 30%|███       | 103579648/344862509 [00:04<00:09, 25188474.20it/s]\n",
            " 31%|███       | 106659840/344862509 [00:04<00:09, 25588140.94it/s]\n",
            " 32%|███▏      | 109576192/344862509 [00:05<00:09, 25434238.92it/s]\n",
            " 33%|███▎      | 112558080/344862509 [00:05<00:09, 25500513.73it/s]\n",
            " 34%|███▎      | 115638272/344862509 [00:05<00:08, 25801710.94it/s]\n",
            " 34%|███▍      | 118325248/344862509 [00:05<00:09, 24991348.29it/s]\n",
            " 35%|███▌      | 121241600/344862509 [00:05<00:08, 24976690.31it/s]\n",
            " 36%|███▌      | 124289024/344862509 [00:05<00:08, 25395221.37it/s]\n",
            " 37%|███▋      | 127270912/344862509 [00:05<00:08, 25474406.90it/s]\n",
            " 38%|███▊      | 130252800/344862509 [00:05<00:08, 25521281.29it/s]\n",
            " 39%|███▊      | 133234688/344862509 [00:06<00:08, 25534654.87it/s]\n",
            " 39%|███▉      | 136216576/344862509 [00:06<00:08, 25594735.75it/s]\n",
            " 40%|████      | 139264000/344862509 [00:06<00:07, 25768611.68it/s]\n",
            " 41%|████▏     | 142311424/344862509 [00:06<00:07, 25921589.21it/s]\n",
            " 42%|████▏     | 145293312/344862509 [00:06<00:07, 25832622.60it/s]\n",
            " 43%|████▎     | 148406272/344862509 [00:06<00:07, 26129518.60it/s]\n",
            " 44%|████▍     | 151289856/344862509 [00:06<00:07, 25754561.72it/s]\n",
            " 45%|████▍     | 154075136/344862509 [00:06<00:07, 25195105.01it/s]\n",
            " 46%|████▌     | 157089792/344862509 [00:06<00:07, 25418845.18it/s]\n",
            " 46%|████▋     | 159940608/344862509 [00:07<00:07, 25159268.14it/s]\n",
            " 47%|████▋     | 162988032/344862509 [00:07<00:07, 25476444.30it/s]\n",
            " 48%|████▊     | 166133760/344862509 [00:07<00:06, 25864262.95it/s]\n",
            " 49%|████▉     | 169148416/344862509 [00:07<00:06, 25944887.33it/s]\n",
            " 50%|████▉     | 172064768/344862509 [00:07<00:06, 25696539.97it/s]\n",
            " 51%|█████     | 175112192/344862509 [00:07<00:06, 25842766.74it/s]\n",
            " 52%|█████▏    | 178094080/344862509 [00:07<00:06, 25791874.86it/s]\n",
            " 52%|█████▏    | 181043200/344862509 [00:07<00:06, 25676946.00it/s]\n",
            " 53%|█████▎    | 184090624/344862509 [00:08<00:06, 25830142.05it/s]\n",
            " 54%|█████▍    | 187039744/344862509 [00:08<00:06, 25700351.34it/s]\n",
            " 55%|█████▌    | 190021632/344862509 [00:08<00:06, 25675873.36it/s]\n",
            " 56%|█████▌    | 193003520/344862509 [00:08<00:05, 25680738.55it/s]\n",
            " 57%|█████▋    | 195985408/344862509 [00:08<00:05, 25675277.84it/s]\n",
            " 58%|█████▊    | 198967296/344862509 [00:08<00:05, 25662419.69it/s]\n",
            " 59%|█████▊    | 202014720/344862509 [00:08<00:05, 25797465.74it/s]\n",
            " 59%|█████▉    | 205062144/344862509 [00:08<00:05, 25956547.74it/s]\n",
            " 60%|██████    | 208109568/344862509 [00:08<00:05, 26028578.80it/s]\n",
            " 61%|██████    | 211189760/344862509 [00:09<00:05, 26168579.53it/s]\n",
            " 62%|██████▏   | 214237184/344862509 [00:09<00:04, 26176557.82it/s]\n",
            " 63%|██████▎   | 217317376/344862509 [00:09<00:04, 26283132.56it/s]\n",
            " 64%|██████▍   | 220397568/344862509 [00:09<00:04, 26359528.44it/s]\n",
            " 65%|██████▍   | 223313920/344862509 [00:09<00:04, 25957117.81it/s]\n",
            " 66%|██████▌   | 226230272/344862509 [00:09<00:04, 25697307.31it/s]\n",
            " 66%|██████▋   | 229179392/344862509 [00:09<00:04, 25601213.51it/s]\n",
            " 67%|██████▋   | 232194048/344862509 [00:09<00:04, 25716915.97it/s]\n",
            " 68%|██████▊   | 235175936/344862509 [00:09<00:04, 25706265.65it/s]\n",
            " 69%|██████▉   | 238125056/344862509 [00:10<00:04, 25595426.57it/s]\n",
            " 70%|██████▉   | 241139712/344862509 [00:10<00:04, 25689026.07it/s]\n",
            " 71%|███████   | 243990528/344862509 [00:10<00:03, 25342918.04it/s]\n",
            " 72%|███████▏  | 246743040/344862509 [00:10<00:03, 24850428.20it/s]\n",
            " 72%|███████▏  | 249692160/344862509 [00:10<00:03, 25009918.37it/s]\n",
            " 73%|███████▎  | 252739584/344862509 [00:10<00:03, 25380835.96it/s]\n",
            " 74%|███████▍  | 255787008/344862509 [00:10<00:03, 25626376.02it/s]\n",
            " 75%|███████▌  | 258867200/344862509 [00:10<00:03, 25885463.76it/s]\n",
            " 76%|███████▌  | 261881856/344862509 [00:11<00:03, 25899548.71it/s]\n",
            " 77%|███████▋  | 264765440/344862509 [00:11<00:03, 25573767.78it/s]\n",
            " 78%|███████▊  | 267354112/344862509 [00:11<00:03, 24583787.23it/s]\n",
            " 78%|███████▊  | 270336000/344862509 [00:11<00:02, 24910843.47it/s]\n",
            " 79%|███████▉  | 273350656/344862509 [00:11<00:02, 25231936.62it/s]\n",
            " 80%|████████  | 276496384/344862509 [00:11<00:02, 25728704.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:02:41. Total running time: 33min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|████████  | 279511040/344862509 [00:11<00:02, 25791150.98it/s]\n",
            " 82%|████████▏ | 282394624/344862509 [00:11<00:02, 25492213.17it/s]\n",
            " 83%|████████▎ | 285409280/344862509 [00:11<00:02, 25595726.76it/s]\n",
            " 84%|████████▎ | 288489472/344862509 [00:12<00:02, 25896958.88it/s]\n",
            " 84%|████████▍ | 291176448/344862509 [00:12<00:02, 25084445.00it/s]\n",
            " 85%|████████▌ | 294060032/344862509 [00:12<00:02, 24998052.91it/s]\n",
            " 86%|████████▌ | 296910848/344862509 [00:12<00:01, 24821683.46it/s]\n",
            " 87%|████████▋ | 299761664/344862509 [00:12<00:01, 24759462.15it/s]\n",
            " 88%|████████▊ | 302841856/344862509 [00:12<00:01, 25288858.34it/s]\n",
            " 89%|████████▊ | 305627136/344862509 [00:12<00:01, 24887562.93it/s]\n",
            " 89%|████████▉ | 308477952/344862509 [00:12<00:01, 24772645.47it/s]\n",
            " 90%|█████████ | 311459840/344862509 [00:13<00:01, 24965969.55it/s]\n",
            " 91%|█████████ | 314310656/344862509 [00:13<00:01, 24889288.53it/s]\n",
            " 92%|█████████▏| 317325312/344862509 [00:13<00:01, 25153529.64it/s]\n",
            " 93%|█████████▎| 320176128/344862509 [00:13<00:00, 25041493.29it/s]\n",
            " 94%|█████████▎| 323223552/344862509 [00:13<00:00, 25397623.25it/s]\n",
            " 95%|█████████▍| 326074368/344862509 [00:13<00:00, 25098190.92it/s]\n",
            " 95%|█████████▌| 328597504/344862509 [00:13<00:00, 24082400.35it/s]\n",
            " 96%|█████████▌| 331415552/344862509 [00:13<00:00, 24177647.17it/s]\n",
            " 97%|█████████▋| 334266368/344862509 [00:13<00:00, 24290854.02it/s]\n",
            " 98%|█████████▊| 337149952/344862509 [00:14<00:00, 24409195.38it/s]\n",
            " 99%|█████████▊| 340197376/344862509 [00:14<00:00, 24958693.31it/s]\n",
            " 99%|█████████▉| 342982656/344862509 [00:14<00:00, 24635809.78it/s]\n",
            "100%|██████████| 344862509/344862509 [00:14<00:00, 24038242.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=50218)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=50218)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=50218)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 2161746.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=50218)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=50218)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 41689935.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:03:11. Total running time: 33min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:03:41. Total running time: 34min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:04:11. Total running time: 34min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:04:41. Total running time: 35min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:05:11. Total running time: 35min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:05:41. Total running time: 36min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:06:11. Total running time: 36min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:06:41. Total running time: 37min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 6 TERMINATED | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-05-02 10:07:11. Total running time: 37min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00006   RUNNING                   8               64   0.000142062                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00007   PENDING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00006 finished iteration 1 at 2024-05-02 10:07:25. Total running time: 37min 48s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00006 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   298.792 |\n",
            "| time_total_s                       298.792 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.09384 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00006 completed after 1 iterations at 2024-05-02 10:07:25. Total running time: 37min 48s\n",
            "\n",
            "Trial train_7e449_00007 started with configuration:\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00007 config             |\n",
            "+--------------------------------------------+\n",
            "| conv1_out_ch                            32 |\n",
            "| conv2_out_ch                            64 |\n",
            "| lr                                 0.00017 |\n",
            "+--------------------------------------------+\n",
            "\u001b[36m(train pid=51530)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=51530)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<19:56, 288169.43it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:41, 452482.97it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:25, 503007.41it/s]\n",
            "  0%|          | 229376/344862509 [00:00<10:52, 527977.00it/s]\n",
            "  0%|          | 491520/344862509 [00:00<04:58, 1153470.39it/s]\n",
            "  0%|          | 983040/344862509 [00:00<02:36, 2203555.05it/s]\n",
            "  1%|          | 1966080/344862509 [00:00<01:20, 4256235.28it/s]\n",
            "  1%|          | 3899392/344862509 [00:00<00:41, 8214908.23it/s]\n",
            "  2%|▏         | 6356992/344862509 [00:01<00:27, 12263922.12it/s]\n",
            "  3%|▎         | 9011200/344862509 [00:01<00:21, 15545842.61it/s]\n",
            "  3%|▎         | 11927552/344862509 [00:01<00:18, 18489794.45it/s]\n",
            "  4%|▍         | 14417920/344862509 [00:01<00:17, 19399962.58it/s]\n",
            "  5%|▍         | 16678912/344862509 [00:01<00:16, 19424310.34it/s]\n",
            "  6%|▌         | 19660800/344862509 [00:01<00:15, 21337320.42it/s]\n",
            "  6%|▋         | 22216704/344862509 [00:01<00:14, 21536576.95it/s]\n",
            "  7%|▋         | 24576000/344862509 [00:01<00:15, 21183542.39it/s]\n",
            "  8%|▊         | 27623424/344862509 [00:01<00:13, 22721367.85it/s]\n",
            "  9%|▉         | 30375936/344862509 [00:02<00:13, 22992190.98it/s]\n",
            " 10%|▉         | 33292288/344862509 [00:02<00:13, 23640609.45it/s]\n",
            " 11%|█         | 36405248/344862509 [00:02<00:12, 24599475.33it/s]\n",
            " 11%|█▏        | 39288832/344862509 [00:02<00:12, 24665445.34it/s]\n",
            " 12%|█▏        | 42336256/344862509 [00:02<00:12, 25163378.53it/s]\n",
            " 13%|█▎        | 45350912/344862509 [00:02<00:11, 25413524.56it/s]\n",
            " 14%|█▍        | 48365568/344862509 [00:02<00:11, 25560118.02it/s]\n",
            " 15%|█▍        | 51511296/344862509 [00:02<00:11, 26058892.62it/s]\n",
            " 16%|█▌        | 54132736/344862509 [00:03<00:11, 24968051.17it/s]\n",
            " 16%|█▋        | 56721408/344862509 [00:03<00:11, 24214089.28it/s]\n",
            " 17%|█▋        | 59703296/344862509 [00:03<00:11, 24657979.09it/s]\n",
            " 18%|█▊        | 62717952/344862509 [00:03<00:11, 25057909.59it/s]\n",
            " 19%|█▉        | 65667072/344862509 [00:03<00:11, 25176533.95it/s]\n",
            " 20%|█▉        | 68648960/344862509 [00:03<00:10, 25333943.70it/s]\n",
            " 21%|██        | 71794688/344862509 [00:03<00:10, 25866569.58it/s]\n",
            " 22%|██▏       | 74907648/344862509 [00:03<00:10, 26159284.41it/s]\n",
            " 23%|██▎       | 78020608/344862509 [00:03<00:10, 26323502.02it/s]\n",
            " 24%|██▎       | 81133568/344862509 [00:04<00:09, 26386562.55it/s]\n",
            " 24%|██▍       | 84148224/344862509 [00:04<00:09, 26307496.73it/s]\n",
            " 25%|██▌       | 86802432/344862509 [00:04<00:10, 25257922.27it/s]\n",
            " 26%|██▌       | 89718784/344862509 [00:04<00:10, 25254190.44it/s]\n",
            " 27%|██▋       | 92536832/344862509 [00:04<00:10, 24961436.82it/s]\n",
            " 28%|██▊       | 95551488/344862509 [00:04<00:09, 25276218.79it/s]\n",
            " 29%|██▊       | 98369536/344862509 [00:04<00:09, 24989982.11it/s]\n",
            " 29%|██▉       | 100892672/344862509 [00:04<00:10, 24021382.33it/s]\n",
            " 30%|███       | 103677952/344862509 [00:04<00:10, 24037539.71it/s]\n",
            " 31%|███       | 106463232/344862509 [00:05<00:09, 24005203.98it/s]\n",
            " 32%|███▏      | 108888064/344862509 [00:05<00:10, 23072752.30it/s]\n",
            " 32%|███▏      | 111673344/344862509 [00:05<00:09, 23361546.72it/s]\n",
            " 33%|███▎      | 114753536/344862509 [00:05<00:09, 24309785.27it/s]\n",
            " 34%|███▍      | 117768192/344862509 [00:05<00:09, 24840545.88it/s]\n",
            " 35%|███▌      | 120815616/344862509 [00:05<00:08, 25053439.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:07:41. Total running time: 38min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=51530)\u001b[0m \r 36%|███▌      | 123404288/344862509 [00:05<00:09, 24237130.34it/s]\n",
            " 37%|███▋      | 126418944/344862509 [00:05<00:08, 24761031.90it/s]\n",
            " 38%|███▊      | 129433600/344862509 [00:06<00:08, 25136024.18it/s]\n",
            " 38%|███▊      | 132382720/344862509 [00:06<00:08, 25244409.00it/s]\n",
            " 39%|███▉      | 135233536/344862509 [00:06<00:08, 25029689.44it/s]\n",
            " 40%|███▉      | 137789440/344862509 [00:06<00:08, 24130809.50it/s]\n",
            " 41%|████      | 140541952/344862509 [00:06<00:08, 24028256.00it/s]\n",
            " 42%|████▏     | 143556608/344862509 [00:06<00:08, 24608335.32it/s]\n",
            " 42%|████▏     | 146472960/344862509 [00:06<00:08, 24763998.47it/s]\n",
            " 43%|████▎     | 149356544/344862509 [00:06<00:07, 24788719.95it/s]\n",
            " 44%|████▍     | 152109056/344862509 [00:06<00:07, 24484262.62it/s]\n",
            " 45%|████▍     | 154566656/344862509 [00:07<00:08, 23485214.24it/s]\n",
            " 46%|████▌     | 157581312/344862509 [00:07<00:07, 24260082.36it/s]\n",
            " 46%|████▋     | 160268288/344862509 [00:07<00:07, 23917866.10it/s]\n",
            " 47%|████▋     | 163217408/344862509 [00:07<00:07, 24380550.82it/s]\n",
            " 48%|████▊     | 165675008/344862509 [00:07<00:07, 23357208.21it/s]\n",
            " 49%|████▉     | 168263680/344862509 [00:07<00:07, 23112001.70it/s]\n",
            " 50%|████▉     | 171114496/344862509 [00:07<00:07, 23573361.98it/s]\n",
            " 50%|█████     | 173768704/344862509 [00:07<00:07, 23368606.82it/s]\n",
            " 51%|█████     | 176553984/344862509 [00:08<00:07, 23569844.01it/s]\n",
            " 52%|█████▏    | 179437568/344862509 [00:08<00:06, 23925652.03it/s]\n",
            " 53%|█████▎    | 182190080/344862509 [00:08<00:06, 23826914.30it/s]\n",
            " 54%|█████▎    | 185008128/344862509 [00:08<00:06, 23977975.50it/s]\n",
            " 55%|█████▍    | 187957248/344862509 [00:08<00:06, 24370340.89it/s]\n",
            " 55%|█████▌    | 190873600/344862509 [00:08<00:06, 24639247.57it/s]\n",
            " 56%|█████▌    | 193560576/344862509 [00:08<00:06, 24206467.81it/s]\n",
            " 57%|█████▋    | 196476928/344862509 [00:08<00:06, 24499162.14it/s]\n",
            " 58%|█████▊    | 199557120/344862509 [00:08<00:05, 25094934.95it/s]\n",
            " 59%|█████▊    | 202276864/344862509 [00:09<00:05, 24606966.44it/s]\n",
            " 60%|█████▉    | 205291520/344862509 [00:09<00:05, 25015960.94it/s]\n",
            " 60%|██████    | 208142336/344862509 [00:09<00:05, 24883026.62it/s]\n",
            " 61%|██████    | 211091456/344862509 [00:09<00:05, 25046111.53it/s]\n",
            " 62%|██████▏   | 214204416/344862509 [00:09<00:05, 25580173.71it/s]\n",
            " 63%|██████▎   | 217088000/344862509 [00:09<00:05, 25351332.10it/s]\n",
            " 64%|██████▍   | 219938816/344862509 [00:09<00:04, 25098353.40it/s]\n",
            " 65%|██████▍   | 222658560/344862509 [00:09<00:04, 24628469.98it/s]\n",
            " 65%|██████▌   | 225411072/344862509 [00:09<00:04, 24349683.10it/s]\n",
            " 66%|██████▌   | 228294656/344862509 [00:10<00:04, 24519518.08it/s]\n",
            " 67%|██████▋   | 230785024/344862509 [00:10<00:04, 23578060.04it/s]\n",
            " 68%|██████▊   | 233668608/344862509 [00:10<00:04, 23967771.33it/s]\n",
            " 69%|██████▊   | 236355584/344862509 [00:10<00:04, 23717908.57it/s]\n",
            " 69%|██████▉   | 239206400/344862509 [00:10<00:04, 24007172.75it/s]\n",
            " 70%|███████   | 242221056/344862509 [00:10<00:04, 24610294.06it/s]\n",
            " 71%|███████   | 245039104/344862509 [00:10<00:04, 24516741.41it/s]\n",
            " 72%|███████▏  | 248152064/344862509 [00:10<00:03, 25188689.62it/s]\n",
            " 73%|███████▎  | 250839040/344862509 [00:11<00:03, 24589967.64it/s]\n",
            " 73%|███████▎  | 253460480/344862509 [00:11<00:03, 23993476.92it/s]\n",
            " 74%|███████▍  | 256573440/344862509 [00:11<00:03, 24847544.75it/s]\n",
            " 75%|███████▌  | 259293184/344862509 [00:11<00:03, 24418506.92it/s]\n",
            " 76%|███████▌  | 261947392/344862509 [00:11<00:03, 23980485.56it/s]\n",
            " 77%|███████▋  | 264699904/344862509 [00:11<00:03, 23858356.48it/s]\n",
            " 78%|███████▊  | 267517952/344862509 [00:11<00:03, 23987420.59it/s]\n",
            " 78%|███████▊  | 270237696/344862509 [00:11<00:03, 23764648.89it/s]\n",
            " 79%|███████▉  | 273285120/344862509 [00:11<00:02, 24516390.04it/s]\n",
            " 80%|████████  | 276234240/344862509 [00:12<00:02, 24791094.31it/s]\n",
            " 81%|████████  | 279052288/344862509 [00:12<00:02, 24680057.41it/s]\n",
            " 82%|████████▏ | 281903104/344862509 [00:12<00:02, 24543750.07it/s]\n",
            " 83%|████████▎ | 284950528/344862509 [00:12<00:02, 25122170.56it/s]\n",
            " 83%|████████▎ | 287932416/344862509 [00:12<00:02, 25360698.68it/s]\n",
            " 84%|████████▍ | 290881536/344862509 [00:12<00:02, 25378727.50it/s]\n",
            " 85%|████████▌ | 293437440/344862509 [00:12<00:02, 23302589.78it/s]\n",
            " 86%|████████▌ | 295796736/344862509 [00:12<00:02, 23374679.63it/s]\n",
            " 86%|████████▋ | 298156032/344862509 [00:12<00:02, 22476844.97it/s]\n",
            " 87%|████████▋ | 300744704/344862509 [00:13<00:01, 22521082.62it/s]\n",
            " 88%|████████▊ | 303661056/344862509 [00:13<00:01, 23320079.91it/s]\n",
            " 89%|████████▉ | 306610176/344862509 [00:13<00:01, 23957997.75it/s]\n",
            " 90%|████████▉ | 309035008/344862509 [00:13<00:01, 19033292.47it/s]\n",
            " 90%|█████████ | 311099392/344862509 [00:13<00:02, 12437450.49it/s]\n",
            " 91%|█████████ | 313688064/344862509 [00:13<00:02, 14431204.66it/s]\n",
            " 91%|█████████▏| 315523072/344862509 [00:14<00:02, 10843551.41it/s]\n",
            " 92%|█████████▏| 317259776/344862509 [00:14<00:02, 11706487.10it/s]\n",
            " 92%|█████████▏| 318767104/344862509 [00:14<00:02, 9852919.13it/s] \n",
            " 93%|█████████▎| 321552384/344862509 [00:14<00:01, 12698028.54it/s]\n",
            " 94%|█████████▎| 323158016/344862509 [00:14<00:01, 12874830.28it/s]\n",
            " 94%|█████████▍| 324698112/344862509 [00:15<00:02, 9379764.92it/s] \n",
            " 95%|█████████▍| 325910528/344862509 [00:15<00:01, 9647853.72it/s]\n",
            " 95%|█████████▌| 327712768/344862509 [00:15<00:01, 10022066.05it/s]\n",
            " 95%|█████████▌| 328892416/344862509 [00:15<00:01, 10004225.62it/s]\n",
            " 96%|█████████▌| 330006528/344862509 [00:15<00:02, 7167335.23it/s] \n",
            " 96%|█████████▌| 331644928/344862509 [00:16<00:01, 7910317.32it/s]\n",
            " 96%|█████████▋| 332595200/344862509 [00:16<00:01, 7889547.43it/s]\n",
            " 97%|█████████▋| 333479936/344862509 [00:16<00:01, 6429783.92it/s]\n",
            " 97%|█████████▋| 334233600/344862509 [00:16<00:01, 6437933.46it/s]\n",
            " 97%|█████████▋| 334954496/344862509 [00:16<00:01, 5627366.38it/s]\n",
            " 97%|█████████▋| 335773696/344862509 [00:16<00:01, 5445410.47it/s]\n",
            " 98%|█████████▊| 336363520/344862509 [00:16<00:01, 5319885.06it/s]\n",
            " 98%|█████████▊| 336920576/344862509 [00:17<00:01, 5163077.51it/s]\n",
            " 98%|█████████▊| 337477632/344862509 [00:17<00:01, 5060167.32it/s]\n",
            " 98%|█████████▊| 338001920/344862509 [00:17<00:01, 4903298.01it/s]\n",
            " 98%|█████████▊| 338526208/344862509 [00:17<00:01, 4790991.28it/s]\n",
            " 98%|█████████▊| 339017728/344862509 [00:17<00:01, 4055531.77it/s]\n",
            " 98%|█████████▊| 339509248/344862509 [00:17<00:01, 3703033.65it/s]\n",
            " 99%|█████████▊| 340000768/344862509 [00:17<00:01, 3834635.09it/s]\n",
            " 99%|█████████▊| 340492288/344862509 [00:18<00:01, 3942123.51it/s]\n",
            " 99%|█████████▉| 340983808/344862509 [00:18<00:00, 4024568.56it/s]\n",
            " 99%|█████████▉| 341475328/344862509 [00:18<00:00, 4084835.07it/s]\n",
            " 99%|█████████▉| 341999616/344862509 [00:18<00:00, 4210573.51it/s]\n",
            " 99%|█████████▉| 342491136/344862509 [00:18<00:00, 4216703.17it/s]\n",
            " 99%|█████████▉| 342982656/344862509 [00:18<00:00, 3606691.50it/s]\n",
            "100%|█████████▉| 343867392/344862509 [00:18<00:00, 4195091.91it/s]\n",
            "100%|█████████▉| 344293376/344862509 [00:18<00:00, 4031835.91it/s]\n",
            "100%|██████████| 344862509/344862509 [00:19<00:00, 18091498.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=51530)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=51530)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=51530)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1479649.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=51530)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=51530)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 39465425.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:08:11. Total running time: 38min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:08:41. Total running time: 39min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:09:11. Total running time: 39min 34s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:09:41. Total running time: 40min 4s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:10:12. Total running time: 40min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:10:42. Total running time: 41min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:11:12. Total running time: 41min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:11:42. Total running time: 42min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:12:12. Total running time: 42min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:12:42. Total running time: 43min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:13:12. Total running time: 43min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:13:42. Total running time: 44min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:14:12. Total running time: 44min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:14:42. Total running time: 45min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:15:12. Total running time: 45min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 7 TERMINATED | 1 RUNNING | 2 PENDING\n",
            "Current time: 2024-05-02 10:15:42. Total running time: 46min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00007   RUNNING                  32               64   0.000170753                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00008   PENDING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00007 finished iteration 1 at 2024-05-02 10:15:53. Total running time: 46min 15s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00007 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   499.782 |\n",
            "| time_total_s                       499.782 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.10603 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00007 completed after 1 iterations at 2024-05-02 10:15:53. Total running time: 46min 16s\n",
            "\n",
            "Trial train_7e449_00008 started with configuration:\n",
            "+------------------------------------------+\n",
            "| Trial train_7e449_00008 config           |\n",
            "+------------------------------------------+\n",
            "| conv1_out_ch                          16 |\n",
            "| conv2_out_ch                          32 |\n",
            "| lr                                 5e-05 |\n",
            "+------------------------------------------+\n",
            "\u001b[36m(train pid=53653)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=53653)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<19:46, 290590.11it/s]\n",
            "  0%|          | 98304/344862509 [00:00<12:40, 453197.54it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:25, 502515.79it/s]\n",
            "  0%|          | 360448/344862509 [00:00<05:55, 968759.58it/s]\n",
            "  0%|          | 720896/344862509 [00:00<03:18, 1731723.26it/s]\n",
            "  0%|          | 1081344/344862509 [00:00<02:37, 2181517.90it/s]\n",
            "  0%|          | 1474560/344862509 [00:00<02:13, 2566264.81it/s]\n",
            "  1%|          | 1900544/344862509 [00:00<01:57, 2907645.22it/s]\n",
            "  1%|          | 2326528/344862509 [00:01<01:49, 3131203.14it/s]\n",
            "  1%|          | 2785280/344862509 [00:01<01:41, 3376669.42it/s]\n",
            "  1%|          | 3244032/344862509 [00:01<01:36, 3545842.13it/s]\n",
            "  1%|          | 3768320/344862509 [00:01<01:29, 3831065.29it/s]\n",
            "  1%|          | 4292608/344862509 [00:01<01:24, 4027679.64it/s]\n",
            "  1%|▏         | 4849664/344862509 [00:01<01:19, 4252370.61it/s]\n",
            "  2%|▏         | 5406720/344862509 [00:01<01:17, 4407085.15it/s]\n",
            "  2%|▏         | 6029312/344862509 [00:01<01:12, 4681754.37it/s]\n",
            "  2%|▏         | 6684672/344862509 [00:01<01:08, 4954214.05it/s]\n",
            "  2%|▏         | 7340032/344862509 [00:02<01:05, 5150625.76it/s]\n",
            "  2%|▏         | 8060928/344862509 [00:02<01:01, 5442827.59it/s]\n",
            "  3%|▎         | 8781824/344862509 [00:02<00:59, 5660361.50it/s]\n",
            "  3%|▎         | 9568256/344862509 [00:02<00:56, 5973544.76it/s]\n",
            "  3%|▎         | 10387456/344862509 [00:02<00:53, 6282307.46it/s]\n",
            "  3%|▎         | 11239424/344862509 [00:02<00:50, 6586479.82it/s]\n",
            "  4%|▎         | 12156928/344862509 [00:02<00:47, 6963050.71it/s]\n",
            "  4%|▍         | 13107200/344862509 [00:02<00:45, 7305303.45it/s]\n",
            "  4%|▍         | 14090240/344862509 [00:03<00:43, 7626891.31it/s]\n",
            "  4%|▍         | 15138816/344862509 [00:03<00:41, 8028730.01it/s]\n",
            "  5%|▍         | 16220160/344862509 [00:03<00:39, 8386442.35it/s]\n",
            "  5%|▌         | 17399808/344862509 [00:03<00:36, 8897430.74it/s]\n",
            "  5%|▌         | 18612224/344862509 [00:03<00:34, 9342773.65it/s]\n",
            "  6%|▌         | 19857408/344862509 [00:03<00:33, 9736988.14it/s]\n",
            "  6%|▌         | 21200896/344862509 [00:03<00:31, 10260625.38it/s]\n",
            "  7%|▋         | 22609920/344862509 [00:03<00:29, 10796852.17it/s]\n",
            "  7%|▋         | 24084480/344862509 [00:03<00:28, 11340384.96it/s]\n",
            "  7%|▋         | 25624576/344862509 [00:04<00:26, 11888783.18it/s]\n",
            "  8%|▊         | 27230208/344862509 [00:04<00:25, 12443917.09it/s]\n",
            "  8%|▊         | 28934144/344862509 [00:04<00:24, 13083216.66it/s]\n",
            "  9%|▉         | 30703616/344862509 [00:04<00:22, 13704463.29it/s]\n",
            "  9%|▉         | 32604160/344862509 [00:04<00:21, 14452800.25it/s]\n",
            " 10%|█         | 34570240/344862509 [00:04<00:20, 15158716.06it/s]\n",
            " 11%|█         | 36634624/344862509 [00:04<00:19, 15909487.44it/s]\n",
            " 11%|█▏        | 38797312/344862509 [00:04<00:18, 16685651.39it/s]\n",
            " 12%|█▏        | 41091072/344862509 [00:05<00:17, 17537241.92it/s]\n",
            " 13%|█▎        | 43483136/344862509 [00:05<00:16, 18432053.01it/s]\n",
            " 13%|█▎        | 45973504/344862509 [00:05<00:15, 19292748.48it/s]\n",
            " 14%|█▍        | 48562176/344862509 [00:05<00:14, 20149258.79it/s]\n",
            " 15%|█▍        | 51249152/344862509 [00:05<00:13, 21007055.12it/s]\n",
            " 16%|█▌        | 54132736/344862509 [00:05<00:13, 22082320.77it/s]\n",
            " 17%|█▋        | 57016320/344862509 [00:05<00:12, 22841919.32it/s]\n",
            " 17%|█▋        | 59867136/344862509 [00:05<00:12, 23301035.79it/s]\n",
            " 18%|█▊        | 62914560/344862509 [00:05<00:11, 24134683.35it/s]\n",
            " 19%|█▉        | 65929216/344862509 [00:06<00:11, 24621211.72it/s]\n",
            " 20%|█▉        | 68878336/344862509 [00:06<00:11, 24805294.64it/s]\n",
            " 21%|██        | 71925760/344862509 [00:06<00:10, 25184979.00it/s]\n",
            " 22%|██▏       | 74874880/344862509 [00:06<00:10, 25201083.26it/s]\n",
            " 22%|██▏       | 77398016/344862509 [00:06<00:11, 24082527.35it/s]\n",
            " 23%|██▎       | 80445440/344862509 [00:06<00:10, 24701891.63it/s]\n",
            " 24%|██▍       | 83132416/344862509 [00:06<00:10, 24183050.54it/s]\n",
            " 25%|██▍       | 85950464/344862509 [00:06<00:10, 24127022.43it/s]\n",
            " 26%|██▌       | 88997888/344862509 [00:07<00:10, 24712872.80it/s]\n",
            " 27%|██▋       | 92078080/344862509 [00:07<00:10, 25188160.58it/s]\n",
            " 28%|██▊       | 95059968/344862509 [00:07<00:09, 25290873.24it/s]\n",
            " 28%|██▊       | 98107392/344862509 [00:07<00:09, 25511486.76it/s]\n",
            " 29%|██▉       | 101154816/344862509 [00:07<00:09, 25680444.64it/s]\n",
            " 30%|███       | 104005632/344862509 [00:07<00:09, 25295690.02it/s]\n",
            " 31%|███       | 107151360/344862509 [00:07<00:09, 25774277.36it/s]\n",
            " 32%|███▏      | 110264320/344862509 [00:07<00:09, 25999038.35it/s]\n",
            " 33%|███▎      | 113246208/344862509 [00:07<00:08, 25846140.15it/s]\n",
            " 34%|███▎      | 116228096/344862509 [00:08<00:08, 25739589.37it/s]\n",
            " 34%|███▍      | 118816768/344862509 [00:08<00:09, 24125079.84it/s]\n",
            " 35%|███▌      | 121241600/344862509 [00:08<00:09, 23006785.31it/s]\n",
            " 36%|███▌      | 123568128/344862509 [00:08<00:10, 22082181.60it/s]\n",
            " 36%|███▋      | 125796352/344862509 [00:08<00:10, 21185416.74it/s]\n",
            " 37%|███▋      | 127926272/344862509 [00:08<00:10, 20391420.77it/s]\n",
            " 38%|███▊      | 129990656/344862509 [00:08<00:10, 19673802.58it/s]\n",
            " 38%|███▊      | 131956736/344862509 [00:08<00:11, 18871780.24it/s]\n",
            " 39%|███▉      | 133857280/344862509 [00:09<00:11, 18156573.57it/s]\n",
            " 39%|███▉      | 136052736/344862509 [00:09<00:11, 18378314.37it/s]\n",
            " 40%|████      | 138543104/344862509 [00:09<00:10, 19256410.57it/s]\n",
            " 41%|████      | 141033472/344862509 [00:09<00:10, 19865892.45it/s]\n",
            " 42%|████▏     | 143556608/344862509 [00:09<00:09, 20386416.60it/s]\n",
            " 42%|████▏     | 146112512/344862509 [00:09<00:09, 20839387.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:16:12. Total running time: 46min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=53653)\u001b[0m \r 43%|████▎     | 148701184/344862509 [00:09<00:09, 21208350.08it/s]\n",
            " 44%|████▍     | 151289856/344862509 [00:09<00:09, 21470158.67it/s]\n",
            " 45%|████▍     | 153878528/344862509 [00:09<00:08, 21667906.28it/s]\n",
            " 45%|████▌     | 156532736/344862509 [00:10<00:08, 21980260.30it/s]\n",
            " 46%|████▌     | 159186944/344862509 [00:10<00:08, 22184254.04it/s]\n",
            " 47%|████▋     | 161841152/344862509 [00:10<00:08, 22314060.10it/s]\n",
            " 48%|████▊     | 164528128/344862509 [00:10<00:08, 22513502.07it/s]\n",
            " 48%|████▊     | 167182336/344862509 [00:10<00:07, 22568662.05it/s]\n",
            " 49%|████▉     | 169705472/344862509 [00:10<00:07, 22274808.47it/s]\n",
            " 50%|████▉     | 172392448/344862509 [00:10<00:07, 22484091.53it/s]\n",
            " 51%|█████     | 175046656/344862509 [00:10<00:07, 22515715.56it/s]\n",
            " 52%|█████▏    | 177799168/344862509 [00:10<00:07, 22863003.74it/s]\n",
            " 52%|█████▏    | 180584448/344862509 [00:11<00:07, 23133360.86it/s]\n",
            " 53%|█████▎    | 183304192/344862509 [00:11<00:06, 23136399.65it/s]\n",
            " 54%|█████▍    | 186089472/344862509 [00:11<00:06, 23317230.74it/s]\n",
            " 55%|█████▍    | 188907520/344862509 [00:11<00:06, 23514313.87it/s]\n",
            " 56%|█████▌    | 191725568/344862509 [00:11<00:06, 23596740.09it/s]\n",
            " 56%|█████▋    | 194412544/344862509 [00:11<00:06, 23576667.67it/s]\n",
            " 57%|█████▋    | 196771840/344862509 [00:11<00:06, 22561648.82it/s]\n",
            " 58%|█████▊    | 199524352/344862509 [00:11<00:06, 22858294.95it/s]\n",
            " 59%|█████▊    | 202309632/344862509 [00:12<00:06, 22892953.07it/s]\n",
            " 59%|█████▉    | 204603392/344862509 [00:12<00:06, 22036503.81it/s]\n",
            " 60%|██████    | 207388672/344862509 [00:12<00:06, 22690644.25it/s]\n",
            " 61%|██████    | 210239488/344862509 [00:12<00:05, 23098601.48it/s]\n",
            " 62%|██████▏   | 212566016/344862509 [00:12<00:05, 22123193.58it/s]\n",
            " 62%|██████▏   | 215384064/344862509 [00:12<00:05, 22732866.63it/s]\n",
            " 63%|██████▎   | 218234880/344862509 [00:12<00:05, 23199430.17it/s]\n",
            " 64%|██████▍   | 221216768/344862509 [00:12<00:05, 23856748.27it/s]\n",
            " 65%|██████▌   | 224231424/344862509 [00:12<00:04, 24434432.16it/s]\n",
            " 66%|██████▌   | 227180544/344862509 [00:13<00:04, 24676160.78it/s]\n",
            " 67%|██████▋   | 229965824/344862509 [00:13<00:04, 24388408.17it/s]\n",
            " 68%|██████▊   | 232980480/344862509 [00:13<00:04, 24755771.01it/s]\n",
            " 68%|██████▊   | 235896832/344862509 [00:13<00:04, 24846221.61it/s]\n",
            " 69%|██████▉   | 238878720/344862509 [00:13<00:04, 25030933.18it/s]\n",
            " 70%|███████   | 241696768/344862509 [00:13<00:04, 24756048.04it/s]\n",
            " 71%|███████   | 244547584/344862509 [00:13<00:04, 24645869.05it/s]\n",
            " 72%|███████▏  | 247529472/344862509 [00:13<00:03, 24903526.55it/s]\n",
            " 73%|███████▎  | 250511360/344862509 [00:14<00:03, 25087659.39it/s]\n",
            " 74%|███████▎  | 253558784/344862509 [00:14<00:03, 25354134.02it/s]\n",
            " 74%|███████▍  | 256245760/344862509 [00:14<00:03, 24632823.01it/s]\n",
            " 75%|███████▌  | 259358720/344862509 [00:14<00:03, 25120133.38it/s]\n",
            " 76%|███████▌  | 262176768/344862509 [00:14<00:03, 24902927.87it/s]\n",
            " 77%|███████▋  | 265191424/344862509 [00:14<00:03, 25169713.63it/s]\n",
            " 78%|███████▊  | 268271616/344862509 [00:14<00:03, 25521839.49it/s]\n",
            " 79%|███████▊  | 270991360/344862509 [00:14<00:02, 24834008.88it/s]\n",
            " 79%|███████▉  | 273973248/344862509 [00:14<00:02, 25038294.94it/s]\n",
            " 80%|████████  | 276987904/344862509 [00:15<00:02, 25250331.16it/s]\n",
            " 81%|████████  | 279871488/344862509 [00:15<00:02, 25075146.37it/s]\n",
            " 82%|████████▏ | 282558464/344862509 [00:15<00:02, 24436287.94it/s]\n",
            " 83%|████████▎ | 285605888/344862509 [00:15<00:02, 24928749.24it/s]\n",
            " 84%|████████▎ | 288522240/344862509 [00:15<00:02, 24928568.30it/s]\n",
            " 85%|████████▍ | 291504128/344862509 [00:15<00:02, 25065239.07it/s]\n",
            " 85%|████████▌ | 294486016/344862509 [00:15<00:01, 25210626.71it/s]\n",
            " 86%|████████▋ | 297533440/344862509 [00:15<00:01, 25462904.42it/s]\n",
            " 87%|████████▋ | 300580864/344862509 [00:16<00:01, 25650083.04it/s]\n",
            " 88%|████████▊ | 303529984/344862509 [00:16<00:01, 25522154.19it/s]\n",
            " 89%|████████▉ | 306610176/344862509 [00:16<00:01, 25305764.41it/s]\n",
            " 90%|████████▉ | 309526528/344862509 [00:16<00:01, 25661249.54it/s]\n",
            " 91%|█████████ | 312508416/344862509 [00:16<00:01, 25544444.83it/s]\n",
            " 91%|█████████▏| 315293696/344862509 [00:16<00:01, 25088772.91it/s]\n",
            " 92%|█████████▏| 317816832/344862509 [00:16<00:01, 24003184.19it/s]\n",
            " 93%|█████████▎| 320634880/344862509 [00:16<00:01, 24084073.12it/s]\n",
            " 94%|█████████▍| 323616768/344862509 [00:16<00:00, 24509133.90it/s]\n",
            " 95%|█████████▍| 326533120/344862509 [00:17<00:00, 24633020.72it/s]\n",
            " 96%|█████████▌| 329515008/344862509 [00:17<00:00, 24910496.50it/s]\n",
            " 96%|█████████▋| 332365824/344862509 [00:17<00:00, 24720932.53it/s]\n",
            " 97%|█████████▋| 335478784/344862509 [00:17<00:00, 25252966.30it/s]\n",
            " 98%|█████████▊| 338558976/344862509 [00:17<00:00, 25577978.59it/s]\n",
            " 99%|█████████▉| 341245952/344862509 [00:17<00:00, 24732346.29it/s]\n",
            "100%|██████████| 344862509/344862509 [00:17<00:00, 19376873.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=53653)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\u001b[36m(train pid=53653)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=53653)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 2032375.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=53653)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=53653)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 34038128.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:16:42. Total running time: 47min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:17:12. Total running time: 47min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:17:42. Total running time: 48min 5s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:18:12. Total running time: 48min 35s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:18:43. Total running time: 49min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:19:13. Total running time: 49min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:19:43. Total running time: 50min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:20:13. Total running time: 50min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 8 TERMINATED | 1 RUNNING | 1 PENDING\n",
            "Current time: 2024-05-02 10:20:43. Total running time: 51min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00008   RUNNING                  16               32   5.40184e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00009   PENDING                  16               64   1.87446e-05                                          |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00008 finished iteration 1 at 2024-05-02 10:20:45. Total running time: 51min 8s\n",
            "+--------------------------------------------+\n",
            "| Trial train_7e449_00008 result             |\n",
            "+--------------------------------------------+\n",
            "| checkpoint_dir_name                        |\n",
            "| time_this_iter_s                   284.953 |\n",
            "| time_total_s                       284.953 |\n",
            "| training_iteration                       1 |\n",
            "| accuracy                           0.09904 |\n",
            "+--------------------------------------------+\n",
            "\n",
            "Trial train_7e449_00008 completed after 1 iterations at 2024-05-02 10:20:45. Total running time: 51min 8s\n",
            "\n",
            "Trial train_7e449_00009 started with configuration:\n",
            "+------------------------------------------+\n",
            "| Trial train_7e449_00009 config           |\n",
            "+------------------------------------------+\n",
            "| conv1_out_ch                          16 |\n",
            "| conv2_out_ch                          64 |\n",
            "| lr                                 2e-05 |\n",
            "+------------------------------------------+\n",
            "\u001b[36m(train pid=54913)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=54913)\u001b[0m \r  0%|          | 0/344862509 [00:00<?, ?it/s]\n",
            "  0%|          | 32768/344862509 [00:00<20:32, 279829.77it/s]\n",
            "  0%|          | 98304/344862509 [00:00<13:00, 441463.03it/s]\n",
            "  0%|          | 163840/344862509 [00:00<11:39, 492843.75it/s]\n",
            "  0%|          | 327680/344862509 [00:00<06:47, 846456.43it/s]\n",
            "  0%|          | 688128/344862509 [00:00<03:29, 1640278.47it/s]\n",
            "  0%|          | 1409024/344862509 [00:00<01:48, 3152448.89it/s]\n",
            "  1%|          | 2818048/344862509 [00:00<00:56, 6012509.48it/s]\n",
            "  1%|▏         | 5111808/344862509 [00:00<00:33, 10266372.47it/s]\n",
            "  2%|▏         | 7372800/344862509 [00:01<00:25, 13034718.41it/s]\n",
            "  3%|▎         | 9928704/344862509 [00:01<00:21, 15639307.14it/s]\n",
            "  4%|▎         | 12517376/344862509 [00:01<00:18, 17544641.55it/s]\n",
            "  4%|▍         | 14974976/344862509 [00:01<00:17, 18517479.99it/s]\n",
            "  5%|▌         | 17858560/344862509 [00:01<00:16, 20274350.26it/s]\n",
            "  6%|▌         | 20676608/344862509 [00:01<00:15, 21346927.73it/s]\n",
            "  7%|▋         | 23625728/344862509 [00:01<00:14, 22403262.21it/s]\n",
            "  8%|▊         | 26542080/344862509 [00:01<00:13, 23089496.95it/s]\n",
            "  9%|▊         | 29687808/344862509 [00:02<00:13, 24126433.88it/s]\n",
            " 10%|▉         | 32800768/344862509 [00:02<00:12, 24776996.64it/s]\n",
            " 10%|█         | 35880960/344862509 [00:02<00:12, 25093444.48it/s]\n",
            " 11%|█         | 38600704/344862509 [00:02<00:12, 24520079.66it/s]\n",
            " 12%|█▏        | 41746432/344862509 [00:02<00:12, 25126311.01it/s]\n",
            " 13%|█▎        | 44761088/344862509 [00:02<00:11, 25228465.20it/s]\n",
            " 14%|█▍        | 47841280/344862509 [00:02<00:11, 25466026.36it/s]\n",
            " 15%|█▍        | 50888704/344862509 [00:02<00:11, 25546426.57it/s]\n",
            " 16%|█▌        | 53936128/344862509 [00:02<00:11, 25613644.15it/s]\n",
            " 16%|█▋        | 56819712/344862509 [00:03<00:11, 25232063.27it/s]\n",
            " 17%|█▋        | 59932672/344862509 [00:03<00:11, 25551715.70it/s]\n",
            " 18%|█▊        | 62488576/344862509 [00:03<00:11, 24331636.02it/s]\n",
            " 19%|█▉        | 65470464/344862509 [00:03<00:11, 24630314.45it/s]\n",
            " 20%|█▉        | 68517888/344862509 [00:03<00:11, 24963108.47it/s]\n",
            " 21%|██        | 71434240/344862509 [00:03<00:11, 24855729.83it/s]\n",
            " 22%|██▏       | 74252288/344862509 [00:03<00:11, 24499399.38it/s]\n",
            " 22%|██▏       | 77299712/344862509 [00:03<00:10, 24894311.40it/s]\n",
            " 23%|██▎       | 80314368/344862509 [00:04<00:10, 25077376.89it/s]\n",
            " 24%|██▍       | 83296256/344862509 [00:04<00:10, 25118886.27it/s]\n",
            " 25%|██▍       | 86016000/344862509 [00:04<00:10, 24459531.88it/s]\n",
            " 26%|██▌       | 88834048/344862509 [00:04<00:10, 24272975.06it/s]\n",
            " 27%|██▋       | 91848704/344862509 [00:04<00:10, 24619285.24it/s]\n",
            " 27%|██▋       | 94666752/344862509 [00:04<00:10, 24331577.89it/s]\n",
            " 28%|██▊       | 97615872/344862509 [00:04<00:10, 24529420.77it/s]\n",
            " 29%|██▉       | 100597760/344862509 [00:04<00:09, 24684220.70it/s]\n",
            " 30%|███       | 103481344/344862509 [00:04<00:09, 24610371.33it/s]\n",
            " 31%|███       | 105971712/344862509 [00:05<00:10, 23487263.86it/s]\n",
            " 32%|███▏      | 108888064/344862509 [00:05<00:09, 23896879.21it/s]\n",
            " 32%|███▏      | 112001024/344862509 [00:05<00:09, 24487924.57it/s]\n",
            " 33%|███▎      | 115113984/344862509 [00:05<00:09, 24917550.10it/s]\n",
            " 34%|███▍      | 118063104/344862509 [00:05<00:09, 25001959.55it/s]\n",
            " 35%|███▌      | 121044992/344862509 [00:05<00:08, 25038930.90it/s]\n",
            " 36%|███▌      | 123797504/344862509 [00:05<00:09, 24473468.86it/s]\n",
            " 37%|███▋      | 126812160/344862509 [00:05<00:08, 24802976.71it/s]\n",
            " 38%|███▊      | 129892352/344862509 [00:06<00:08, 25180943.41it/s]\n",
            " 39%|███▊      | 132972544/344862509 [00:06<00:08, 25441620.10it/s]\n",
            " 39%|███▉      | 135823360/344862509 [00:06<00:08, 25029235.61it/s]\n",
            " 40%|████      | 138510336/344862509 [00:06<00:08, 24317787.24it/s]\n",
            " 41%|████      | 141524992/344862509 [00:06<00:08, 24631804.78it/s]\n",
            " 42%|████▏     | 144605184/344862509 [00:06<00:07, 25096558.38it/s]\n",
            " 43%|████▎     | 147423232/344862509 [00:06<00:08, 24613637.50it/s]\n",
            " 44%|████▎     | 150372352/344862509 [00:06<00:07, 24691096.32it/s]\n",
            " 44%|████▍     | 153387008/344862509 [00:06<00:07, 24901948.83it/s]\n",
            " 45%|████▌     | 156172288/344862509 [00:07<00:07, 24486441.37it/s]\n",
            " 46%|████▌     | 159252480/344862509 [00:07<00:07, 24950273.86it/s]\n",
            " 47%|████▋     | 162136064/344862509 [00:07<00:07, 24688801.18it/s]\n",
            " 48%|████▊     | 165216256/344862509 [00:07<00:07, 25087899.71it/s]\n",
            " 49%|████▊     | 167936000/344862509 [00:07<00:07, 24452304.63it/s]\n",
            " 50%|████▉     | 170917888/344862509 [00:07<00:07, 24638356.65it/s]\n",
            " 50%|█████     | 173834240/344862509 [00:07<00:06, 24641289.59it/s]\n",
            " 51%|█████▏    | 176816128/344862509 [00:07<00:06, 24798830.44it/s]\n",
            " 52%|█████▏    | 179798016/344862509 [00:08<00:06, 24921481.81it/s]\n",
            " 53%|█████▎    | 182910976/344862509 [00:08<00:06, 25337545.38it/s]\n",
            " 54%|█████▍    | 185860096/344862509 [00:08<00:06, 25040018.07it/s]\n",
            " 55%|█████▍    | 189005824/344862509 [00:08<00:06, 25464094.43it/s]\n",
            " 56%|█████▌    | 192020480/344862509 [00:08<00:05, 25598341.95it/s]\n",
            " 57%|█████▋    | 195067904/344862509 [00:08<00:05, 25689232.44it/s]\n",
            " 57%|█████▋    | 198115328/344862509 [00:08<00:05, 25696594.19it/s]\n",
            " 58%|█████▊    | 201228288/344862509 [00:08<00:05, 25865154.54it/s]\n",
            " 59%|█████▉    | 203816960/344862509 [00:09<00:13, 10821565.17it/s]\n",
            " 60%|██████    | 208273408/344862509 [00:09<00:09, 15166800.96it/s]\n",
            " 61%|██████▏   | 211386368/344862509 [00:09<00:07, 17229635.56it/s]\n",
            " 62%|██████▏   | 214499328/344862509 [00:09<00:06, 19122182.14it/s]\n",
            " 63%|██████▎   | 217645056/344862509 [00:09<00:06, 20805323.44it/s]\n",
            " 64%|██████▍   | 220364800/344862509 [00:10<00:05, 21061918.57it/s]\n",
            " 65%|██████▍   | 223379456/344862509 [00:10<00:05, 22182959.91it/s]\n",
            " 66%|██████▌   | 226328576/344862509 [00:10<00:05, 22924857.82it/s]\n",
            " 66%|██████▋   | 229244928/344862509 [00:10<00:04, 23405359.82it/s]\n",
            " 67%|██████▋   | 232259584/344862509 [00:10<00:04, 23982398.01it/s]\n",
            " 68%|██████▊   | 235372544/344862509 [00:10<00:04, 24654955.99it/s]\n",
            " 69%|██████▉   | 238485504/344862509 [00:10<00:04, 25096378.44it/s]\n",
            " 70%|███████   | 241631232/344862509 [00:10<00:04, 25525326.83it/s]\n",
            " 71%|███████   | 244744192/344862509 [00:11<00:03, 25708865.50it/s]\n",
            " 72%|███████▏  | 247529472/344862509 [00:11<00:03, 25012931.73it/s]\n",
            " 73%|███████▎  | 250281984/344862509 [00:11<00:03, 24502074.53it/s]\n",
            " 73%|███████▎  | 253394944/344862509 [00:11<00:03, 25052853.04it/s]\n",
            " 74%|███████▍  | 256442368/344862509 [00:11<00:03, 25260379.14it/s]\n",
            " 75%|███████▌  | 259391488/344862509 [00:11<00:03, 25157260.33it/s]\n",
            " 76%|███████▌  | 262504448/344862509 [00:11<00:03, 25502851.67it/s]\n",
            " 77%|███████▋  | 265322496/344862509 [00:11<00:03, 24984032.09it/s]\n",
            " 78%|███████▊  | 268337152/344862509 [00:11<00:03, 25134112.04it/s]\n",
            " 79%|███████▊  | 271482880/344862509 [00:12<00:02, 25554075.78it/s]\n",
            " 80%|███████▉  | 274530304/344862509 [00:12<00:02, 25625601.60it/s]\n",
            " 81%|████████  | 277676032/344862509 [00:12<00:02, 25909201.74it/s]\n",
            " 81%|████████▏ | 280788992/344862509 [00:12<00:02, 26030405.81it/s]\n",
            " 82%|████████▏ | 283836416/344862509 [00:12<00:02, 25955116.59it/s]\n",
            " 83%|████████▎ | 286752768/344862509 [00:12<00:02, 25551232.23it/s]\n",
            " 84%|████████▍ | 289865728/344862509 [00:12<00:02, 25790940.09it/s]\n",
            " 85%|████████▍ | 292913152/344862509 [00:12<00:02, 25759803.62it/s]\n",
            " 86%|████████▌ | 295895040/344862509 [00:13<00:01, 25601917.85it/s]\n",
            " 87%|████████▋ | 298975232/344862509 [00:13<00:01, 25731134.39it/s]\n",
            " 88%|████████▊ | 301760512/344862509 [00:13<00:01, 25072265.57it/s]\n",
            " 88%|████████▊ | 304480256/344862509 [00:13<00:01, 24433620.62it/s]\n",
            " 89%|████████▉ | 307593216/344862509 [00:13<00:01, 24977629.29it/s]\n",
            " 90%|█████████ | 310542336/344862509 [00:13<00:01, 24967313.27it/s]\n",
            " 91%|█████████ | 313229312/344862509 [00:13<00:01, 24244751.52it/s]\n",
            " 92%|█████████▏| 315916288/344862509 [00:13<00:01, 23836129.08it/s]\n",
            " 93%|█████████▎| 319029248/344862509 [00:14<00:01, 24566619.23it/s]\n",
            " 93%|█████████▎| 322076672/344862509 [00:14<00:00, 24912229.96it/s]\n",
            " 94%|█████████▍| 325156864/344862509 [00:14<00:00, 25245069.20it/s]\n",
            " 95%|█████████▌| 327909376/344862509 [00:14<00:00, 24624771.03it/s]\n",
            " 96%|█████████▌| 330432512/344862509 [00:14<00:00, 23514704.41it/s]\n",
            " 97%|█████████▋| 333348864/344862509 [00:14<00:00, 23976391.73it/s]\n",
            " 98%|█████████▊| 336429056/344862509 [00:14<00:00, 24587287.36it/s]\n",
            " 98%|█████████▊| 339542016/344862509 [00:14<00:00, 25067039.50it/s]\n",
            " 99%|█████████▉| 342622208/344862509 [00:14<00:00, 25336785.18it/s]\n",
            "100%|██████████| 344862509/344862509 [00:15<00:00, 22950770.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=54913)\u001b[0m Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "\n",
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:21:13. Total running time: 51min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "\u001b[36m(train pid=54913)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=54913)\u001b[0m \r  0%|          | 0/502 [00:00<?, ?it/s]\r100%|██████████| 502/502 [00:00<00:00, 1216372.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=54913)\u001b[0m Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train pid=54913)\u001b[0m \r  0%|          | 0/14989 [00:00<?, ?it/s]\r100%|██████████| 14989/14989 [00:00<00:00, 42680531.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:21:43. Total running time: 52min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:22:13. Total running time: 52min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:22:43. Total running time: 53min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:23:13. Total running time: 53min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:23:43. Total running time: 54min 6s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:24:13. Total running time: 54min 36s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-02 10:24:24,447\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
            "2024-05-02 10:24:24,470\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_2024-05-02_09-29-36' in 0.0153s.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial status: 9 TERMINATED | 1 RUNNING\n",
            "Current time: 2024-05-02 10:24:24. Total running time: 54min 47s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name          status         conv1_out_ch     conv2_out_ch            lr     iter     total time (s)     accuracy |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_7e449_00009   RUNNING                  16               64   1.87446e-05                                          |\n",
            "| train_7e449_00000   TERMINATED               32               64   1.20162e-05        1            489.728    0.0775736 |\n",
            "| train_7e449_00001   TERMINATED               16               64   0.000133662        1            353.861    0.0962758 |\n",
            "| train_7e449_00002   TERMINATED               16               32   0.000913118        1            288.532    0.0798504 |\n",
            "| train_7e449_00003   TERMINATED               16               64   2.22106e-05        1            347.978    0.0922101 |\n",
            "| train_7e449_00004   TERMINATED                8               16   1.54268e-05        1            189.252    0.0387055 |\n",
            "| train_7e449_00005   TERMINATED               16               16   0.000103507        1            246.368    0.093999  |\n",
            "| train_7e449_00006   TERMINATED                8               64   0.000142062        1            298.792    0.0938364 |\n",
            "| train_7e449_00007   TERMINATED               32               64   0.000170753        1            499.782    0.106034  |\n",
            "| train_7e449_00008   TERMINATED               16               32   5.40184e-05        1            284.953    0.0990405 |\n",
            "+-------------------------------------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-05-02 10:24:34,499\tWARNING tune.py:1054 -- Experiment has been interrupted, but the most recent state was saved.\n",
            "Resume experiment with: tune.run(..., resume=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best hyperparameters: {'conv1_out_ch': 32, 'conv2_out_ch': 64, 'lr': 0.00017075320416410454}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import ray\n",
        "from ray import train\n",
        "from ray import tune\n",
        "from ray.train import Checkpoint\n",
        "from ray.train.torch import TorchTrainer\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define the neural network architecture\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_channels=3, num_out_ch=[8, 16], img_w=128, img_h=128, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=num_channels, out_channels=num_out_ch[0],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn1 = nn.BatchNorm2d(num_out_ch[0])\n",
        "        self.conv2 = nn.Conv2d(in_channels=num_out_ch[0], out_channels=num_out_ch[1],\n",
        "                               kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
        "        self.bn2 = nn.BatchNorm2d(num_out_ch[1])\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
        "        self.fc = nn.Linear(in_features=int(img_w/4)*int(img_h/4)*num_out_ch[1], out_features=num_classes)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x.reshape(x.shape[0], -1))\n",
        "        return x\n",
        "\n",
        "def train(config):\n",
        "    # Load the dataset with absolute paths\n",
        "    train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "    test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "    # Initialize the model\n",
        "    model = MyCNN(num_channels=3, num_out_ch=[config[\"conv1_out_ch\"], config[\"conv2_out_ch\"]],\n",
        "                  img_w=128, img_h=128, num_classes=102)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    # Train the model\n",
        "    epochs = 5\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for images, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct / total\n",
        "\n",
        "    # Use ray.train.report instead of tune.report\n",
        "    ray.train.report({\"accuracy\": accuracy})\n",
        "\n",
        "# Configure Ray Tune\n",
        "ray.shutdown()\n",
        "ray.init()\n",
        "analysis = tune.run(\n",
        "    train,\n",
        "    config=config,\n",
        "    resources_per_trial={\"cpu\": 2},\n",
        "    num_samples=10,\n",
        ")\n",
        "\n",
        "# Get best hyperparameters\n",
        "best_config = analysis.get_best_config(metric=\"accuracy\", mode=\"max\")\n",
        "print(\"Best hyperparameters:\", best_config)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WNvdOyUzavU"
      },
      "source": [
        "RESEARCH PAPER WITH OVERFEAT NETWORK ARCHITECTURE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uziBkVoRzZoF",
        "outputId": "def71ace-1485-48a2-d451-b583fe351d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/102flowers.tgz to data/flowers-102/102flowers.tgz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 344862509/344862509 [00:05<00:00, 66032297.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/flowers-102/102flowers.tgz to data/flowers-102\n",
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/imagelabels.mat to data/flowers-102/imagelabels.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 502/502 [00:00<00:00, 1194294.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://thor.robots.ox.ac.uk/datasets/flowers-102/setid.mat to data/flowers-102/setid.mat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 14989/14989 [00:00<00:00, 31608055.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/200], Train Loss: 4.6282, Test Loss: 4.6258, Test Accuracy: 0.33%\n",
            "Epoch [2/200], Train Loss: 4.6208, Test Loss: 4.5735, Test Accuracy: 4.20%\n",
            "Epoch [3/200], Train Loss: 4.5234, Test Loss: 4.4350, Test Accuracy: 1.54%\n",
            "Epoch [4/200], Train Loss: 4.3722, Test Loss: 4.3701, Test Accuracy: 3.24%\n",
            "Epoch [5/200], Train Loss: 4.3025, Test Loss: 4.3414, Test Accuracy: 2.10%\n",
            "Epoch [6/200], Train Loss: 4.2352, Test Loss: 4.2759, Test Accuracy: 1.98%\n",
            "Epoch [7/200], Train Loss: 4.1748, Test Loss: 4.2265, Test Accuracy: 3.27%\n",
            "Epoch [8/200], Train Loss: 4.1296, Test Loss: 4.2424, Test Accuracy: 2.46%\n",
            "Epoch [9/200], Train Loss: 4.0644, Test Loss: 4.1952, Test Accuracy: 3.63%\n",
            "Epoch [10/200], Train Loss: 4.0285, Test Loss: 4.1870, Test Accuracy: 3.27%\n",
            "Epoch [11/200], Train Loss: 4.0062, Test Loss: 4.2005, Test Accuracy: 4.24%\n",
            "Epoch [12/200], Train Loss: 3.9978, Test Loss: 4.1653, Test Accuracy: 3.71%\n",
            "Epoch [13/200], Train Loss: 3.9004, Test Loss: 4.1762, Test Accuracy: 3.85%\n",
            "Epoch [14/200], Train Loss: 3.8810, Test Loss: 4.1408, Test Accuracy: 5.32%\n",
            "Epoch [15/200], Train Loss: 3.7966, Test Loss: 4.1133, Test Accuracy: 6.05%\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import Flowers102\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Preprocess and load the dataset with augmented transformations\n",
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize((231, 231)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "train_dataset = Flowers102(root='./data', split='train', transform=data_transform, download=True)\n",
        "test_dataset = Flowers102(root='./data', split='test', transform=data_transform, download=True)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, num_classes=102):\n",
        "        super(MyCNN, self).__init__()\n",
        "        # Initialize the CNN layers with the specified architecture\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        # Calculate the input size for the fully connected layers dynamically\n",
        "        self.fc_input_size = self._get_fc_input_size()\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(self.fc_input_size, 3072)\n",
        "        self.fc2 = nn.Linear(3072, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the feature maps\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def _get_fc_input_size(self):\n",
        "        # Forward a dummy input through the convolutional layers to get the output size\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.randn(1, 3, 231, 231)  # Assuming input image size of 231x231\n",
        "            features_output = self.features(dummy_input)\n",
        "            return features_output.view(features_output.size(0), -1).shape[1]\n",
        "\n",
        "# Initialize the model\n",
        "num_classes = len(set(train_dataset._labels))\n",
        "model = MyCNN(num_classes=num_classes)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
        "\n",
        "# Train the model\n",
        "epochs = 200\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "best_test_loss = float('inf')\n",
        "patience = 3\n",
        "counter = 0\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            test_loss += loss.item() * images.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    test_loss = test_loss / len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "\n",
        "    # Early stopping and learning rate adjustment\n",
        "    if test_loss < best_test_loss:\n",
        "        best_test_loss = test_loss\n",
        "        bad_counter = 0\n",
        "    else:\n",
        "        bad_counter += 1\n",
        "        if bad_counter >= patience:\n",
        "            print(\"Adjusting learning rate...\")\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] *= 0.1  # Reduce learning rate by a factor of 10\n",
        "            bad_counter = 0  # Reset bad_counter\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Test Accuracy: {(100 * correct / total):.2f}%')\n",
        "\n",
        "# Plot the training and test losses\n",
        "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, len(test_losses) + 1), test_losses, label='Test Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Losses')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}